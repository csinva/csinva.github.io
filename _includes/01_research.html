<h2 style="text-align: center; margin-top: -150px;"> Research</h2>

<style>
    .research_box {
        padding: 10px;
        margin-bottom: 20px;
        background-color: #262626;
        width: 100%;
        border: 3px solid #3d3c3c;
    }

    .research_box:hover {
        border: 3px solid #5bc0de;
        background-color: #3d3c3c;
        /* Adjust the border width and color as needed */
    }
</style>
<div style="padding-left: 5%;padding-right: 5%">
    <div style="width: 100%;padding: 8px;margin-bottom: 20px; text-align:center; font-size: large;">
        Some areas I'm currently excited about. If you want to chat about research or
        are interested in interning at MSR, feel free to reach out over email :)</div>

    <div class="research_box"><strong>🔎
            Interpretability.</strong> I'm interested in <a href="https://arxiv.org/abs/2402.01761">rethinking
            interpretability</a> in the context of LLMs
        <br>
        <br>
        <a href="https://www.nature.com/articles/s41467-023-43713-1">augmented imodels</a> - use LLMs to build a
        transparent model<br>
        <a href="http://proceedings.mlr.press/v119/rieger20a.html">explanation penalization</a> - regularize
        explanations to align models with prior knowledge<br>
        <a href="https://proceedings.neurips.cc/paper/2021/file/acaa23f71f963e96c8847585e71352d6-Paper.pdf">adaptive
            wavelet distillation</a> - replace neural nets with simple, performant wavelet models
    </div>

    <div class="research_box">

        <strong>🚗 LLM steering. </strong>Interpretability tools can provide ways to better guide and use LLMs (without
        needing gradients!)
        <br>
        <br>
        <a href="https://arxiv.org/abs/2310.14034">tree prompting</a> - improve black-box few-shot text classification
        with decision trees<br>
        <a href="https://arxiv.org/abs/2311.02262">attention steering</a> / <a
            href="https://arxiv.org/abs/2409.10790">automatic attention steering</a> - guide LLMs by
        emphasizing specific input
        spans<br>
        <a href="https://arxiv.org/abs/2210.01848">interpretable autoprompting</a> - automatically find fluent
        natural-language prompts<br>
    </div>


    <div class="research_box">

        <strong>🧠 Neuroscience. </strong> Since joining MSR, I've been focused on leveraging LLM interpretability
        to understand how the human brain represents language (using fMRI in collaboration with the <a
            href="https://www.cs.utexas.edu/~huth/index.html">Huth lab</a> at UT Austin).
        <br>
        <br>
        <a href="https://arxiv.org/abs/2405.16714">qa embeddings</a> - build interpretable fMRI encoding models by
        asking yes/no questions to LLMs<br>
        <a href="https://arxiv.org/abs/2305.09863">summarize &amp; score explanations</a> - generate natural-language
        explanations of fMRI encoding models
    </div>


    <div class="research_box"><strong>💊
            Healthcare. </strong>I'm also actively working on how we can improve clinical decision instruments by using
        the information contained across various sources in the medical literature (in collaboration with <a
            href="https://profiles.ucsf.edu/aaron.kornblith">Aaron Kornblith</a> at UCSF and the MSR <a
            href="https://www.microsoft.com/en-us/research/group/real-world-evidence/">Health Futures team</a>).
        <br>
        <br>
        <a href="https://arxiv.org/abs/2306.00024">clinical self-verification</a> - self-verification improves
        performance and interpretability of clinical information extraction<br>
        <a href="https://journals.plos.org/digitalhealth/article?id=10.1371/journal.pdig.0000076">clinical rule
            vetting</a> - stress testing a clinical decision instrument performance for intra-abdominal injury

    </div>

    <div style="width: 100%;padding: 8px;margin-bottom: 20px; text-align:center; font-size: large;">
        Across these areas, I'm interested in decision trees and how we can build flexible but accurate transparent
        models. I put a lot of my code into the <a href="https://github.com/csinva/imodels">imodels</a> and <a
            href="https://github.com/csinva/imodelsx">imodelsX</a> packages.</div>
</div>

<hr>

<script>
    $(document).ready(function () {
        $('#research_table').DataTable({
            "order": [[0, "desc"]],
            "aLengthMenu": [[6, -1], [6, "All"]],
            "pageLength": 6,
            dom: 'Bfrtip',
            buttons: [
                {
                    text: '🔎 interpretability',
                    action: function (e, dt, node, config) {
                        var current_val = $(".dataTables_wrapper input").val();
                        var table = $('#research_table').DataTable();
                        table.search(current_val + "🔎").draw();
                    }
                },
                {
                    text: '🌀 deep learning',
                    action: function (e, dt, node, config) {
                        var current_val = $(".dataTables_wrapper input").val();
                        var table = $('#research_table').DataTable();
                        table.search(current_val + "🌀").draw();
                    }
                },
                {
                    text: '🌳 interpretable models',
                    action: function (e, dt, node, config) {
                        var current_val = $(".dataTables_wrapper input").val();
                        var table = $('#research_table').DataTable();
                        table.search(current_val + "🌳").draw();
                    }
                },
                {
                    text: '💻 open-source ML',
                    action: function (e, dt, node, config) {
                        var current_val = $(".dataTables_wrapper input").val();
                        var table = $('#research_table').DataTable();
                        table.search(current_val + "💻").draw();
                    }
                },
                {
                    text: '🧠',
                    action: function (e, dt, node, config) {
                        var current_val = $(".dataTables_wrapper input").val();
                        var table = $('#research_table').DataTable();
                        table.search(current_val + "🧠").draw();
                    }
                },
            ]
        });
    });
</script>

<table id="research_table" class="display" style="width:100%">
    <thead>
        <tr>
            <th>year</th>
            <th>title</th>
            <th>authors</th>
            <th>tags</th>
            <th>paper</th>
            <th>code</th>
            <th>misc</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td class="center">'24</td>
            <td>Crafting Interpretable Embeddings by Asking LLMs Questions
            </td>
            <td>benara*, singh*, morris, antonello, stoica, huth, & gao</td>
            <td class="med">🧠🔎🌀</td>
            <td class="center"><a href="https://arxiv.org/abs/2405.16714">neurips</a></td>
            <td class="big"><a href="https://github.com/csinva/interpretable-embeddings"><i
                        class="fa fa-github fa-fw"></i></a></td>
            <td class="med">
            </td>
        </tr>
        <tr>
            <td class="center">'24</td>
            <td>Rethinking Interpretability in the Era of Large Language Models
            </td>
            <td>singh, inala, galley, caruana, & gao</td>
            <td class="med">🔎🌀</td>
            <td class="center"><a href="https://arxiv.org/abs/2402.01761">arxiv</a></td>
            <td class="big"></td>
            <td class="med">
            </td>
        </tr>
        <tr>
            <td class="center">'24</td>
            <td>Towards Consistent Natural-Language Explanations via Explanation-Consistency Finetuning
            </td>
            <td>chen et al.</td>
            <td class="med">🔎🌀</td>
            <td class="center"><a href="https://arxiv.org/abs/2401.13986">arXiv</a></td>
            <td class="big"><a href="https://github.com/yandachen/explanation-consistency-finetuning"><i
                        class="fa fa-github fa-fw"></i></a></td>
            <td class="med">
            </td>
        </tr>
        <tr>
            <td class="center">'24</td>
            <td>Learning a Decision Tree Algorithm with Transformers
            </td>
            <td>zhuang et al.</td>
            <td class="med">🔎🌀🌳</td>
            <td class="center"><a href="https://arxiv.org/abs/2402.03774">tmlr</a></td>
            <td class="big"><a href="https://github.com/EvanZhuang/MetaTree"><i class="fa fa-github fa-fw"></i></a></td>
            <td class="med">
            </td>
        </tr>

        <tr>
            <td class="center">'24</td>
            <td>Model Tells Itself Where to Attend: Faithfulness Meets Automatic Attention Steering
            </td>
            <td>zhang*, yu*, et al.</td>
            <td class="med">🔎🌀</td>
            <td class="center"><a href="https://arxiv.org/abs/2409.10790">arxiv</a></td>
            <td class="big"><a href="https://github.com/QingruZhang/AutoPASTA"><i class="fa fa-github fa-fw"></i></a>
            </td>
            <td class="med">
            </td>
        </tr>

        <tr>
            <td class="center">'24</td>
            <td>Tell Your Model Where to Attend: Post-hoc Attention Steering for LLMs
            </td>
            <td>zhang et al.</td>
            <td class="med">🔎🌀</td>
            <td class="center"><a href="https://arxiv.org/abs/2311.02262">iclr</a></td>
            <td class="big"><a href="https://github.com/QingruZhang/PASTA"><i class="fa fa-github fa-fw"></i></a></td>
            <td class="med">
            </td>
        </tr>
        <tr>
            <td class="center">'24</td>
            <td>Attribute Structuring Improves LLM-Based Evaluation of Clinical Text Summaries
            </td>
            <td>gero et al.</td>
            <td class="med">🔎🌀</td>
            <td class="center"><a href="https://arxiv.org/abs/2403.01002">arxiv</a></td>
            <td class="big"><a href="https://github.com/microsoft/attribute-structuring/"><i
                        class="fa fa-github fa-fw"></i></a></td>
            <td class="med">
            </td>
        </tr>
        <tr>
            <td class="center">'23</td>
            <td>Tree Prompting
            </td>
            <td>morris*, singh*, rush, gao, & deng</td>
            <td class="med">🔎🌀🌳</td>
            <td class="center"><a href="https://arxiv.org/abs/2310.14034">emnlp</a></td>
            <td class="big"><a href="https://github.com/csinva/tree-prompt"><i class="fa fa-github fa-fw"></i></a></td>
            <td class="med">
                <a
                    href="https://docs.google.com/presentation/d/17RqIjCGOaM19R_PFKTQMj5OGhmfpGccmxGW61ixzUPo/edit#slide=id.g21b26013510_0_4"><i
                        class="fa fa-desktop fa-fw"></i></a>
            </td>
        </tr>
        <tr>
            <td class="center">'23</td>
            <td>Augmenting Interpretable Models with LLMs during Training
            </td>
            <td>singh, askari, caruana, & gao</td>
            <td class="med">🔎🌀🌳</td>
            <td class="center"><a href="https://arxiv.org/abs/2209.11799">nature communications</a></td>
            <td class="big"><a href="https://github.com/microsoft/augmented-interpretable-models"><i
                        class="fa fa-github fa-fw"></i></a></td>
            <td class="med">
                <a
                    href="https://docs.google.com/presentation/d/1ctUCnboHFtEsgJm8J7k66PtPn6xDLH-Y3aq_pNTFPBo/edit#slide=id.g23a629b547c_0_0"><i
                        class="fa fa-desktop fa-fw"></i></a>
            </td>
        </tr>
        <tr>
            <td class="center">'23</td>
            <td>Explaining black box text modules in natural language with language models
            </td>
            <td>singh*, hsu*, antonello, jain, huth, yu & gao</td>
            <td class="med">🔎🌀</td>
            <td class="center"><a href="https://arxiv.org/abs/2305.09863">neurips workshop</a></td>
            <td class="big"><a href="https://github.com/microsoft/automated-explanations"><i
                        class="fa fa-github fa-fw"></i></a></td>
            <td class="med">
                <a
                    href="https://docs.google.com/presentation/d/1qL_cATZWiwOg4EjgrQ93m2zEpNMYYdIUUqqMO1REbIk/edit#slide=id.g21b26013510_0_182"><i
                        class="fa fa-desktop fa-fw"></i></a>
            </td>
        </tr>
        <tr>
            <td class="center">'23</td>
            <td>Self-Verification Improves Few-Shot Clinical Information Extraction
            </td>
            <td>gero*, singh*, cheng, naumann, galley, gao, & poon</td>
            <td class="med">🔎🌀💊</td>
            <td class="center"><a href="https://arxiv.org/abs/2306.00024">icml workshop</a></td>
            <td class="big"><a href="https://github.com/microsoft/clinical-self-verification"><i
                        class="fa fa-github fa-fw"></i></a></td>
            <td class="med">
            </td>
        </tr>
        <tr>
            <td class="center">'22</td>
            <td>Explaining patterns in data with language models via interpretable autoprompting
            </td>
            <td>singh*, morris*, aneja, rush, & gao</td>
            <td class="med">🔎🌀</td>
            <td class="center"><a href="https://arxiv.org/abs/2210.01848">emnlp workshop</a></td>
            <td class="big"><a href="https://github.com/csinva/interpretable-autoprompting"><i
                        class="fa fa-github fa-fw"></i></a></td>
            <td class="med">
                <a href="https://docs.google.com/presentation/d/1_4X1IZMm6B621H5_81QZ5DuK9n4E-Vj8sVryVm1kjSE/"><i
                        class="fa fa-desktop fa-fw"></i></a>
            </td>
        </tr>
        <!-- <tr>
            <td class="center">'22</td>
            <td>Interpretable deep learning for accurate molecular partner prediction in clathrin-mediated endocytosis
            </td>
            <td>singh*, li*, et al.</td>
            <td class="med">🔎🌀🦠</td>
            <td class="center">in prep</td>
            <td class="big"><a href="https://github.com/Yu-Group/auxilin-prediction"><i
                        class="fa fa-github fa-fw"></i></a>
            </td>
            <td class="med">
                <a href="https://docs.google.com/presentation/d/1sQXbFUTSEyrmDkovV8g759Wj8E9LBpATAVV1iweKeGo/"><i
                        class="fa fa-desktop fa-fw"></i></a>
            </td>
        </tr> -->
        <!--    <tr>-->
        <!--        <td class="center">'22</td>-->
        <!--        <td>Group Probability-Weighted Tree Sums for Interpretable Modeling of Heterogeneous Data-->
        <!--        </td>-->
        <!--        <td>nasseri, singh, duncan, kornblith, & yu</td>-->
        <!--        <td class="med">🔎🌳💊</td>-->
        <!--        <td class="center"><a href="https://arxiv.org/abs/2205.15135">arXiv</a></td>-->
        <!--        <td class="big"><a href="https://github.com/Yu-Group/imodels-experiments"><i-->
        <!--                class="fa fa-github fa-fw"></i></a></td>-->
        <!--        <td class="med">-->
        <!--        </td>-->
        <!--    </tr>-->
        <tr>
            <td class="center">'22</td>
            <td>Stress testing a clinical decision instrument performance for intra-abdominal injury
            </td>
            <td>kornblith*, singh* et al.</td>
            <td class="med">🔎🌳💊</td>
            <td class="center"><a
                    href="https://journals.plos.org/digitalhealth/article?id=10.1371/journal.pdig.0000076">PLOS digital
                    health</a></td>
            <td class="big"><a href="https://github.com/csinva/iai-clinical-decision-rule"><i
                        class="fa fa-github fa-fw"></i></a></td>
            <td class="med">
                <a href="https://docs.google.com/presentation/d/1mxzGE0MkNZnzbIimDP8Kyq8oLfVSmHrOCKDPhiBPMz4/"><i
                        class="fa fa-desktop fa-fw"></i></a>
            </td>
        </tr>
        <tr>
            <td class="center">'22</td>
            <td>Fast interpretable greedy-tree sums (FIGS)</td>
            <td>tan*, singh*, nasseri, agarwal, & yu</td>
            <td class="med">🔎🌳</td>
            <td class="center"><a href="https://arxiv.org/abs/2201.11931">arxiv</a></td>
            <!--            <td></td>-->
            <td class="big"><a href="https://github.com/csinva/imodels"><i class="fa fa-github fa-fw"></i></a>
            </td>
            <td class="med">
                <a href="https://docs.google.com/presentation/d/1Gk5mEcSp6uePS72q-oF-GhXgLSbHfq2jWqMTKfwDaJw/"><i
                        class="fa fa-desktop fa-fw"></i></a>
                <a href="https://csinva.io/imodels/figs.html"><i class="fa fa-home fa-fw"></i></a>
            </td>
        </tr>
        <tr>
            <td class="center">'22</td>
            <td>Hierarchical shrinkage for trees</td>
            <td>agarwal*, tan*, ronen, singh, & yu</td>
            <td class="med">🔎🌳</td>
            <td class="center"><a href="https://arxiv.org/abs/2202.00858">icml (spotlight)</a></td>
            <!--            <td></td>-->
            <td class="big"><a href="https://github.com/csinva/imodels"><i class="fa fa-github fa-fw"></i></a>
            </td>
            <td class="med">
                <a href="https://docs.google.com/presentation/d/1inyZnryrs6dNO6VCn7ng6Rjc-XCkuagxx9YVHKJWqrM/"><i
                        class="fa fa-desktop fa-fw"></i></a>
                <a href="https://csinva.io/imodels/shrinkage.html"><i class="fa fa-home fa-fw"></i></a>
                <!--            <a href="https://docs.google.com/presentation/d/1ReJ3Lqh4VZqpu6X6sP47f6Re6PvLIX9ZRAdjb8ZhFXE/present?slide=id.p"><i-->
                <!--                    class="fa fa-desktop fa-fw"></i></a>-->
            </td>
        </tr>
        <tr>
            <td class="center">'22</td>
            <td>VeridicalFlow: a python package for building trustworthy data science pipelines with PCS</td>
            <td>duncan*, kapoor*, agarwal*, singh*, & yu</td>
            <td class="med">💻🔍</td>
            <td class="center"><a href="https://joss.theoj.org/papers/10.21105/joss.03895">joss</a></td>
            <!--            <td></td>-->
            <td class="big"><a href="https://github.com/Yu-Group/veridical-flow"><i class="fa fa-github fa-fw"></i></a>
            </td>
            <td class="med">
                <a href="https://docs.google.com/presentation/d/1ReJ3Lqh4VZqpu6X6sP47f6Re6PvLIX9ZRAdjb8ZhFXE/"><i
                        class="fa fa-desktop fa-fw"></i></a>
            </td>
        </tr>
        <tr>
            <td class="center">'21</td>
            <td>imodels: a python package for fitting interpretable models</td>
            <td>singh*, nasseri*, et al.</td>
            <td class="med">💻🔍🌳</td>
            <td class="center"><a href="https://joss.theoj.org/papers/10.21105/joss.03192">joss</a></td>
            <!--            <td></td>-->
            <td class="big"><a href="https://github.com/csinva/imodels"><i class="fa fa-github fa-fw"></i></a>
            </td>
            <td class="med">
                <a href="https://docs.google.com/presentation/d/1fpHo-MtIJntlIrYlQj0yK3spJ7Unf10CNTH-PG9LQ_A/"><i
                        class="fa fa-desktop fa-fw"></i></a>
                <a href="https://bair.berkeley.edu/blog/2022/02/02/imodels/"><i class="fa fa-home fa-fw"></i></a>
            </td>
        </tr>
        <tr>
            <td class="center">'21</td>
            <td>Adaptive wavelet distillation from neural networks through interpretations</td>
            <td>ha, singh, et al.</td>
            <td class="med">🔍🌀🌳</td>
            <td class="center"><a href="https://arxiv.org/abs/2107.09145">neurips</a></td>
            <!--            <td></td>-->
            <td class="big"><a href="https://github.com/Yu-Group/adaptive-wavelet-distillation"><i
                        class="fa fa-github fa-fw"></i></a>
            </td>
            <td class="med">
                <a href="https://docs.google.com/presentation/d/1YrzAir94D0KWewau34dZAXXPdATRuqeVf8Jt-o_wqG8/"><i
                        class="fa fa-desktop fa-fw"></i></a>
                <a href="https://bair.berkeley.edu/blog/2021/09/28/wavelet/"><i class="fa fa-home fa-fw"></i></a>
            </td>
        </tr>
        <tr>
            <td class="center">'21</td>
            <td>Matched sample selection with GANs for mitigating attribute confounding</td>
            <td>singh, balakrishnan, & perona</td>
            <td class="med">🌀</td>
            <td class="center"><a href="https://arxiv.org/abs/2103.13455">cvpr workshop</a></td>
            <!--            <td></td>-->
            <td class="big"><a href="https://github.com/csinva/matching-with-gans"><i
                        class="fa fa-github fa-fw"></i></a>
            </td>
            <td class="med">
                <a href="https://docs.google.com/presentation/d/19Z4TnHCDkNENutyKmE_kZBSJX4jMUam6DoH3HckkMrI/"><i
                        class="fa fa-desktop fa-fw"></i></a>
            </td>
        </tr>
        <tr>
            <td class="center">'21</td>
            <td>Revisiting complexity and the bias-variance tradeoff</td>
            <td>dwivedi*, singh*, yu & wainwright</td>
            <td class="med">🌀</td>
            <td class="center"><a href="https://jmlr.org/papers/volume24/21-1133/21-1133.pdf">jmlr</a></td>
            <td class="big"><a href="https://github.com/csinva/mdl-complexity"><i class="fa fa-github fa-fw"></i></a>
            </td>
            <td class="med">
                <a href="https://drive.google.com/file/d/15hzAndJYNO3YsflL_RyB-4nQb2_KypK-/view?usp=sharing"><i
                        class="fa fa-desktop fa-fw"></i></a>
            </td>
        </tr>
        <tr>
            <td class="center">'20</td>
            <td>Curating a COVID-19 data repository and forecasting county-level death counts in the United States</td>
            <td>altieri et al.</td>
            <td class="med">🔎🦠</td>
            <td class="center"><a href="https://arxiv.org/abs/2005.07882">hdsr</a></td>
            <td class="big"><a href="https://github.com/Yu-Group/covid19-severity-prediction"><i
                        class="fa fa-github fa-fw"></i></a></td>
            <td class="med">
                <a href="https://docs.google.com/presentation/d/1nAYfBHj9qP-Qzpjho4dyMTx2Bc5Pccxu1VqIFiEaeYg/"><i
                        class="fa fa-desktop fa-fw"></i></a>
                <a href="https://covidseverity.com/"><i class="fa fa-home fa-fw"></i></a>
            </td>
        </tr>
        <tr>
            <td class="center">'20</td>
            <td>Transformation importance with applications to cosmology</td>
            <td>singh*, ha*, lanusse, boehm, liu & yu</td>
            <td class="med">🔎🌀🌌</td>
            <td class="center"><a href="https://arxiv.org/abs/2003.01926">iclr workshop (spotlight)</a></td>
            <td class="big"><a href="https://github.com/csinva/transformation-importance"><i
                        class="fa fa-github fa-fw"></i></a>
            </td>
            <td class="med"><a
                    href="https://docs.google.com/presentation/d/1mH1uG38qJg-ar0G-LiVPZWNKPO_2GiD-uayWM5AI-bo/"><i
                        class="fa fa-desktop fa-fw"></i></a></td>
        </tr>
        <tr>
            <td class="center">'20</td>
            <td>Interpretations are useful: penalizing explanations to align neural networks with prior knowledge</td>
            <td>rieger, singh, murdoch & yu</td>
            <td class="med">🔎🌀</td>
            <td class="center"><a href="http://proceedings.mlr.press/v119/rieger20a.html">icml</a>
            </td>
            <td class="big"><a href="https://github.com/laura-rieger/deep-explanation-penalization"><i
                        class="fa fa-github fa-fw"></i></a></td>
            <td class="med"><a href="https://icml.cc/virtual/2020/poster/5914"><i class="fa fa-desktop fa-fw"></i></a>
            </td>
        </tr>
        <tr>
            <td class="center">'19</td>
            <td>Hierarchical interpretations for neural network predictions</td>
            <td>Singh*, Murdoch*, & Yu</td>
            <td class="med">🔍🌀</td>
            <td class="center"><a href="https://arxiv.org/abs/1806.05337">ICLR</a></td>
            <td class="big"><a href="https://github.com/csinva/acd"><i class="fa fa-github fa-fw"></i></a></td>
            <td class="med"><a
                    href="https://docs.google.com/presentation/d/1I6djTqVn6YGKqxvQk59-4C39LbE68mNQbX1Go5pzTH4/"><i
                        class="fa fa-desktop fa-fw"></i></a>
                <!--            <a href="{{site.baseurl}}/assets/write_ups/acd_18_bairday_poster.pdf"><i class="fa fa-picture-o fa-fw"></i></a>-->
            </td>
        </tr>
        <tr>
            <td class="center">'19</td>
            <td>interpretable machine learning: definitions, methods, and applications</td>
            <td>Murdoch*, Singh*, et al.</td>
            <td class="med">🔍🌳🌀</td>
            <td class="center"><a href="https://arxiv.org/abs/1901.04592">pnas</a></td>
            <td></td>
            <td class="med"><a
                    href="https://docs.google.com/presentation/d/13jbgFyYSSDaMUd2w4RY9GHteTcWJj1drS6_2sOkvnv4/"><i
                        class="fa fa-desktop fa-fw"></i></a>
                <!--            <a  href="{{site.baseurl}}/assets/write_ups/utokyo_19_interp_poster.pdf"><i  class="fa fa-picture-o fa-fw"></i></a></td>-->
        </tr>
        <tr>
            <td class="center">'19</td>
            <td>disentangled attribution curves for interpreting random forests and boosted trees</td>
            <td>devlin, singh, murdoch & yu</td>
            <td class="med">🔍🌳</td>
            <td class="center"><a href="https://arxiv.org/abs/1905.07631">arxiv</a></td>
            <td class="big"><a href="https://github.com/csinva/disentangled_attribution_curves"><i
                        class="fa fa-github fa-fw"></i></a></td>
            <td></td>
        </tr>
        <tr>
            <td class="center">'18</td>
            <td>large scale image segmentation with structured loss based deep learning for connectome reconstruction
            </td>
            <td>Funke*, Tschopp*, et al.</td>
            <td class="med">🧠🌀</td>
            <td class="center"><a href="https://ieeexplore.ieee.org/abstract/document/8364622/">TPAMI</a></td>
            <td class="big"><a href="https://github.com/funkey/mala"><i class="fa fa-github fa-fw"></i></a></td>
            <td class="med">
                <a href="{{site.baseurl}}/assets/write_ups/singh_15_rf_segmentation.pdf"><i
                        class="fa fa-picture-o fa-fw"></i></a>
            </td>
        </tr>
        <tr>
            <td class="center">'18</td>
            <td>linearization of excitatory synaptic integration at no extra cost</td>
            <td>Morel, Singh, & Levy</td>
            <td class="med">🧠</td>
            <td class="center"><a href="http://rdcu.be/FDUo">J Comp Neuro</a></td>
            <td class="big"><a href="https://senselab.med.yale.edu/modeldb/ShowModel.cshtml?model=237594"><i
                        class="fa fa-github fa-fw"></i></a></td>
            <td class="med"><a
                    href="https://docs.google.com/presentation/d/1JriXXofysuXyfU4CeyNHJUTYSfa18R9Q3EhkCwFwh4g/"><i
                        class="fa fa-desktop fa-fw"></i></a></td>
        </tr>
        <tr>
            <td class="center">'17</td>
            <td>a consensus layer V pyramidal neuron can sustain interpulse-interval coding</td>
            <td>Singh & Levy</td>
            <td class="med">🧠</td>
            <td class="center"><a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0180839">Plos
                    One</a></td>
            <td class="big"><a href="https://senselab.med.yale.edu/modeldb/ShowModel.cshtml?model=237594"><i
                        class="fa fa-github fa-fw"></i></a></td>
            <td class="med"><a
                    href="https://docs.google.com/presentation/d/1JriXXofysuXyfU4CeyNHJUTYSfa18R9Q3EhkCwFwh4g/"><i
                        class="fa fa-desktop fa-fw"></i></a></td>
        </tr>
        <tr>
            <td class="center">'17</td>
            <td>a constrained, weighted-l1 minimization approach for joint discovery of heterogeneous neural
                connectivity
                graphs
            </td>
            <td>Singh, Wang, & Qi</td>
            <td class="med">🧠</td>
            <td class="center"><a href="https://arxiv.org/abs/1709.04090">neurips Workshop</a></td>
            <td class="big"><a href="https://cran.r-project.org/web/packages/simule/index.html"><i
                        class="fa fa-github fa-fw"></i></a></td>
            <td class="med"><a
                    href="https://docs.google.com/presentation/d/1GO6lN5o2idozOUdnObXGnXKFbZiJiKKKkmx73uE4BAI/"><i
                        class="fa fa-desktop fa-fw"></i></a>,
                <!--            <a-->
                <!--                href="{{site.baseurl}}/assets/write_ups/wsimule_17_nips_poster.pdf"><i-->
                <!--                class="fa fa-picture-o fa-fw"></i></a>-->
            </td>
        </tr>
    </tbody>

</table>

<style>
    .big {
        font-size: large;
        text-align: center;
    }

    .med {
        font-size: medium;
        text-align: center;
    }

    td {
        text-align: left;
    }

    .center {
        text-align: center;
    }

    .dt-button span {
        color: white;
        font-family: Lora, "Helvetica Neue", Helvetica, Arial, sans-serif;
    }

    .dt-button {
        border-color: rgb(141, 141, 141) !important;
    }

    .dt-button:hover {
        border: 2px solid #5bc0de !important;
    }
</style>