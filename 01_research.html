---
layout: null
section-type: research
title: Research
---
## Research

<table>
    <tr>
        <th>
            <strong style="font-size:21px;"> interpretable ml </strong> <br/>
            <a href="/blog/research/interp"> what is interpretability? </a> <br/>
            <a href="/blog/research/interp_eval"> evaluating interpretability </a>
        </th>
<!--        <th><strong style="font-size:21px;"> interpretability applications </strong></th>-->
        <th>
            <strong style="font-size:21px;"> science </strong> <br/>
            <a href="/blog/research/connectomics"> Connectomics</a> <br/>
            <a href="/blog/research/neural_coding" > neural coding </a>
        </th>
<!--        <th>-->
<!--            <strong style="font-size:21px;"> ml theory </strong>-->
<!--        </th>-->
    </tr>
    <tr>
        <th><br/></th>
    </tr>
    <tr>
        <th><img src="{{ site.baseurl }}/assets/img/alexnet.png" class="research_thumb"></th>
<!--        <th><img src="{{ site.baseurl }}/assets/img/cosmo.png" class="research_thumb"></th>-->
        <th><img src="{{ site.baseurl }}/assets/img/neuron.gif" class="research_thumb"></th>
<!--        <th><img src="{{ site.baseurl }}/assets/img/complexity.png" class="research_thumb"></th>-->
    </tr>
</table>

<br/>
<br/>

<table id="example" class="display" style="width:100%">
    <thead>
        <tr>
            <th>year</th>
            <th>title</th>
            <th>authors</th>
            <th>tags</th>
            <th>paper</th>
            <th>code</th>
            <th>slides</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>2020</td>
            <td>transformation importance with applications to cosmology</td>
            <td>singh*, ha*, lanusse, boehm, liu & yu</td>
            <td>ml</td>
            <td><a href="https://arxiv.org/abs/2003.01926">iclr workshop (spotlight talk)</a></td>
            <td><a href="https://github.com/csinva/transformation-importance"><i class="fa fa-github fa-fw"></i></a></td>
            <td><a href="https://docs.google.com/presentation/d/1mH1uG38qJg-ar0G-LiVPZWNKPO_2GiD-uayWM5AI-bo/present?slide=id.p"><i class="fa fa-desktop fa-fw"></i></a>, <a href="{{site.baseurl}}/assets/write_ups/acd_18_bairday_poster.pdf"><i class="fa fa-picture-o fa-fw"></i></a></td>
        </tr>
        <tr>
            <td>2019</td>
            <td>interpretations are useful: penalizing explanations to align neural networks with prior knowledge</td>
            <td>rieger, singh, murdoch & yu</td>
            <td>ml</td>
            <td><a href="https://arxiv.org/abs/1909.13584">arxiv</a></td>
            <td><a href="https://github.com/laura-rieger/deep-explanation-penalization"><i class="fa fa-github fa-fw"></i></a></td>
            <td>--</td>
        </tr>
        <tr>
            <td>2019</td>
            <td>disentangled attribution curves for interpreting random forests and boosted trees</td>
            <td>devlin, singh, murdoch & yu</td>
            <td>ml</td>
            <td><a href="https://arxiv.org/abs/1905.07631">arxiv</a></td>
            <td><a href="https://github.com/csinva/disentangled_attribution_curves"><i class="fa fa-github fa-fw"></i></a></td>
            <td>--</td>
        </tr>
        <tr>
            <td>2019</td>
            <td>interpretable machine learning: definitions, methods, and applications</td>
            <td>Murdoch*, Singh*, Kumbier, Abbasi-Asl, & Yu</td>
            <td>ml</td>
            <td><a href="https://arxiv.org/abs/1901.04592">pnas</a></td>
            <td>--</td>
            <td><a href="https://docs.google.com/presentation/d/13jbgFyYSSDaMUd2w4RY9GHteTcWJj1drS6_2sOkvnv4/present?slide=id.p"><i class="fa fa-desktop fa-fw"></i></a>, <a href="{{site.baseurl}}/assets/write_ups/utokyo_19_interp_poster.pdf"><i class="fa fa-picture-o fa-fw"></i></a></td>
        </tr>
        <tr>
            <td>2019</td>
            <td>hierarchical interpretations for neural network predictions</td>
            <td>Singh*, Murdoch*, & Yu</td>
            <td>ml</td>
            <td><a href="https://arxiv.org/abs/1806.05337">ICLR</a></td>
            <td><a href="https://github.com/csinva/acd"><i class="fa fa-github fa-fw"></i></a></td>
            <td><a href="https://docs.google.com/presentation/d/1I6djTqVn6YGKqxvQk59-4C39LbE68mNQbX1Go5pzTH4/present?slide=id.p"><i class="fa fa-desktop fa-fw"></i></a>, <a href="{{site.baseurl}}/assets/write_ups/acd_18_bairday_poster.pdf"><i class="fa fa-picture-o fa-fw"></i></a></td>
        </tr>
        <tr>
            <td>2018</td>
            <td>large scale image segmentation with structured loss based deep learning for connectome reconstruction</td>
            <td>Funke*, Tschopp*, Grisaitis, Sheridan, Singh, Saalfeld, & Turaga</td>
            <td>ml, neuro</td>
            <td><a href="https://ieeexplore.ieee.org/abstract/document/8364622/">TPAMI</a></td>
            <td><a href="https://github.com/funkey/mala"><i class="fa fa-github fa-fw"></i></a></td>
            <td><a href="{{site.baseurl}}/assets/write_ups/singh_15_rf_segmentation.pdf"><i class="fa fa-picture-o fa-fw"></i></a></td>
        </tr>
       <tr>
            <td>2018</td>
            <td>linearization of excitatory synaptic integration at no extra cost</td>
            <td>Morel, Singh, & Levy</td>
            <td>neuro</td>
            <td><a href="http://rdcu.be/FDUo">J Comp Neuro</a></td>
           <td><a href="https://senselab.med.yale.edu/modeldb/ShowModel.cshtml?model=237594"><i class="fa fa-github fa-fw"></i></a></td>
           <td><a href="https://docs.google.com/presentation/d/1JriXXofysuXyfU4CeyNHJUTYSfa18R9Q3EhkCwFwh4g/present?slide=id.p"><i class="fa fa-desktop fa-fw"></i></a></td>
        </tr>
       <tr>
            <td>2017</td>
            <td>a consensus layer V pyramidal neuron can sustain interpulse-interval coding</td>
            <td>Singh & Levy</td>
            <td>neuro</td>
            <td><a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0180839">Plos One</a></td>
            <td><a href="https://senselab.med.yale.edu/modeldb/ShowModel.cshtml?model=237594"><i class="fa fa-github fa-fw"></i></a></td>
            <td><a href="https://docs.google.com/presentation/d/1JriXXofysuXyfU4CeyNHJUTYSfa18R9Q3EhkCwFwh4g/present?slide=id.p"><i class="fa fa-desktop fa-fw"></i></a></td>
        </tr>
       <tr>
            <td>2017</td>
            <td>a constrained, weighted-l1 minimization approach for joint discovery of heterogeneous neural connectivity graphs</td>
            <td>Singh, Wang, & Qi</td>
            <td>ml, neuro</td>
            <td><a href="https://arxiv.org/abs/1709.04090">neurips Workshop</a></td>
           <td><a href="https://cran.r-project.org/web/packages/simule/index.html"><i class="fa fa-github fa-fw"></i></a></td>
           <td><a href="https://docs.google.com/presentation/d/1GO6lN5o2idozOUdnObXGnXKFbZiJiKKKkmx73uE4BAI/present?slide=id.p4"><i class="fa fa-desktop fa-fw"></i></a>, <a href="{{site.baseurl}}/assets/write_ups/wsimule_17_nips_poster.pdf"><i class="fa fa-picture-o fa-fw"></i></a></td>
        </tr>
    </tbody>

</table>

<style>
.research_thumb {
    width: 50%; /* 90% */
    border-radius: 50%;
    border: 1px solid #f1f1f1;
}
</style>