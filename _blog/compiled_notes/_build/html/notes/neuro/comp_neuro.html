
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>5.5. comp neuro</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notes/neuro/comp_neuro';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="5.6. disease" href="disease.html" />
    <link rel="prev" title="5.4. sensory input" href="sensory_input.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.png" class="logo__image only-light" alt=" - Home"/>
    <script>document.write(`<img src="../../_static/logo.png" class="logo__image only-dark" alt=" - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    overview 👋
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../ai/ai.html">1. ai</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../ai/knowledge_rep.html">1.1. representations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ai/psychology.html">1.2. psychology</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ai/fairness_sts.html">1.3. fairness, sts</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ai/philosophy.html">1.4. philosophy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ai/ai_futures.html">1.5. ai futures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ai/cogsci.html">1.6. cognitive science</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ai/llms.html">1.7. llms</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ai/logic.html">1.8. logic</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ai/search.html">1.9. search</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ai/decisions_rl.html">1.10. decisions, rl</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../math/math.html">2. math</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../math/linear_algebra.html">2.1. linear algebra</a></li>
<li class="toctree-l2"><a class="reference internal" href="../math/optimization.html">2.2. optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../math/differential_equations.html">2.3. differential equations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../math/chaos.html">2.4. chaos</a></li>
<li class="toctree-l2"><a class="reference internal" href="../math/math_basics.html">2.5. math basics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../math/signals.html">2.6. signals</a></li>
<li class="toctree-l2"><a class="reference internal" href="../math/calculus.html">2.7. calculus</a></li>
<li class="toctree-l2"><a class="reference internal" href="../math/proofs.html">2.8. proofs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../math/analysis.html">2.9. real analysis</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../ml/ml.html">3. ml</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../ml/unsupervised.html">3.1. unsupervised</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ml/structure_ml.html">3.2. structure learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ml/learning_theory.html">3.3. learning theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ml/deep_learning.html">3.4. deep learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ml/comp_vision.html">3.5. computer vision</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ml/kernels.html">3.6. kernels</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ml/nlp.html">3.7. nlp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ml/feature_selection.html">3.8. feature selection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ml/evaluation.html">3.9. evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ml/classification.html">3.10. classification</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../stat/stat.html">4. stat</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../stat/time_series.html">4.1. time series</a></li>
<li class="toctree-l2"><a class="reference internal" href="../stat/graphical_models.html">4.2. graphical models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../stat/causal_inference.html">4.3. causal inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../stat/game_theory.html">4.4. game theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../stat/info_theory.html">4.5. info theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../stat/linear_models.html">4.6. linear models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../stat/data_analysis.html">4.7. data analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../stat/testing.html">4.8. testing</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="neuro.html">5. neuro</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="motor.html">5.1. motor system</a></li>
<li class="toctree-l2"><a class="reference internal" href="memory.html">5.2. memory</a></li>
<li class="toctree-l2"><a class="reference internal" href="development.html">5.3. development</a></li>
<li class="toctree-l2"><a class="reference internal" href="sensory_input.html">5.4. sensory input</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">5.5. comp neuro</a></li>
<li class="toctree-l2"><a class="reference internal" href="disease.html">5.6. disease</a></li>
<li class="toctree-l2"><a class="reference internal" href="vissci.html">5.7. vision</a></li>
<li class="toctree-l2"><a class="reference internal" href="brain_basics.html">5.8. brain basics</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cs/cs.html">6. cs</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../cs/comp_theory.html">6.1. cs theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cs/graphs.html">6.2. graphs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cs/retrieval.html">6.3. info retrieval</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cs/data_structures.html">6.4. data structures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cs/os.html">6.5. os</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cs/quantum.html">6.6. quantum</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cs/software.html">6.7. software engineering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cs/algo.html">6.8. algorithms</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cs/arch.html">6.9. architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cs/languages.html">6.10. languages</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cs/reproducibility.html">6.11. reproducibility</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../research_ovws/research_ovws.html">7. research_ovws</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../research_ovws/ovw_disentanglement.html">7.1. disentanglement</a></li>
<li class="toctree-l2"><a class="reference internal" href="../research_ovws/ovw_uncertainty.html">7.2. uncertainty</a></li>
<li class="toctree-l2"><a class="reference internal" href="../research_ovws/ovw_generalization.html">7.3. generalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../research_ovws/ovw_causal_inference.html">7.4. causal inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../research_ovws/ovw_omics.html">7.5. omics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../research_ovws/ovw_ml_medicine.html">7.6. ml in medicine</a></li>
<li class="toctree-l2"><a class="reference internal" href="../research_ovws/ovw_llms.html">7.7. llms</a></li>
<li class="toctree-l2"><a class="reference internal" href="../research_ovws/ovw_transfer_learning.html">7.8. transfer learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../research_ovws/ovw_interp.html">7.9. interpretability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../research_ovws/ovw_complexity.html">7.10. complexity</a></li>
<li class="toctree-l2"><a class="reference internal" href="../research_ovws/ovw_dl_theory.html">7.11. dl theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../research_ovws/ovw_scat.html">7.12. scattering transform</a></li>
<li class="toctree-l2"><a class="reference internal" href="../research_ovws/ovw_interesting_science.html">7.13. interesting science</a></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/csinva/csinva.github.io" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/notes/neuro/comp_neuro.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>comp neuro</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">5.5.1. introduction</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#overview">5.5.1.1. overview</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#history">5.5.1.2. history</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#types-of-models">5.5.1.3. types of models</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#biophysical-models">5.5.2. biophysical models</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#modeling-neurons">5.5.2.1. modeling neurons</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simplified-model-neurons">5.5.2.2. simplified model neurons</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#modeling-dendrites-axons">5.5.2.3. modeling dendrites / axons</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#circuit-modeling-basics">5.5.2.4. circuit-modeling basics</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#action-potentials">5.5.2.5. action potentials</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#physics-of-computation">5.5.2.6. physics of computation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#spiking-neurons">5.5.2.7. spiking neurons</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#neural-coding">5.5.3. neural coding</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#neural-encoding">5.5.3.1. neural encoding</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#neural-decoding">5.5.3.2. neural decoding</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#information-theory">5.5.3.3. information theory</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#computing-with-networks">5.5.4. computing with networks</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#modeling-connections-between-neurons">5.5.4.1. modeling connections between neurons</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#intro-to-network-models">5.5.4.2. intro to network models</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#recurrent-networks">5.5.4.3. recurrent networks</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hopfield-nets">5.5.4.4. hopfield nets</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#learning">5.5.5. learning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#supervised-learning">5.5.5.1. supervised learning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#unsupervised-learning">5.5.5.2. unsupervised learning</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#hebbian-learning-and-pca">5.5.5.2.1. hebbian learning and pca</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#synaptic-plasticity-hebb-s-rule-and-statistical-learning">5.5.5.3. synaptic plasticity, hebb’s rule, and statistical learning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tensor-product-representation-tpr">5.5.5.4. tensor product representation (TPR)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sparse-coding-and-predictive-coding">5.5.5.5. sparse coding and predictive coding</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sparse-distributed-coding">5.5.5.6. sparse, distributed coding</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#self-organizing-maps-kohonen-maps">5.5.5.7. self-organizing maps = kohonen maps</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#probabilistic-models-inference">5.5.6. probabilistic models + inference</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#boltzmann-machines">5.5.6.1. boltzmann machines</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-driven-neuroscience">5.5.7. data-driven neuroscience</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-types">5.5.7.1. data types</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interventions">5.5.7.2. interventions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#datasets">5.5.7.3. datasets</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#language">5.5.7.3.1. language</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#misc">5.5.7.3.2. misc</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#eeg">5.5.7.4. eeg</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cross-subject-modeling">5.5.7.5. cross-subject modeling</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fmri">5.5.8. fMRI</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">5.5.8.1. language</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#semantic-decoding">5.5.8.2. semantic decoding</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#theories-of-explanation">5.5.8.3. theories of explanation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#speech-ecog">5.5.8.4. speech / ECoG</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#advanced-topics">5.5.9. advanced topics</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#high-dimensional-hyperdimensional-computing">5.5.9.1. high-dimensional (hyperdimensional) computing</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dynamic-routing-between-capsules">5.5.9.2. dynamic routing between capsules</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hierarchical-temporal-memory-htm-numenta">5.5.9.3. hierarchical temporal memory (htm, numenta)</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#necortical-structure">5.5.9.3.1. necortical structure</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#principles">5.5.9.3.2. principles</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#papers">5.5.9.3.3. papers</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#forgetting">5.5.9.4. forgetting</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#maximal-exciting-inputs">5.5.9.5. maximal exciting inputs</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#population-coding">5.5.9.6. population coding</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interesting-misc-papers">5.5.9.7. interesting misc papers</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#navigation">5.5.9.8. navigation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#neuromorphic-computing">5.5.9.9. neuromorphic computing</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#locality-sensitive-hashing">5.5.9.10. locality sensitive hashing</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#neuro-inspired-ai-niai">5.5.10. neuro-inspired ai (niAI)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#neuro-dl-reviews">5.5.10.1. neuro-dl reviews</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#credit-assignment">5.5.10.2. credit assignment</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#biological-constraints-for-dnns">5.5.10.3. biological constraints for DNNs</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">5.5.10.4. overview</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="comp-neuro">
<h1><span class="section-number">5.5. </span>comp neuro<a class="headerlink" href="#comp-neuro" title="Link to this heading">#</a></h1>
<section id="introduction">
<h2><span class="section-number">5.5.1. </span>introduction<a class="headerlink" href="#introduction" title="Link to this heading">#</a></h2>
<section id="overview">
<h3><span class="section-number">5.5.1.1. </span>overview<a class="headerlink" href="#overview" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>lacking: insight from neuro that can help build machine</p></li>
<li><p>scales: cortex, column, neuron, synapses</p></li>
<li><p>physics: theory and practice are much closer</p></li>
<li><p>are there principles?</p>
<ul>
<li><p>“god is a hacker” - francis crick</p></li>
<li><p>theorists are lazy - ramon y cajal</p></li>
<li><p>things seemed like mush but became more clear - horace barlow</p></li>
</ul>
</li>
</ul>
</section>
<section id="history">
<h3><span class="section-number">5.5.1.2. </span>history<a class="headerlink" href="#history" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>ai</p>
<ul>
<li><p>people: turing, von neumman, marvin minsky, mccarthy…</p></li>
<li><p>ai: birth at 1956 conference</p>
<ul>
<li><p>vision: marvin minsky thought it would be a summer project</p></li>
</ul>
</li>
<li><p>lighthill debate 1973 - was ai worth funding?</p></li>
<li><p>intelligence tends to be developed by young children</p></li>
<li><p>cortex grew very rapidly</p></li>
</ul>
</li>
<li><p>cybernetics / artficial neuro nets</p>
<ul>
<li><p>people: norbert weiner, mcculloch &amp; pitts, rosenblatt</p></li>
<li><p>neuro</p>
<ul>
<li><p>hubel &amp; weisel (1962, 1965) simple, complex, hypercomplex cells</p></li>
<li><p>neocognitron fukushima (1980)</p></li>
<li><p>david marr: theory, representation, implementation</p></li>
<li><p>felleman &amp; van essen (1991)</p>
<ul>
<li><p>ascending layers (e.g. v1-&gt; v2): goes from superficial to deep layers</p></li>
<li><p>descending layers (e.g. v2 -&gt; v1): deep layers to superficial</p></li>
</ul>
</li>
<li><p>solari &amp; stoner (2011) “cognitive consilience” - layers thicknesses change in different parts of the brain</p>
<ul>
<li><p>motor cortex has much smaller input (layer 4), since it is mostly output</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</section>
<section id="types-of-models">
<h3><span class="section-number">5.5.1.3. </span>types of models<a class="headerlink" href="#types-of-models" title="Link to this heading">#</a></h3>
<ul>
<li><p>three types</p>
<ol class="arabic simple">
<li><p><em>descriptive</em> brain model - encode / decode external stimuli</p></li>
<li><p><em>mechanistic</em> brian cell / network model - simulate the behavior of a single neuron / network</p></li>
<li><p><em>interpretive</em> (or normative) brain model - why do brain circuits operate how they do</p></li>
</ol>
</li>
<li><p><em>receptive field</em> - the things that make a neuron fire</p>
<ul class="simple">
<li><p>retina has on-center / off-surround cells - stimulated by points</p></li>
<li><p>then, V1 has differently shaped receptive fields</p></li>
</ul>
</li>
<li><p><em>efficient coding hypothesis</em> - brain learns different combinations (e.g. lines) that can efficiently represent images</p>
<ol class="arabic simple">
<li><p>sparse coding (Olshausen and Field, 1996)</p></li>
<li><p>ICA (Bell and Sejnowski, 1997)</p></li>
<li><p>predictive coding (Rao and Ballard, 1999)</p></li>
</ol>
<ul class="simple">
<li><p>brain is trying to learn faithful and efficient representations of an animal’s natural environment</p></li>
</ul>
</li>
</ul>
</section>
</section>
<section id="biophysical-models">
<h2><span class="section-number">5.5.2. </span>biophysical models<a class="headerlink" href="#biophysical-models" title="Link to this heading">#</a></h2>
<section id="modeling-neurons">
<h3><span class="section-number">5.5.2.1. </span>modeling neurons<a class="headerlink" href="#modeling-neurons" title="Link to this heading">#</a></h3>
<ul>
<li><p>membrane can be treated as a simple circuit, with a capacitor and resistor</p></li>
<li><p>nernst battery</p>
<ol class="arabic simple">
<li><p>osmosis (for each ion)</p></li>
<li><p>electrostatic forces (for each ion)</p></li>
</ol>
<ul class="simple">
<li><p>together these yield Nernst potential <span class="math notranslate nohighlight">\(E = \frac{k_B T}{zq} ln \frac{[in]}{[out]}\)</span></p>
<ul>
<li><p>T is temp</p></li>
<li><p>q is ionic charge</p></li>
<li><p>z is num charges</p></li>
</ul>
</li>
<li><p>part of voltage is accounted for by nernst battery <span class="math notranslate nohighlight">\(V_{rest}\)</span></p></li>
<li><p>yields <span class="math notranslate nohighlight">\(\tau \frac{dV}{dt} = -V + V_\infty\)</span> where <span class="math notranslate nohighlight">\(\tau=R_mC_m=r_mc_m\)</span></p></li>
<li><p>equivalently, <span class="math notranslate nohighlight">\(\tau_m \frac{dV}{dt} = -((V-E_L) - g_s(t)(V-E_s) r_m) + I_e R_m \)</span></p></li>
</ul>
</li>
<li><p><img alt="" src="../../_images/5_1_2.png" /></p></li>
</ul>
</section>
<section id="simplified-model-neurons">
<h3><span class="section-number">5.5.2.2. </span>simplified model neurons<a class="headerlink" href="#simplified-model-neurons" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><em>integrate-and-fire</em> neuron</p>
<ul>
<li><p>passive membrane (neuron charges)</p></li>
<li><p>when <span class="math notranslate nohighlight">\(V = V_{thresh}\)</span>, a spike is fired</p></li>
<li><p>then <span class="math notranslate nohighlight">\(V = V_{reset}\)</span></p></li>
<li><p>approximation is poor near threshold</p></li>
<li><p>can include threshold by saying</p>
<ul>
<li><p>when <span class="math notranslate nohighlight">\(V = V_{max}\)</span>, a spike is fired</p></li>
<li><p>then <span class="math notranslate nohighlight">\(V = V_{reset}\)</span></p></li>
</ul>
</li>
</ul>
</li>
<li><p>modeling multiple variables</p>
<ul>
<li><p>also model a K current</p></li>
<li><p>can capture things like resonance</p></li>
</ul>
</li>
<li><p><em>theta neuron</em> (Ermentrout and Kopell)</p>
<ul>
<li><p><img alt="" src="../../_images/5_3_1.png" /></p></li>
<li><p>often used for periodically firing neurons (it fires spontaneously)</p></li>
</ul>
</li>
</ul>
</section>
<section id="modeling-dendrites-axons">
<h3><span class="section-number">5.5.2.3. </span>modeling dendrites / axons<a class="headerlink" href="#modeling-dendrites-axons" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>cable theory - Kelvin</p></li>
<li><p>voltage V is a function of both x and t</p></li>
<li><p><img alt="" src="../../_images/5_4_1.png" /></p></li>
<li><p>separate into sections that don’t depend on x</p>
<ul>
<li><p>coupling conductances link the sections (based on area of compartments / branching)</p></li>
</ul>
</li>
<li><p>Rall model for dendrites</p>
<ul>
<li><p>if branches obey a certain branching ratio, can replace each pair of branches with a single cable segment with equivalent surface area and electrotonic length</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(d_1^{3/2} = d_{11}^{3/2} + d_{12}^{3/2}\)</span></p></li>
</ul>
</li>
</ul>
</li>
<li><p>dendritic computation (London and Hausser 2005)</p>
<ul>
<li><p>hippocampus - when inputs arrive at soma, similiar shape no matter where they come in = <em>synaptic scaling</em></p></li>
<li><p>where inputs enter influences how they sum</p></li>
<li><p>dendrites can generate spikes (usually calcium) / backpropagating spikes</p></li>
</ul>
</li>
<li><p>ex. <em>Jeffress model</em>  - sound localized based on timing difference between ears</p></li>
<li><p>ex. direction selectivity in retinal ganglion cells - if events arive at dendrite far -&gt; close, all get to soma at same time and add</p></li>
</ul>
</section>
<section id="circuit-modeling-basics">
<h3><span class="section-number">5.5.2.4. </span>circuit-modeling basics<a class="headerlink" href="#circuit-modeling-basics" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>membrane has capacitance <span class="math notranslate nohighlight">\(C_m\)</span></p></li>
<li><p>force for diffusion, force for drift</p></li>
<li><p>can write down diffeq for this, which yields an equilibrium</p></li>
<li><p><span class="math notranslate nohighlight">\(\tau = RC\)</span></p>
<ul>
<li><p>bigger <span class="math notranslate nohighlight">\(\tau\)</span> is slower</p></li>
<li><p>to increase capacitance</p>
<ul>
<li><p>could have larger diameter <span class="math notranslate nohighlight">\(C_m \propto D\)</span></p></li>
</ul>
</li>
<li><p>axial resistance <span class="math notranslate nohighlight">\(R_A \propto 1/D^2\)</span> (not same as membrane leak), thus bigger axons actually charge faster</p></li>
</ul>
</li>
</ul>
</section>
<section id="action-potentials">
<h3><span class="section-number">5.5.2.5. </span>action potentials<a class="headerlink" href="#action-potentials" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>channel/receptor types</p>
<ul>
<li><p>ionotropic: <span class="math notranslate nohighlight">\(G_{ion}\)</span> = f(molecules outside)</p>
<ul>
<li><p>something binds and opens channel</p></li>
</ul>
</li>
<li><p>metabotropic: <span class="math notranslate nohighlight">\(G_{ion}\)</span> = f(molecules inside)</p>
<ul>
<li><p>doesn’t directly open a channel: indirect</p></li>
</ul>
</li>
<li><p>others</p>
<ul>
<li><p>photoreceptor</p></li>
<li><p>hair cell</p></li>
</ul>
</li>
<li><p>voltage-gated (active - provide gain; might not require active ATP, other channels are all passive)</p></li>
</ul>
</li>
</ul>
</section>
<section id="physics-of-computation">
<h3><span class="section-number">5.5.2.6. </span>physics of computation<a class="headerlink" href="#physics-of-computation" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>drift and diffusion are at the heart of everything (based on carver mead)</p></li>
<li><p>Boltzmann distr. models many things (ex. distr of air molecules vs elevation. Subject to gravity and diffusion upwards since they’re colliding)</p>
<ul>
<li><p>nernst potential</p></li>
<li><p>current-voltage relation of voltage-gated channels</p></li>
<li><p>current-voltage relation of MOS transistor</p></li>
</ul>
</li>
<li><p>these things are all like a transistor: energy barrier that must be overcome</p></li>
</ul>
</section>
<section id="spiking-neurons">
<h3><span class="section-number">5.5.2.7. </span>spiking neurons<a class="headerlink" href="#spiking-neurons" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>passive membrane model was leaky integrator</p></li>
<li><p>voltage-gaed channels were more complicated</p></li>
<li><p>can be though of as leaky integrate-and-fire neuron (LIF)</p>
<ul>
<li><p>this charges up and then fires a spike, has refractory period, then starts charging up again</p></li>
</ul>
</li>
<li><p>rate coding hypothesis - signal conveyed is the rate of spiking (some folks think is too simple)</p>
<ul>
<li><p>spiking irregularly is largely due to noise and doesn’t convey information</p></li>
<li><p>some neurons (e.g. neurons in LIP) might actually just convey a rate</p></li>
</ul>
</li>
<li><p>linear-nonlinear-poisson model (LNP) - sometimes called GLM (generalized linear model)</p>
<ul>
<li><p>based on observation that variance in firing rate <span class="math notranslate nohighlight">\(\propto\)</span> mean firing rate</p>
<ul>
<li><p>plotting mean vs variance = 1 <span class="math notranslate nohighlight">\(\implies\)</span> Poisson output</p></li>
</ul>
</li>
<li><p>these led people to model firing rates as Poisson <span class="math notranslate nohighlight">\(\frac {\lambda^n e^{-\lambda}} {n!}\)</span></p></li>
<li><p>bruno doesn’t really believe the firing is random (just an effect of other things we can’t measure)</p></li>
<li><p>ex. fly H1 neuron 1997</p>
<ul>
<li><p>constant stimulus looks very Poisson</p></li>
<li><p>moving stimulus looks very Bernoulli</p></li>
</ul>
</li>
</ul>
</li>
<li><p>spike timing hypothesis</p>
<ul>
<li><p>spike timing can be very precise in response to time-varying signals (mainen &amp; sejnowski 1995; bair &amp; koch 1996)</p></li>
<li><p>often see precise timing</p></li>
</ul>
</li>
<li><p>encoding: stimulus <span class="math notranslate nohighlight">\(\to\)</span> spikes</p></li>
<li><p>decoding: spikes <span class="math notranslate nohighlight">\(\to\)</span> representation</p></li>
<li><p>encoding + decoding are related through the joint distr. over simulus and repsonse (see Bialek spikes book)</p>
<ul>
<li><p>nonlinear encoding function can yield linear decoding</p></li>
<li><p>able to directly decode spikes using a kernel to reproduce signal (seems to say you need spikes - rates would not be good enough)</p>
<ul>
<li><p>some reactions happen too fast to average spikes (e.g. 30 ms)</p></li>
</ul>
</li>
<li><p>estimating information rate: bits (usually better than snr - can calculate between them) - usually 2-3 bits/spike</p></li>
</ul>
</li>
</ul>
</section>
</section>
<section id="neural-coding">
<h2><span class="section-number">5.5.3. </span>neural coding<a class="headerlink" href="#neural-coding" title="Link to this heading">#</a></h2>
<section id="neural-encoding">
<h3><span class="section-number">5.5.3.1. </span>neural encoding<a class="headerlink" href="#neural-encoding" title="Link to this heading">#</a></h3>
<p><strong>defining neural code</strong></p>
<ul class="simple">
<li><p><em>encoding</em>: P(response | stimulus)</p>
<ul>
<li><p><em>tuning curve</em> - neuron’s response (ex. firing rate) as a function of stimulus</p></li>
<li><p>orientation / color selective cells are distributed in organized fashion</p></li>
<li><p>some neurons fire to a concept, like “Pamela Anderson”</p></li>
<li><p>retina (simple) -&gt; V1 (orientations) -&gt; V4 (combinations) -&gt; ?</p></li>
<li><p>also massive feedback</p></li>
</ul>
</li>
<li><p><em>decoding</em>: P(stimulus | response)</p></li>
</ul>
<p><strong>simple encoding</strong></p>
<ul>
<li><p>want P(response | stimulus)</p>
<ul class="simple">
<li><p>response := firing rate r(t)</p></li>
<li><p>stimulus := s</p></li>
</ul>
</li>
<li><p>simple linear model</p>
<ul class="simple">
<li><p>r(t) = c * s(t)</p></li>
</ul>
</li>
<li><p><em>weighted linear model</em> - takes into account previous states weighted by f</p>
<ol class="arabic simple">
<li><p><em>temporal filtering</em></p></li>
</ol>
<ul class="simple">
<li><p>r(t) = <span class="math notranslate nohighlight">\(f_0 \cdot s_0 + ... + f_t \cdot s_t =  \sum s_{t-k} f_k\)</span> where f weights stimulus over time</p></li>
<li><p>could also make this an integral, yielding a convolution:</p></li>
<li><p>r(t) = <span class="math notranslate nohighlight">\(\int_{-\infty}^t d\tau \: s(t-\tau) f(\tau)\)</span></p></li>
<li><p>a linear system can be thought of as a system that searches for portions of the signal that resemble its filter f</p></li>
<li><p>leaky integrator - sums its inputs with f decaying exponentially into the past</p></li>
<li><p>flaws</p>
<ul>
<li><p>no negative firing rates</p></li>
<li><p>no extremely high firing rates</p></li>
<li><p>can add a nonlinear function g of the linear sum can fix this</p>
<ul>
<li><p>r(t) = <span class="math notranslate nohighlight">\(g(\int_{-\infty}^t d\tau \: s(t-\tau) f(\tau))\)</span></p></li>
</ul>
</li>
</ul>
</li>
</ul>
<ol class="arabic simple" start="2">
<li><p><em>spatial filtering</em></p></li>
</ol>
<ul class="simple">
<li><p>r(x,y) = <span class="math notranslate nohighlight">\(\sum_{x',y'} s_{x-x',y-y'} f_{x',y'}\)</span> where f again is spatial weights that represent the spatial field</p></li>
<li><p>could also write this as a convolution</p></li>
<li><p>for a retinal center surround cell, f is positive for small <span class="math notranslate nohighlight">\(\Delta x\)</span> and then negative for large <span class="math notranslate nohighlight">\(\Delta x\)</span></p>
<ul>
<li><p>can be calculated as a narrow, large positive Gaussian + spread out negative Gaussian</p></li>
</ul>
</li>
<li><p>can combine above to make <em>spatiotemporal filtering</em></p>
<ul>
<li><p>filtering = convolution = projection</p></li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>feature selection</strong></p>
<ul class="simple">
<li><p>P(response|stimulus) is very hard to get</p>
<ul>
<li><p>stimulus can be high-dimensional (e.g. video)</p></li>
<li><p>stimulus can take on many values</p></li>
<li><p>need to keep track of stimulus over time</p></li>
<li><p>solution: sample P(response|s) to many stimuli to characterize what in input triggers responses</p></li>
</ul>
</li>
<li><p>find vector <em>f</em> that captures features that lead to spike</p>
<ul>
<li><p>dimensionality reduction - ex. discretize</p></li>
<li><p>value at each time <span class="math notranslate nohighlight">\(t_i\)</span> is new dimension</p></li>
<li><p>commonly use Gaussian white noise</p></li>
<li><p>time step sets cutoff of highest frequency present</p></li>
<li><p><em>prior distribution</em> - distribution of stimulus</p>
<ul>
<li><p>multivariate Gaussian - Gaussian in any dimension, or any linear combination of dimensions</p></li>
</ul>
</li>
<li><p>look at where spike-triggering points are and calculate <em>spike-triggered average</em> <em>f</em> of features that led to spike</p>
<ul>
<li><p>use this f as filter</p></li>
</ul>
</li>
</ul>
</li>
<li><p>determining the nonlinear input/output function <em>g</em></p>
<ul>
<li><p>replace stimulus in P(spike|stimulus) with P(spike|<span class="math notranslate nohighlight">\(s_1\)</span>), where s1 is our filtered stimulus</p>
<ul>
<li><p>use bayes rule <span class="math notranslate nohighlight">\(g=P(spike\|s_1)=\frac{P(s_1\|spike)P(spike)}{P(s_1)}\)</span></p></li>
<li><p>if <span class="math notranslate nohighlight">\(P(s_1\|spike) \approx P(s_1)\)</span> then response doesn’t seem to have to do with stimulus</p></li>
</ul>
</li>
</ul>
</li>
<li><p>incorporating many features <em><span class="math notranslate nohighlight">\(f_1,...,f_n\)</span></em></p>
<ul>
<li><p>here, each <span class="math notranslate nohighlight">\(f_i\)</span> is a vector of weights</p></li>
<li><p><span class="math notranslate nohighlight">\(r(t) = g(f_1\cdot s,f_2 \cdot s,...,f_n \cdot s)\)</span></p></li>
<li><p>could use <em>PCA</em> - discovers low-dimensional structure in high-dimensional data</p></li>
<li><p>each f represents a feature (maybe a curve over time) that fires the neuron</p></li>
</ul>
</li>
</ul>
<p><strong>variability</strong></p>
<ul>
<li><p>hidden assumptions about time-varying firing rate and single spikes</p>
<ul class="simple">
<li><p>smooth function RFT can miss some stimuli</p></li>
</ul>
</li>
<li><p>statistics of stimulus can effect P(spike|stimulus)</p>
<ul class="simple">
<li><p>Gaussian white noise is nice because no way to filter it to get structure</p></li>
</ul>
</li>
<li><p>identifying good filter</p>
<ul class="simple">
<li><p>want <span class="math notranslate nohighlight">\(P(s_f\|spike)\)</span> to differ from <span class="math notranslate nohighlight">\(P(s_f)\)</span> where <span class="math notranslate nohighlight">\(s_f\)</span> is calculated via the filter</p></li>
<li><p>instead of PCA, could look for f that directly maximizes this difference (Sharpee &amp; Bialek, 2004)</p></li>
<li><p><em>Kullback-Leibler divergence</em> - calculates difference between 2 distributions</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(D_{KL}(P(s),Q(s)) = \int ds P(s) log_2 P(s) / Q(s)\)</span></p></li>
</ul>
</li>
<li><p>maximizing KL divergence is equivalent to maximizing mutual info between spike and stimulus</p>
<ul>
<li><p>this is because we are looking for most informative feature</p></li>
<li><p>this technique doesn’t require that our stimulus is white noise, so can use natural stimuli</p></li>
<li><p>maximization isn’t guaranteed to uniquely converge</p></li>
</ul>
</li>
</ul>
</li>
<li><p>modeling the noise</p>
<ul>
<li><p>need to go from r(t) -&gt; spike times</p></li>
<li><p>divide time T into n bins with p = probability of firing per bin</p></li>
<li><p>over some chunk T, number of spikes follows binomial distribution (n, p)</p></li>
<li><p>if n gets very large, binomial approximates Poisson</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\lambda\)</span> = spikes in some set time (mean = <span class="math notranslate nohighlight">\(\lambda\)</span>, var = <span class="math notranslate nohighlight">\(\lambda\)</span>)</p></li>
</ul>
<ol class="arabic simple">
<li><p>can test if distr is Poisson with <em>Fano factor</em>=mean/var=1</p></li>
<li><p>interspike intervals have exponential distribution	- if fires a lot, this can be bad assumption (due to refractory period)</p></li>
</ol>
</li>
</ul>
</li>
<li><p>generalized linear model adds explicit spike-generation / post-spike filter (Pillow et al. 2008)</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(P(\text{spike at }t)\sim\exp((f_1*s + h_1*r)) \)</span></p></li>
<li><p>post-spike filter models refractory period</p></li>
<li><p><em>Paninski</em> showed that using exponential nonlinearity allows this to be optimized</p></li>
<li><p>could add in firing of other neurons</p></li>
<li><p><em>time-rescaling theorem</em> - tests how well we have captured influences on spiking (Brown et al 2001)</p>
<ul>
<li><p>scaled ISIs (<span class="math notranslate nohighlight">\(t_{i-1}-t_i\)</span>) r(t) should be exponential</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</section>
<section id="neural-decoding">
<h3><span class="section-number">5.5.3.2. </span>neural decoding<a class="headerlink" href="#neural-decoding" title="Link to this heading">#</a></h3>
<p><strong>neural decoding and signal detection</strong></p>
<ul class="simple">
<li><p>decoding: P(stimulus | response) - ex. you hear noise and want to tell what it is</p>
<ul>
<li><p>here <span class="math notranslate nohighlight">\(r\)</span> = response = firing rate</p></li>
</ul>
</li>
<li><p>monkey is trained to move eyes in same direction as dot pattern (Britten et al. 92)</p>
<ul>
<li><p>when dots all move in same direction (100% coherence), easy</p>
<ul>
<li><p>neuron recorded in MT - tracks dots</p></li>
<li><p>count firing rate when monkey tracks in right direction</p></li>
<li><p>count firing rate when  monkey tracks in wrong direction</p></li>
<li><p>as coherence decreases, these firing rates blur</p></li>
</ul>
</li>
<li><p>need to get P(+ or - | r)</p>
<ul>
<li><p>can set a threshold on r by maximizing likelihood</p>
<ul>
<li><p>P(r|+) and P(r|-) are likelihoods</p></li>
</ul>
</li>
<li><p><em>Neyman-Pearson lemma</em> - likelihood ratio test is the most efficient statistic, in that is has the most power for a given size</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\frac{p(r\|+)}{p(r\|-)} &gt; 1?\)</span></p></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>accumulated evidence - we can accumulate evidence over time by multiplying these probabilities</p>
<ul>
<li><p>instead we take sum the logs, and compare to 0</p></li>
<li><p><span class="math notranslate nohighlight">\(\sum_i ln \frac{p(r_i\|+)}{p(r_i\|-)} &gt; 0?\)</span></p></li>
<li><p>once we hit some threshold for this sum, we can make a decision + or -</p></li>
</ul>
</li>
<li><p>experimental evidence (Kiani, Hanks, &amp; Shadlen, Nat. Neurosci 2006)</p>
<ul>
<li><p>monkey is making decision about whether dots are moving left/right</p></li>
<li><p>neuron firing rates increase over time, representing integrated evidence</p></li>
<li><p>neuron always seems to stop at same firing rate</p></li>
</ul>
</li>
<li><p>priors - ex. tiger is much less likely then breeze</p>
<ul>
<li><p>scale P(+|r) by prior P(+)</p></li>
<li><p>neuroscience ex. photoreceptor cells P(noise|r) is much larger than P(signal|r)</p>
<ul>
<li><p>therefore threshold on r is high to minimize total mistakes</p></li>
</ul>
</li>
</ul>
</li>
<li><p>cost of acting/not acting</p>
<ul>
<li><p>loss for predicting + when it is -: <span class="math notranslate nohighlight">\(L_- \cdot P[+\|r]\)</span></p></li>
<li><p>loss for predicting - when it is +: <span class="math notranslate nohighlight">\(L_+ \cdot P[-\|r]\)</span></p></li>
<li><p>cut your losses: answer + when average Loss<span class="math notranslate nohighlight">\(_+\)</span> &lt; Loss<span class="math notranslate nohighlight">\(_-\)</span></p>
<ul>
<li><p>i.e. <span class="math notranslate nohighlight">\(L_+ \cdot P[-\|r]\)</span> &lt; <span class="math notranslate nohighlight">\(L_- \cdot P[+\|r]\)</span></p></li>
</ul>
</li>
<li><p>rewriting with Baye’s rule yields new test:</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\frac{p(r\|+)}{p(r\|-)}&gt; L_+ \cdot P[-] / L_- \cdot P[+]\)</span></p></li>
<li><p>here the loss term replaces the 1 in the Neyman-Pearson lemma</p></li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>population coding and bayesian estimation</strong></p>
<ul class="simple">
<li><p><em>population vector</em> - sums vectors for cells that point in different directions weighted by their firing rates</p>
<ul>
<li><p>ex. cricket cercal cells sense wind in different directions</p></li>
<li><p>since neuron can’t have negative firing rate, need overcomplete basis so that can record wind in both directions along an axis</p></li>
<li><p>can do the same thing for direction of arm movement in a neural prosthesis</p></li>
<li><p>not general - some neurons aren’t tuned, are noisier</p></li>
<li><p>not <em>optimal</em> - making use of all information in the stimulus/response distributions</p></li>
</ul>
</li>
<li><p><em>bayesian inference</em></p>
<ul>
<li><p><span class="math notranslate nohighlight">\(p(s\|r) = \frac{p(r\|s)p(s)}{p( r)}\)</span></p></li>
<li><p>maximum likelihood: s* which maximizes p(r|s)</p></li>
<li><p>MAP = maximum a posteriori: s* which mazimizes p(s|r)</p></li>
</ul>
</li>
<li><p>simple continuous stimulus example</p>
<ul>
<li><p>setup</p>
<ul>
<li><p>s - orientation of an edge</p></li>
<li><p>each neuron’s average firing rate=tuning curve <span class="math notranslate nohighlight">\(f_a(s)\)</span> is Gaussian (in s)</p></li>
<li><p>let <span class="math notranslate nohighlight">\(r_a\)</span> be number of spikes for neuron a</p></li>
<li><p>assume receptive fields of neurons span s: <span class="math notranslate nohighlight">\(\sum r_a (s)\)</span> is const</p></li>
<li><p><img alt="" src="../../_images/3_2_2.png" /></p></li>
</ul>
</li>
<li><p>solving</p>
<ul>
<li><p>maximizing log-likelihood with respect to s			-</p></li>
<li><p>take derivative and set to 0</p>
<ul>
<li><p>soln <span class="math notranslate nohighlight">\(s^* = \frac{\sum r_a s_a / \sigma_a^2}{\sum r_a / \sigma_a^2}\)</span></p></li>
<li><p>if all the <span class="math notranslate nohighlight">\(\sigma\)</span> are same, <span class="math notranslate nohighlight">\(s^* = \frac{\sum r_a s_a}{\sum r_a}\)</span></p>
<ul>
<li><p>this is the population vector</p></li>
</ul>
</li>
</ul>
</li>
<li><p>maximum <em>a posteriori</em></p>
<ul>
<li><p><span class="math notranslate nohighlight">\(ln \: p(s\|r) = ln \: P(r\|s) + ln \: p(s) = ln \: P(r )\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(s^* = \frac{T \sum r_a s_a / \sigma^2_a + s_{prior} / \sigma^2_{prior}}{T \sum r_a / \sigma^2_a + 1/\sigma^2_{prior}}\)</span></p></li>
<li><p>this takes into account the prior</p>
<ul>
<li><p>narrow prior makes it matter more</p></li>
</ul>
</li>
</ul>
</li>
<li><p>doesn’t incorporate correlations in the population</p></li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>stimulus reconstruction</strong></p>
<ul>
<li><p>decoding s -&gt; <span class="math notranslate nohighlight">\(s^*\)</span></p></li>
<li><p>want an estimator <span class="math notranslate nohighlight">\(s_{Bayes}=s_B\)</span> given some response r</p>
<ul class="simple">
<li><p>error function <span class="math notranslate nohighlight">\(L(s,s_{B})=(s-s_{B})^2\)</span></p></li>
<li><p>minimize <span class="math notranslate nohighlight">\(\int ds \: L(s,s_{B}) \: p(s\|r)\)</span> by taking derivative with respect to <span class="math notranslate nohighlight">\(s_B\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(s_B = \int ds \: p(s\|r) \: s\)</span> - the conditional mean (spike-triggered average)</p></li>
</ul>
</li>
<li><p>add in spike-triggered average at each spike</p>
<ul class="simple">
<li><p>if spike-triggered average looks exponential, can never have smooth downwards stimulus</p></li>
<li><p>could use 2 neurons (like in H1) and replay the second with negative sign</p></li>
</ul>
</li>
<li><p>LGN neurons can reconstruct a video, but with noise</p></li>
<li><p>recreated 1 sec long movies - (<em>Jack Gallant</em> - Nishimoto et al. 2011, Current Biology)</p>
<ol class="arabic simple">
<li><p>voxel-based encoding model samples ton of prior clips and predicts signal</p></li>
</ol>
<ul class="simple">
<li><p>get p(r|s)</p></li>
<li><p>pick best p(r|s) by comparing predicted signal to actual signal</p></li>
<li><p>input is filtered to extract certain features</p></li>
<li><p>filtered again to account for slow timescale of BOLD signal</p></li>
</ul>
<ol class="arabic simple" start="2">
<li><p>decoding</p></li>
</ol>
<ul class="simple">
<li><p>maximize p(s|r) by maximizing p(r|s) p(s), and assume p(s) uniform</p></li>
<li><p>30 signals that have highest match to predicted signal are averaged</p></li>
<li><p>yields pretty good pictures</p></li>
</ul>
</li>
</ul>
</section>
<section id="information-theory">
<h3><span class="section-number">5.5.3.3. </span>information theory<a class="headerlink" href="#information-theory" title="Link to this heading">#</a></h3>
<p><strong>information and entropy</strong></p>
<ul class="simple">
<li><p>surprise for seeing a spike h(p) = <span class="math notranslate nohighlight">\(-log_2 (p)\)</span></p></li>
<li><p>entropy = average information</p></li>
<li><p>code might not align spikes with what we are encoding</p></li>
<li><p>how much of the variability in r is encoding s</p>
<ul>
<li><p>define q as en error</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(P(r_+\|s=+)=1-q\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(P(r_-\|s=+)=q\)</span></p></li>
<li><p>similar for when s=-</p></li>
</ul>
</li>
<li><p>total entropy: <span class="math notranslate nohighlight">\(H(R ) = - P(r_+) log P(r_+) - P(r_-)log P(r_-)\)</span></p></li>
<li><p>noise entropy: <span class="math notranslate nohighlight">\(H(R\|S=+) = -q log q - (1-q) log (1-q)\)</span></p></li>
<li><p>mutual info I(S;R) = <span class="math notranslate nohighlight">\(H(R ) - H(R\|S) \)</span> = total entropy - average noise entropy</p>
<ul>
<li><p>= <span class="math notranslate nohighlight">\(D_{KL} (P(R,S), P(R )P(S))\)</span></p></li>
</ul>
</li>
</ul>
</li>
<li><p><em>grandma’s famous mutual info recipe</em></p>
<ul>
<li><p>for each s</p>
<ul>
<li><p>P(R|s) - take one stimulus and repeat many times (or run for a long time)</p></li>
<li><p>H(R|s) - noise entropy</p></li>
</ul>
</li>
<li><p><span class="math notranslate nohighlight">\(H(R\|S)=\sum_s P(s) H(R\|s)\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(H(R ) \)</span> calculated using <span class="math notranslate nohighlight">\(P(R ) = \sum_s P(s) P(R\|s)\)</span></p></li>
</ul>
</li>
</ul>
<p><strong>info in spike trains</strong></p>
<ol class="arabic simple">
<li><p>information in spike patterns</p></li>
</ol>
<ul class="simple">
<li><p>divide pattern into time bins of 0 (no spike) and 1 (spike)</p></li>
<li><p>binary words w with letter size <span class="math notranslate nohighlight">\(\Delta t\)</span>, length T (Reinagel &amp; Reid 2000)</p>
<ul>
<li><p>can create histogram of each word</p></li>
<li><p>can calculate entropy of word</p></li>
</ul>
</li>
<li><p>look at distribution of words for just one stimulus</p>
<ul>
<li><p>distribution should be narrower</p></li>
</ul>
</li>
<li><p>calculate <span class="math notranslate nohighlight">\(H_{noise}\)</span> - average over time with random stimuli and calculate entropy</p>
<ul>
<li><p>varied parameters of word: length of bin (dt) and length of word (T)</p></li>
<li><p>there’s some limit to dt at which information stops increasing</p>
<ul>
<li><p>this represents temporal resolution at which jitter doesn’t stop response from identifying info about the stimulus</p></li>
</ul>
</li>
<li><p>corrections for finite sample size (Panzeri, Nemenman,…)</p></li>
</ul>
</li>
</ul>
<ol class="arabic simple" start="2">
<li><p>information in single spikes - how much info does single spike tell us about stimulus</p></li>
</ol>
<ul class="simple">
<li><p>don’t have to know encoding, mutual info doesn’t care</p></li>
</ul>
<ol class="arabic simple">
<li><p>calculate entropy for random stimulus
- <span class="math notranslate nohighlight">\(p=\bar{r} \Delta t\)</span> where <span class="math notranslate nohighlight">\(\bar{r}\)</span> is the mean firing rate</p></li>
<li><p>calculate entropy for specific stimulus</p></li>
</ol>
<ul class="simple">
<li><p>let <span class="math notranslate nohighlight">\(P(r=1\|s) = r(t) \Delta t\)</span></p></li>
<li><p>let <span class="math notranslate nohighlight">\(P(r=0\|s) = 1 - r(t) \Delta t\)</span></p></li>
<li><p>get r(t) by having simulus on for long time</p></li>
<li><p><em>ergodicity</em> - a time average is equivalent to averging over the s ensemble</p></li>
<li><p>info per spike <span class="math notranslate nohighlight">\(I(r,s) = \frac{1}{T} \int_0^T dt \frac{r(t)}{\bar{r}} log \frac{r(t)}{\bar{r}}\)</span></p>
<ul>
<li><p>timing precision reduces r(t)</p></li>
<li><p>low mean spike rate -&gt; high info per spike</p></li>
</ul>
</li>
<li><p>ex. rat runs through place field and only fires when it’s in place field</p>
<ul>
<li><p>spikes can be sharper, more / less frequent</p></li>
</ul>
</li>
</ul>
<p><strong>coding principles</strong></p>
<ul>
<li><p>natural stimuli</p>
<ul class="simple">
<li><p>huge dynamic range - variations over many orders of magnitude (ex. brightness)</p></li>
<li><p>power law scaling - structure at many scales (ex. far away things)</p></li>
</ul>
</li>
<li><p><em>efficient coding</em> - in order to have maximum entropy output, a good encoder should match its outputs to the distribution of its inputs</p>
<ul class="simple">
<li><p>want to use each of our “symbols” (ex. different firing rates) equally often</p></li>
<li><p>should assign equal areas of input stimulus PDF to each symbol</p></li>
</ul>
</li>
<li><p>adaptation to stimulus statistics</p>
<ul class="simple">
<li><p><img alt="" src="../../_images/4_3_1.png" /></p></li>
<li><p>feature adaptation (Atick and Redlich)</p>
<ul>
<li><p>spatial filtering properties in retina / LGN change with varying light levels</p></li>
<li><p>at low light levels surround becomes weaker</p></li>
</ul>
</li>
</ul>
</li>
<li><p>coding sechemes</p>
<ol class="arabic simple">
<li><p>redundancy reduction</p></li>
</ol>
<ul class="simple">
<li><p>population code <span class="math notranslate nohighlight">\(P(R_1,R_2)\)</span></p></li>
<li><p>entropy <span class="math notranslate nohighlight">\(H(R_1,R_2) \leq H(R_1) + H(R_2)\)</span> - being independent would maximize entropy</p></li>
</ul>
<ol class="arabic simple" start="2">
<li><p>correlations can be good</p></li>
</ol>
<ul class="simple">
<li><p>error correction and robust coding</p></li>
<li><p>correlations can help discrimination</p></li>
<li><p>retina neurons are redundant (Berry, Chichilnisky)</p></li>
</ul>
<ol class="arabic simple" start="3">
<li><p>more recently, sparse coding</p></li>
</ol>
<ul class="simple">
<li><p>penalize weights of basis functions</p></li>
<li><p>instead, we get localized features</p></li>
</ul>
</li>
<li><p>we ignored the behavioral feedback loop</p></li>
</ul>
</section>
</section>
<section id="computing-with-networks">
<h2><span class="section-number">5.5.4. </span>computing with networks<a class="headerlink" href="#computing-with-networks" title="Link to this heading">#</a></h2>
<section id="modeling-connections-between-neurons">
<h3><span class="section-number">5.5.4.1. </span>modeling connections between neurons<a class="headerlink" href="#modeling-connections-between-neurons" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>model effects of synapse by using synaptic conductance <span class="math notranslate nohighlight">\(g_s\)</span> with reversal potential <span class="math notranslate nohighlight">\(E_s\)</span></p>
<ul>
<li><p><span class="math notranslate nohighlight">\(g_s = g_{s,max} \cdot P_{rel} \cdot P_s\)</span></p>
<ul>
<li><p><span class="math notranslate nohighlight">\(P_{rel}\)</span> - probability of release given an input spike</p></li>
<li><p><span class="math notranslate nohighlight">\(P_s\)</span> - probability of postsynaptic channel opening = fraction of channels opened</p></li>
</ul>
</li>
</ul>
</li>
<li><p>basic synapse model</p>
<ul>
<li><p>assume <span class="math notranslate nohighlight">\(P_{rel}=1\)</span></p></li>
<li><p>model <span class="math notranslate nohighlight">\(P_s\)</span> with kinetic model</p>
<ul>
<li><p>open based on <span class="math notranslate nohighlight">\(\alpha_s\)</span></p></li>
<li><p>close based on <span class="math notranslate nohighlight">\(\beta_s\)</span></p></li>
<li><p>yields <span class="math notranslate nohighlight">\(\frac{dP_s}{dt} = \alpha_s (1-P_s) - \beta_s P_s\)</span></p></li>
</ul>
</li>
<li><p>3 synapse types</p>
<ol class="arabic simple">
<li><p>AMPA - well-fit by exponential</p></li>
<li><p>GAMA - fit by “alpha” function - has some delay</p></li>
<li><p>NMDA - fit by “alpha” function - has some delay</p></li>
</ol>
</li>
</ul>
</li>
<li><p>linear filter model of a synapse</p>
<ul>
<li><p>pick filter (ex. K(t) ~ exponential)</p></li>
<li><p><span class="math notranslate nohighlight">\(g_s = g_{s,max} \sum K(t-t_i)\)</span></p></li>
</ul>
</li>
<li><p>network of integrate-and-fire neurons</p>
<ul>
<li><p>if 2 neurons inhibit each other, get <em>synchrony</em> (fire at the same time</p></li>
</ul>
</li>
</ul>
</section>
<section id="intro-to-network-models">
<h3><span class="section-number">5.5.4.2. </span>intro to network models<a class="headerlink" href="#intro-to-network-models" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>comparing spiking models to firing-rate models</p>
<ul>
<li><p>advantages</p>
<ul>
<li><p>spike timing</p></li>
<li><p>spike correlations / synchrony between neurons</p></li>
</ul>
</li>
<li><p>disadvantages</p>
<ul>
<li><p>computationally expensive</p></li>
</ul>
</li>
<li><p>uses linear filter model of a synapse</p></li>
</ul>
</li>
<li><p>developing a firing-rate model</p>
<ul>
<li><p>replace spike train <span class="math notranslate nohighlight">\(\rho_1(t) \to u_1(t)\)</span></p>
<ul>
<li><p>can’t make this replacement when there are correlations / synchrony?</p></li>
</ul>
</li>
<li><p>input current <span class="math notranslate nohighlight">\(I_s\)</span>: <span class="math notranslate nohighlight">\(\tau_s \frac{dI_s}{dt}=-I_s + \mathbf{w} \cdot \mathbf{u}\)</span></p>
<ul>
<li><p>works only if we let K be exponential</p></li>
</ul>
</li>
<li><p>output firing rate: <span class="math notranslate nohighlight">\(\tau_r \frac{d\nu}{dt} = -\nu + F(I_s(t))\)</span></p></li>
<li><p>if synapses are fast (<span class="math notranslate nohighlight">\(\tau_s &lt;&lt; \tau_r\)</span>)</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\tau_r \frac{d\nu}{dt} = -\nu + F(\mathbf{w} \cdot \mathbf{u}))\)</span></p></li>
</ul>
</li>
<li><p>if synapses are slow (<span class="math notranslate nohighlight">\(\tau_r &lt;&lt; \tau_s\)</span>)</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\nu = F(I_s(t))\)</span></p></li>
</ul>
</li>
<li><p>if static inputs (input doesn’t change) - this is like artificial neural network, where F is sigmoid</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\nu_{\infty} = F(\mathbf{w} \cdot \mathbf{u})\)</span></p></li>
<li><p>could make these all vectors to extend to multiple output neurons</p></li>
</ul>
</li>
</ul>
</li>
<li><p>recurrent networks</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\tau \frac{d\mathbf{v}}{dt} = -\mathbf{v} + F(W\mathbf{u} + M \mathbf{v})\)</span></p>
<ul>
<li><p><span class="math notranslate nohighlight">\(-\mathbf{v}\)</span> is decay</p></li>
<li><p><span class="math notranslate nohighlight">\(W\mathbf{u}\)</span> is input</p></li>
<li><p><span class="math notranslate nohighlight">\(M \mathbf{v}\)</span> is feedback</p></li>
</ul>
</li>
<li><p>with constant input, <span class="math notranslate nohighlight">\(v_{\infty} = W \mathbf{u}\)</span></p></li>
<li><p>ex. edge detectors</p></li>
<li><p>V1 neurons are basically computing derivatives</p></li>
</ul>
</li>
</ul>
</section>
<section id="recurrent-networks">
<h3><span class="section-number">5.5.4.3. </span>recurrent networks<a class="headerlink" href="#recurrent-networks" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>linear recurrent network: <span class="math notranslate nohighlight">\(\tau \frac{d\mathbf{v}}{dt} = -\mathbf{v} + W\mathbf{u} + M \mathbf{v}\)</span></p>
<ul>
<li><p>let <span class="math notranslate nohighlight">\(\mathbf{h} = W\mathbf{u}\)</span></p></li>
<li><p>want to investigate different M</p></li>
</ul>
</li>
<li><p>can solve for <span class="math notranslate nohighlight">\(\mathbf{v}\)</span> using eigenvectors</p>
<ul>
<li><p>suppose M (NxN) is symmetric (connections are equal in both directions)</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\to\)</span> M has N orthogonal eigenvectors / eigenvalues</p></li>
<li><p>let <span class="math notranslate nohighlight">\(e_i\)</span> be the orthonormal eigenvectors</p></li>
</ul>
</li>
<li><p>output vector <span class="math notranslate nohighlight">\(\mathbf{v}(t) = \sum c_i (t) \mathbf{e_i}\)</span></p></li>
<li><p>allows us to get a closed-form solution for <span class="math notranslate nohighlight">\(c_i(t)\)</span></p></li>
<li><p>eigenvalues determine network stability</p>
<ul>
<li><p>if any <span class="math notranslate nohighlight">\(\lambda_i &gt; 1, \mathbf{v}(t)\)</span> explodes <span class="math notranslate nohighlight">\(\implies\)</span> network is unstable</p>
<ul>
<li><p>otherwise stable and converges to steady-state value</p></li>
</ul>
</li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{v}_\infty = \sum \frac{h\cdot e_i}{1-\lambda_i} e_i\)</span></p></li>
<li><p>amplification of input projection by a factor of <span class="math notranslate nohighlight">\(\frac{1}{1-\lambda_i}\)</span></p></li>
</ul>
</li>
</ul>
</li>
<li><p>ex. each output neuron codes for an angle between -180 to 180</p>
<ul>
<li><p>define M as cosine function of relative angle</p></li>
<li><p>excitation nearby, inhibition further away</p></li>
</ul>
</li>
<li><p>memory in linear recurrent networks</p>
<ul>
<li><p>suppose <span class="math notranslate nohighlight">\(\lambda_1=1\)</span> and all other <span class="math notranslate nohighlight">\(\lambda_i &lt; 1\)</span></p></li>
<li><p>then <span class="math notranslate nohighlight">\(\tau \frac{dc_1}{dt} = h \cdot e_1\)</span> - keeps memory of input</p></li>
<li><p>ex. memory of eye position in medial vestibular nucleus (Seung et al. 2000)</p>
<ul>
<li><p>integrator neuron maintains persistent activity</p></li>
</ul>
</li>
</ul>
</li>
<li><p>nonlinear recurrent networks: <span class="math notranslate nohighlight">\(\tau \frac{d\mathbf{v}}{dt} = -\mathbf{v} + F(\mathbf{h}+ M \mathbf{v})\)</span></p>
<ul>
<li><p>ex. ReLu F(x) = max(0,x)</p>
<ul>
<li><p>ensures that firing rates never go below</p></li>
</ul>
</li>
<li><p>can have eigenvalues &gt; 1 but stable due to rectification</p></li>
<li><p>can perform selective “attention”</p>
<ul>
<li><p>network performs “winner-takes-all” input selection</p></li>
</ul>
</li>
<li><p><em>gain modulation</em> - adding constant amount to input h multiplies the output</p></li>
<li><p>also maintains memory</p></li>
</ul>
</li>
<li><p>non-symmetric recurrent networks</p>
<ul>
<li><p>ex. excitatory and inhibitory neurons</p></li>
<li><p>linear stability analysis - find fixed points and take partial derivatives</p>
<ul>
<li><p>use eigenvalues to determine dynamics of the nonlinear network near a fixed point</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</section>
<section id="hopfield-nets">
<h3><span class="section-number">5.5.4.4. </span>hopfield nets<a class="headerlink" href="#hopfield-nets" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>hopfield nets can store / retrieve memories</p>
<ul>
<li><p>marr-pogio stereo algorithm</p></li>
</ul>
</li>
<li><p>binary Hopfield networks were introduced as associative memories that can store and retrieve patterns (Hopfield, 1982)</p>
<ul>
<li><p>network with dimension <span class="math notranslate nohighlight">\(d\)</span> can store <span class="math notranslate nohighlight">\(d\)</span> uncorrelated patterns, but fewer correlated patterns</p></li>
<li><p>in contrast to the storage capacity, the number of energy minima (spurious states, stable states) of Hopfield networks is exponential in <span class="math notranslate nohighlight">\(d\)</span>​ (Tanaka &amp; Edwards, 1980; Bruck &amp; Roychowdhury, 1990; Wainrib &amp; Touboul, 2013)</p></li>
<li><p>energy function only has pairwise connections</p></li>
<li><p>fully connected (no input/output) - activations are what matter</p>
<ul>
<li><p>can memorize patterns - starting with noisy patterns can converge to these patterns</p></li>
</ul>
</li>
</ul>
</li>
<li><p>hopfield three-way connections</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(E = - \sum_{i, j, k} T_{i, j, k} V_i V_j V_k\)</span> (self connections set to 0)</p>
<ul>
<li><p>update to <span class="math notranslate nohighlight">\(V_i\)</span>​ is now bilinear</p></li>
</ul>
</li>
</ul>
</li>
<li><p>modern hopfield network = dense associative memory (DAM) model</p>
<ul>
<li><p>use an energy function with interaction functions of the form <span class="math notranslate nohighlight">\(F (x) = x^n\)</span> and achieve storage capacity <span class="math notranslate nohighlight">\(\propto d^{n-1}\)</span> (Krotov &amp; Hopfield, 2016; 2018)</p></li>
</ul>
</li>
</ul>
</section>
</section>
<section id="learning">
<h2><span class="section-number">5.5.5. </span>learning<a class="headerlink" href="#learning" title="Link to this heading">#</a></h2>
<section id="supervised-learning">
<h3><span class="section-number">5.5.5.1. </span>supervised learning<a class="headerlink" href="#supervised-learning" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>net talk was major breakthrough (words -&gt; audio) Sejnowski &amp; Rosenberg 1987</p></li>
<li><p>people looked for world-centric receptive fields (so neurons responded to things not relative to retina but relative to body) but didn’t find them</p>
<ul>
<li><p>however, they did find gain fields: (Zipser &amp; Anderson, 1987)</p>
<ul>
<li><p>gain changes based on what retina is pointing at</p></li>
</ul>
</li>
<li><p>trained nn to go from pixels to head-centered coordinate frame</p>
<ul>
<li><p>yielded gain fields</p></li>
</ul>
</li>
<li><p>pouget et al. were able to find that this helped having 2 pop vectors: one for retina, one for eye, then add to account for it</p></li>
</ul>
</li>
<li><p>support vector networks (vapnik et al.) - svms early inspired from NNs</p></li>
<li><p>dendritic nonlinearities (hausser &amp; mel, 2003)</p>
<ul>
<li><p>example to think about neurons do this: <span class="math notranslate nohighlight">\(u = w_1 x_1 + w_2x_2 + w_{12}x_1x_2\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(y=\sigma(u)\)</span></p></li>
<li><p>somestimes called sigma-pi unit since it’s a sum of products</p></li>
<li><p>exponential number of params…<strong>could be fixed w/ kernel trick?</strong></p>
<ul>
<li><p>could also incorporate geometry constraint</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</section>
<section id="unsupervised-learning">
<h3><span class="section-number">5.5.5.2. </span>unsupervised learning<a class="headerlink" href="#unsupervised-learning" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>born w/ extremely strong priors on weights in different areas</p></li>
<li><p>barlow 1961, attneave 1954: efficient coding hypothesis = redundancy reduction hypothesis</p>
<ul>
<li><p>representation: compression / usefulness</p></li>
<li><p>easier to store prior probabilities (because inputs are independent)</p></li>
<li><p>relich 93: redundancy reduction for unsupervised learning (text ex. learns words from text w/out spaces)</p></li>
</ul>
</li>
</ul>
<section id="hebbian-learning-and-pca">
<h4><span class="section-number">5.5.5.2.1. </span>hebbian learning and pca<a class="headerlink" href="#hebbian-learning-and-pca" title="Link to this heading">#</a></h4>
<ul>
<li><p>pca can also be thought of as a tool for decorrelation (pc coefs tend to be less correlated)</p></li>
<li><p>hebbian learning = fire together, wire together: <span class="math notranslate nohighlight">\(\Delta w_{ab} \propto &lt;a, b&gt;\)</span> note: <span class="math notranslate nohighlight">\(&lt;a, b&gt;\)</span> is correlation of a and b (average over time)</p></li>
<li><p>linear hebbian learning (perceptron with linear output)</p></li>
<li><p><span class="math notranslate nohighlight">\(\dot{w}_i \propto &lt;y, x_i&gt; \propto \sum_j w_j &lt;x_j, x_i&gt;\)</span> since weights change relatively slowly</p>
<ul class="simple">
<li><p>synapse couldn’t do this, would grow too large</p></li>
</ul>
</li>
<li><p>oja’s rule (hebbian learning w/ weight decay so ws don’t get too big)</p>
<ul class="simple">
<li><p>points to correct direction</p></li>
</ul>
</li>
<li><p>sanger’s rule: for multiple neurons, fit residuals of other neurons</p></li>
<li><p>competitive learning rule: winner take all</p>
<ul class="simple">
<li><p>population nonlinearity is a max</p></li>
<li><p>gets stuck in local minima (basically k-means)</p></li>
</ul>
</li>
<li><p>pca only really good when data is gaussian</p>
<ul class="simple">
<li><p>interesting problems are non-gaussian, non-linear, non-convex</p></li>
</ul>
</li>
<li><p>pca: yields checkerboards that get increasingly complex (because images are smooth, can describe with smaller checkerboards)</p>
<ul class="simple">
<li><p>this is what jpeg does</p></li>
<li><p>very similar to discrete cosine transform (DCT)</p></li>
<li><p>very hard for neurons to get receptive fields that look like this</p></li>
</ul>
</li>
<li><p>retina: does whitening (yields center-surround receptive fields)</p>
<ul class="simple">
<li><p>easier to build</p></li>
<li><p>gets more even outputs</p></li>
<li><p>only has ~1.5 million fibers</p></li>
</ul>
</li>
<li><p><img alt="" src="../../_images/7_2_1.png" /></p>
<ul class="simple">
<li><p>most active neuron is the one whose w is closest to x</p></li>
</ul>
</li>
<li><p><em>competitive learning</em></p>
<ul>
<li><p>updating weights given a new input</p>
<ol class="arabic simple">
<li><p>pick a cluster (corresponds to most active neuron)</p></li>
<li><p>set weight vector for that cluster to running average of all inputs in that cluster</p></li>
</ol>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\Delta w = \epsilon \cdot (\mathbf{x} - \mathbf{w})\)</span></p></li>
</ul>
</li>
</ul>
</li>
</ul>
</section>
</section>
<section id="synaptic-plasticity-hebb-s-rule-and-statistical-learning">
<h3><span class="section-number">5.5.5.3. </span>synaptic plasticity, hebb’s rule, and statistical learning<a class="headerlink" href="#synaptic-plasticity-hebb-s-rule-and-statistical-learning" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>if 2 spikes keep firing at same time, get LTP - long-term potentiation</p>
<ul>
<li><p>if input fires, but not B then could get LTD - long-term depression</p></li>
</ul>
</li>
<li><p><em>Hebb rule</em> <span class="math notranslate nohighlight">\(\tau_w \frac{d\mathbf{w}}{dt} = \mathbf{x}v\)</span></p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\mathbf{x}\)</span> - input</p></li>
<li><p><span class="math notranslate nohighlight">\(v\)</span> - output</p></li>
<li><p>translates to <span class="math notranslate nohighlight">\(\mathbf{w}_{i+1}=\mathbf{w}_i + \epsilon \cdot \mathbf{x}v\)</span></p></li>
<li><p>average effect of the rule is to change based on correlation matrix <span class="math notranslate nohighlight">\(\mathbf{x}^T\mathbf{x}\)</span></p></li>
</ul>
</li>
<li><p><em>covariance rule</em>: <span class="math notranslate nohighlight">\(\tau_w \frac{d\mathbf{w}}{dt} = \mathbf{x}(v-E[v])\)</span></p>
<ul>
<li><p>includes LTD as well as LTP</p></li>
</ul>
</li>
<li><p><em>Oja’s rule</em>: <span class="math notranslate nohighlight">\(\tau_w \frac{d\mathbf{w}}{dt} = \mathbf{x}v- \alpha v^2 \mathbf{w}\)</span> where <span class="math notranslate nohighlight">\(\alpha&gt;0\)</span></p></li>
<li><p>stability</p>
<ul>
<li><p>Hebb rule - derivative of w is always positive <span class="math notranslate nohighlight">\(\implies\)</span> w grows without bound</p></li>
<li><p>covariance rule - derivative of w is still always positive <span class="math notranslate nohighlight">\(\implies\)</span> w grows without bound</p>
<ul>
<li><p>could add constraint that <span class="math notranslate nohighlight">\(\|\|w\|\|=1\)</span> and normalize w after every step</p></li>
</ul>
</li>
<li><p>Oja’s rule - <span class="math notranslate nohighlight">\(\|\|w\|\| = 1/\sqrt{\alpha}\)</span>, so stable</p></li>
</ul>
</li>
<li><p>solving <em>Hebb rule</em> <span class="math notranslate nohighlight">\(\tau_w \frac{d\mathbf{w}}{dt} = Q w\)</span> where Q represents correlation matrix</p>
<ul>
<li><p>write w(t) in terms of eigenvectors of Q</p></li>
<li><p>lets us solve for <span class="math notranslate nohighlight">\(\mathbf{w}(t)=\sum_i c_i(0)\exp(\lambda_i t / \tau_w) \mathbf{e}_i\)</span></p></li>
<li><p>when t is large, largest eigenvalue dominates</p></li>
</ul>
</li>
<li><p>hebbian learning implements PCA</p>
<ul>
<li><p>hebbian learning learns w aligned with principal eigenvector of input correlation matrix</p></li>
<li><p>this is same as PCA</p></li>
</ul>
</li>
</ul>
</section>
<section id="tensor-product-representation-tpr">
<h3><span class="section-number">5.5.5.4. </span>tensor product representation (TPR)<a class="headerlink" href="#tensor-product-representation-tpr" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>tensor product representation = TPR</p>
<ul>
<li><p>Tensor product variable binding and the representation of symbolic structures in connectionist systems (<a class="reference external" href="https://www.sciencedirect.com/science/article/abs/pii/000437029090007M?via%3Dihub">paul smolensky, 1990</a>) - activation patterns are “symbols” and internal structure allows them to be processed like symbols</p></li>
<li><p><strong>filler</strong> - one vector that embeds the content of the constituent</p></li>
<li><p><strong>role</strong> - second vector that embeds the structural role it fills</p></li>
<li><p>TPR is built by summing the outer product between roles and fillers:</p></li>
<li><p><img alt="tpr" src="../../_images/tpr.png" /></p>
<ul>
<li><p>can optionally flatten the final TPR as is done in <a class="reference external" href="https://arxiv.org/pdf/1812.08718.pdf">mccoy…smolensky, 2019</a> if we want to compare it to a vector or an embedding</p></li>
</ul>
</li>
<li><p>TPR of a structure is the sum of the TPR of its constituents</p>
<ul>
<li><p>tensor product operation allows constituents to be uniquely identified, even after the sum (if roles are linearly independent)</p></li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference external" href="https://csinva.io/blog/misc/24_tensor_product_repr">TPR intro blog post</a></p></li>
<li><p><a class="reference external" href="https://www.mit.edu/~jda/teaching/6.884/slides/oct_02.pdf">TPR slides</a></p></li>
<li><p>RNNs Implicitly Implement Tensor Product Representations (<a class="reference external" href="https://arxiv.org/pdf/1812.08718.pdf">mccoy…smolensky, 2019</a>)</p>
<ul>
<li><p>introduce TP Decomposition Networks (TPDNs), which use TPRs to approximate existing vector representations</p>
<ul>
<li><p>assumes a particular hypothesis for the relevant set of roles (e.g., sequence indexes or structural positions in a parse tree)</p></li>
</ul>
</li>
<li><p>TPDNs can successfully approximate linear and tree-based RNN autoencoder representations</p></li>
<li><p>evaluate TPDN based on how well the decoder applied to the TPDN representation produces the same output as the original RNN</p></li>
</ul>
</li>
<li><p>Discovering the Compositional Structure of Vector Representations with Role Learning Networks (<a class="reference external" href="https://arxiv.org/pdf/1910.09113.pdf">soulos, mccoy, linzen, &amp; smolensky, 2019</a>) - extend DISCOVER to learned roles with an LSTM</p>
<ul>
<li><p>role vector is regularized to be one-hot</p></li>
</ul>
</li>
<li><p>Concepts and Compositionality: In Search of the Brain’s Language of Thought (<a class="reference external" href="https://www.annualreviews.org/doi/10.1146/annurev-psych-122216-011829">frankland &amp; greene, 2020</a>)</p>
<ul>
<li><p>Fodor’s classic language of thought hypothesis: our minds employ an amodal, language-like system for combining and recombining simple concepts to form more complex thoughts</p></li>
<li><p>combinatorial processes engage a common set of brain regions, typically housed throughout the brain’s default mode network (DMN)</p></li>
</ul>
</li>
</ul>
</section>
<section id="sparse-coding-and-predictive-coding">
<h3><span class="section-number">5.5.5.5. </span>sparse coding and predictive coding<a class="headerlink" href="#sparse-coding-and-predictive-coding" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>eigenface - Turk and Pentland 1991</p>
<ul>
<li><p>eigenvectors of the input covariance matrix are good features</p></li>
<li><p>can represent images using sum of eigenvectors (orthonormal basis)</p></li>
</ul>
</li>
<li><p>suppose you use only first M principal eigenvectors</p>
<ul>
<li><p>then there is some noise</p></li>
<li><p>can use this for compression</p></li>
<li><p>not good for local components of an image (e.g. parts of face, local edges)</p></li>
</ul>
</li>
<li><p>if you assume Gausian noise, maximizing likelihood = minimizing squared error</p></li>
<li><p>generative model</p>
<ul>
<li><p>images X</p></li>
<li><p>causes</p></li>
<li><p>likelihood <span class="math notranslate nohighlight">\(P(X=x\|C=c)\)</span></p>
<ul>
<li><p>Gaussian</p></li>
<li><p>proportional to <span class="math notranslate nohighlight">\(\exp(x-Gc)\)</span></p></li>
</ul>
</li>
<li><p>want posterior <span class="math notranslate nohighlight">\(P(C\|X)\)</span></p></li>
<li><p>prior <span class="math notranslate nohighlight">\(p(C)\)</span></p>
<ul>
<li><p>assume priors causes are independent</p></li>
<li><p>want sparse distribution</p>
<ul>
<li><p>has heavy tail (super-Gaussian distribution)</p></li>
</ul>
</li>
<li><p>then P(C ) = <span class="math notranslate nohighlight">\(k\prod \exp(g(C_i))\)</span></p></li>
</ul>
</li>
<li><p>can implement sparse coding in a recurrent neural network</p></li>
<li><p>Olshausen &amp; Field, 1996 - learns receptive fields in V1</p></li>
</ul>
</li>
<li><p>sparse coding is a special case of <em>predictive coding</em></p>
<ul>
<li><p><img alt="" src="../../_images/7_3_1.png" /></p></li>
<li><p>there is usually a feedback connection for every feedforward connection (Rao &amp; Ballard, 1999)</p></li>
</ul>
</li>
<li><p>recurrent sparse reconstruction (<a class="reference external" href="https://arxiv.org/pdf/2204.10962.pdf">shi…joshi, darrell, wang, 2022</a>) - sparse reconstruction (of a single image) learns a layer that does better than self-attention</p></li>
</ul>
</section>
<section id="sparse-distributed-coding">
<h3><span class="section-number">5.5.5.6. </span>sparse, distributed coding<a class="headerlink" href="#sparse-distributed-coding" title="Link to this heading">#</a></h3>
<ul>
<li><div class="math notranslate nohighlight">
\[\underset {\mathbf{D}} \min \underset t \sum \underset {\mathbf{h^{(t)}}} \min ||\mathbf{x^{(t)}} - \mathbf{Dh^{(t)}}||_2^2 + \lambda ||\mathbf{h^{(t)}}||_1\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(D\)</span> is like autoencoder output weight matrix</p></li>
<li><p>h is more complicated - requires solving inner minimization problem</p></li>
<li><p>outer loop is not quite lasso - weights are not what is penalized</p></li>
</ul>
</li>
<li><p>barlow 1972: want to represent stimulus with minimum active neurons</p>
<ul class="simple">
<li><p>neurons farther in cortex are more silent</p></li>
<li><p>v1 is highly overcomplete (dimensionality expansion)</p></li>
</ul>
</li>
<li><p>codes: dense -&gt; sparse, distributed <span class="math notranslate nohighlight">\(n \choose k\)</span> -&gt; local (grandmother cells)</p>
<ul class="simple">
<li><p>energy argument - bruno doesn’t think it’s a big deal (could just not have a brain)</p></li>
</ul>
</li>
<li><p>PCA: autoencoder when you enforce weights to be orthonormal</p>
<ul class="simple">
<li><p>retina must output encoded inputs as spikes, lower dimension -&gt; uses whitening</p></li>
</ul>
</li>
<li><p>cortex</p>
<ul class="simple">
<li><p>sparse coding different kind of autencoder bottleneck (imposes sparsity)</p></li>
</ul>
</li>
<li><p>using bottlenecks in autoencoders forces you to find structure in data</p></li>
<li><p>v1 simple-cell receptive fields are localized, oriented, and bandpass</p></li>
<li><p>higher-order image statistics</p>
<ul class="simple">
<li><p>phase alignment</p></li>
<li><p>orientation (requires at least 3 points stats (like orientation)</p></li>
<li><p>motion</p></li>
</ul>
</li>
<li><p>how to learn sparse repr?</p>
<ul class="simple">
<li><p>foldiak 1990 forming sparse reprs by local anti-hebbian learning</p></li>
<li><p>driven by inputs and gets lateral inhibition and sum threshold</p></li>
<li><p>neurons drift towards some firing rate naturally (adjust threshold naturally)</p></li>
</ul>
</li>
<li><p>use higher-order statistics</p>
<ul class="simple">
<li><p>projection pursuit (field 1994) - maximize non-gaussianity of projections</p>
<ul>
<li><p>CLT says random projections should look gaussian</p></li>
<li><p>gabor-filter response histogram over natural images look non-Gaussian (sparse) - peaked at 0</p></li>
</ul>
</li>
<li><p>doesn’t work for graded signals</p></li>
</ul>
</li>
<li><p>sparse coding for graded signals: olshausen &amp; field, 1996</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\underset{Image}{I(x, y)} = \sum_i a_i \phi_i (x, y) + \epsilon (x,y)\)</span></p></li>
<li><p>loss function <span class="math notranslate nohighlight">\(\frac{1}{2} |I - \phi a|^2 + \lambda \sum_i C(a_i)\)</span></p></li>
<li><p>can think about difference between <span class="math notranslate nohighlight">\(L_1\)</span> and <span class="math notranslate nohighlight">\(L_2\)</span> as having preferred directions (for the same length of vector) - prefer directions which some zeros</p></li>
<li><p>in terms of optimization, smooth near zero</p></li>
<li><p>there is a network implementation</p></li>
<li><p><span class="math notranslate nohighlight">\(a_i\)</span>are calculated by solving optimization for each image, <span class="math notranslate nohighlight">\(\phi\)</span> is learned more slowly</p></li>
<li><p><strong>can you get <span class="math notranslate nohighlight">\(a_i\)</span> closed form soln?</strong></p></li>
</ul>
</li>
<li><p>wavelets invented in 1980s/1990s for sparsity + compression</p></li>
<li><p>these tuning curves match those of real v1 neurons</p></li>
<li><p>applications</p>
<ul class="simple">
<li><p>for time, have spatiotemporal basis where local wavelet moves</p></li>
<li><p>sparse coding of natural sounds</p>
<ul>
<li><p>audition like a movie with two pixels (each ear sounds independent)</p></li>
<li><p>converges to gamma tone functions, which is what auditory fibers look like</p></li>
</ul>
</li>
<li><p>sparse coding to neural recordings - finds spikes in neurons</p>
<ul>
<li><p>learns that different layers activate together, different frequencies come out</p></li>
<li><p>found place cell bases for LFP in hippocampus</p></li>
</ul>
</li>
<li><p>nonnegative matrix factorization - like sparse coding but enforces nonnegative</p></li>
<li><p>can explicitly enforce nonnegativity</p></li>
</ul>
</li>
<li><p>LCA algorithm lets us implement sparse coding in biologically plausible local manner</p></li>
<li><p>explaining away - neural responses at the population should be decodable (shouldn’t be ambiguous)</p></li>
<li><p>good project: understanding properties of sparse coding bases</p></li>
<li><p>SNR = <span class="math notranslate nohighlight">\(VAR(I) / VAR(|I- \phi A|)\)</span></p></li>
<li><p>can run on data after whitening</p>
<ul class="simple">
<li><p>graph is of power vs frequency (images go down as <span class="math notranslate nohighlight">\(1/f\)</span>), need to weighten with f</p></li>
<li><p>don’t whiten highest frequencies (because really just noise)</p>
<ul>
<li><p>need to do this softly - roughly what the retina does</p></li>
</ul>
</li>
<li><p>as a result higher spatial frequency activations have less variance</p></li>
</ul>
</li>
<li><p>whitening effect on sparse coding</p>
<ul class="simple">
<li><p>if you don’t whiten, have some directions that have much more variance</p></li>
</ul>
</li>
<li><p>projects</p>
<ul class="simple">
<li><p>applying to different types of data (ex. auditory)</p></li>
</ul>
</li>
<li><p>adding more bases as time goes on</p></li>
<li><p>combining convolution w/ sparse coding?</p></li>
<li><p>people didn’t see sparsity for a while because they were using very specific stimuli and specific neurons</p>
<ul class="simple">
<li><p>now people with less biased sampling are finding more sparsity</p></li>
<li><p>in cortex anasthesia tends to lower firing rates, but opposite in hippocampus</p></li>
</ul>
</li>
</ul>
</section>
<section id="self-organizing-maps-kohonen-maps">
<h3><span class="section-number">5.5.5.7. </span>self-organizing maps = kohonen maps<a class="headerlink" href="#self-organizing-maps-kohonen-maps" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>homunculus - 3d map corresponds to map in cortex (sensory + motor)</p></li>
<li><p>related to <em>self-organizing maps</em> = kohonen maps</p>
<ul>
<li><p>in self-organizing maps, update other neurons in the neighborhood of the winner</p></li>
<li><p>update winner closer</p></li>
<li><p>update neighbors to also be closer</p></li>
<li><p>ex. V1 has orientation preference maps that do this</p></li>
</ul>
</li>
<li><p>visual cortex</p>
<ul>
<li><p>visual cortex mostly devoted to center</p></li>
<li><p>different neurons in same regions sensitive to different orientations (changing smoothly)</p></li>
<li><p>orientation constant along column</p></li>
<li><p>orientation maps not found in mice (but in cats, monkeys)</p></li>
<li><p>direction selective cells as well</p></li>
</ul>
</li>
<li><p>maps are plastic - cortex devoted to particular tasks expands (not passive, needs to be active)</p>
<ul>
<li><p>kids therapy with tone-tracking video games at higher and higher frequencies</p></li>
</ul>
</li>
</ul>
</section>
</section>
<section id="probabilistic-models-inference">
<h2><span class="section-number">5.5.6. </span>probabilistic models + inference<a class="headerlink" href="#probabilistic-models-inference" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Wiener filter: has Gaussian prior + likelihood</p></li>
<li><p>gaussians are everywhere because of CLT, max entropy (subject to power constraint)</p>
<ul>
<li><p>for gaussian function, <span class="math notranslate nohighlight">\(d/dx f(x) = -x f(x)\)</span></p></li>
</ul>
</li>
</ul>
<section id="boltzmann-machines">
<h3><span class="section-number">5.5.6.1. </span>boltzmann machines<a class="headerlink" href="#boltzmann-machines" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>hinton &amp; sejnowski 1983</p></li>
<li><p>starts with a hopfield net (states <span class="math notranslate nohighlight">\(s_i\)</span> weights <span class="math notranslate nohighlight">\(\lambda_{ij}\)</span>) where states are <span class="math notranslate nohighlight">\(\pm 1\)</span></p></li>
<li><p>define energy function <span class="math notranslate nohighlight">\(E(\mathbf{s}) = - \sum_{ij} \lambda_{ij} s_i s_j\)</span></p></li>
<li><p>assume Boltzmann distr <span class="math notranslate nohighlight">\(P(s) = \frac{1}{z} \exp (- \beta \phi(s))\)</span></p></li>
<li><p>learning rule is basically expectation over data - expectation over model</p>
<ul>
<li><p>could use wake-sleep algorithm</p></li>
<li><p>during day, calculate expectation over data via Hebbian learning (in Hopfield net this would store minima)</p></li>
<li><p>during night, would run anti-hebbian by doing random walk over network (in Hopfield net this would remove spurious local minima)</p></li>
</ul>
</li>
<li><p>learn via gibbs sampling (prob for one node conditioned on others is sigmoid)</p></li>
<li><p>can add hidden units to allow for learning higher-order interactions (not just pairwise)</p>
<ul>
<li><p>restricted boltzmann machine: no connections between “visible” units and no connections between “hidden units”</p></li>
<li><p>computationally easier (sampling is independent) but less rich</p></li>
</ul>
</li>
<li><p>stacked rbm: hinton &amp; salakhutdinov (hinton argues this is first paper to launch deep learning)</p>
<ul>
<li><p>don’t train layers jointly</p></li>
<li><p>learn weights with rbms as encoder</p></li>
<li><p>then decoder is just transpose of weights</p></li>
<li><p>finally, run fine-tuning on autoencoder</p></li>
<li><p>able to separate units in hidden layer</p></li>
<li><p><strong>cool - didn’t actually need decoder</strong></p></li>
</ul>
</li>
<li><p>in rbm</p>
<ul>
<li><p>when measuring true distr, don’t see hidden vals</p>
<ul>
<li><p>instead observe visible units and conditionally sample over hidden units</p></li>
<li><p><span class="math notranslate nohighlight">\(P(h|v) = \prod_i P(h_i | v)\)</span> ~ easy to sample from</p></li>
</ul>
</li>
<li><p>when measuring sampled distr., just sample <span class="math notranslate nohighlight">\(P(h|v)\)</span> then sample <span class="math notranslate nohighlight">\(P(v|h)\)</span></p></li>
</ul>
</li>
<li><p>ising model - only visible units</p>
<ul>
<li><p>basically just replicates pairwise statistics (kind of like pca)</p>
<ul>
<li><p>pairwise statistics basically say “when I’m on, are my neighbors on?”</p></li>
</ul>
</li>
<li><p>need 3-point statistics to learn a line</p></li>
</ul>
</li>
<li><p>generating textures</p>
<ul>
<li><p>learn the distribution of pixels in 3x3 patches</p></li>
<li><p>then maximize this distribution - can yield textures</p></li>
</ul>
</li>
<li><p>reducing the dimensionality of data with neural networks</p></li>
</ul>
</section>
</section>
<section id="data-driven-neuroscience">
<h2><span class="section-number">5.5.7. </span>data-driven neuroscience<a class="headerlink" href="#data-driven-neuroscience" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://docs.google.com/document/d/1qil2ylAnw6XrHPymYjKKYNDJn2qZQYA_Qg2_ijl-MaQ/edit">list of comparisons</a></p></li>
<li><p><a class="reference external" href="https://medium.com/the-spike/a-neural-data-science-how-and-why-d7e3969086f2">https://medium.com/the-spike/a-neural-data-science-how-and-why-d7e3969086f2</a></p></li>
</ul>
<section id="data-types">
<h3><span class="section-number">5.5.7.1. </span>data types<a class="headerlink" href="#data-types" title="Link to this heading">#</a></h3>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p>EEG</p></th>
<th class="head"><p>ECoG</p></th>
<th class="head"><p>Local Field potential (LFP) -&gt; microelectrode array</p></th>
<th class="head"><p>single-unit</p></th>
<th class="head"><p>calcium imaging</p></th>
<th class="head"><p>fMRI</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>scale</p></td>
<td><p>high</p></td>
<td><p>high</p></td>
<td><p>low</p></td>
<td><p>tiny</p></td>
<td><p>low</p></td>
<td><p>high</p></td>
</tr>
<tr class="row-odd"><td><p>spatial res</p></td>
<td><p>very low</p></td>
<td><p>low</p></td>
<td><p>mid-low</p></td>
<td><p>x</p></td>
<td><p>low</p></td>
<td><p>mid-low</p></td>
</tr>
<tr class="row-even"><td><p>temporal res</p></td>
<td><p>mid-high</p></td>
<td><p>high</p></td>
<td><p>high</p></td>
<td><p>super high</p></td>
<td><p>high</p></td>
<td><p>very low</p></td>
</tr>
<tr class="row-odd"><td><p>invasiveness</p></td>
<td><p>non</p></td>
<td><p>yes (under skull)</p></td>
<td><p>very</p></td>
<td><p>very</p></td>
<td><p>non</p></td>
<td><p>non</p></td>
</tr>
</tbody>
</table>
</div>
<ul>
<li><p><a class="reference external" href="https://medium.com/neurotechx/timeline-of-global-highlights-in-neuroengineering-2005-2018-75e4637b9e38">ovw of advancements in neuroengineering</a></p></li>
<li><p><strong>pro big-data</strong></p>
<p>Artificial neural networks can compute in several different ways. There is some evidence in the visual system that neurons in higher layers of visual areas can, to some extent, be predicted linearly by higher layers of deep networks (yamins2014performance)</p>
<ul class="simple">
<li><p>when comparing energy-efficiency, must normalize network performance by energy / number of computations / parameters</p></li>
</ul>
<p><strong>anti big-data</strong></p>
<ul class="simple">
<li><p>could neuroscientist  understand microprocessor (<a class="reference external" href="https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268">jonas &amp; kording, 2017</a>)</p></li>
<li><p>System Identification of Neural Systems: If We Got It Right, Would We Know? (<a class="reference external" href="https://proceedings.mlr.press/v202/han23d">han, poggio, &amp; cheung, 2023</a>) - could functional similarity be a reliable predictor of architectural similarity?</p></li>
<li><p>Can a biologist fix a radio?—Or, what I learned while studying apoptosis (<a class="reference external" href="https://www.cell.com/fulltext/S1535-6108(02)00133-2">lazebnik, 2002</a>)</p></li>
<li><p>no canonical microcircuit</p></li>
</ul>
</li>
<li><p>cellular</p>
<ul class="simple">
<li><p>extracellular microeelectrodes</p></li>
<li><p>intracellular microelectrode</p></li>
<li><p><strong>neuropixels</strong></p></li>
</ul>
</li>
<li><p>optical</p>
<ul class="simple">
<li><p>calcium imaging / fluorescence imaging</p></li>
<li><p>whole-brain light sheet imaging</p></li>
<li><p>voltage-sensitive dyes / voltage imaging</p></li>
<li><p><strong>adaptive optics</strong></p></li>
<li><ul>
<li><p>fNIRSlike fMRI but cheaper, allows more immobility, slightly worse spatial res</p></li>
</ul>
</li>
<li><p><strong>oct</strong> - noninvasive - can look at retina (maybe find biomarkers of alzheimer’s)</p></li>
<li><p>fiber photometry - optical fiber implanted delivers excitation light</p></li>
</ul>
</li>
<li><p>high-level</p>
<ul class="simple">
<li><p>EEG/ECoG</p></li>
<li><p>MEG</p></li>
<li><p>fMRI/PET</p>
<ul>
<li><p>MRI with <a class="reference external" href="https://www.biorxiv.org/content/10.1101/2021.05.21.444581v2">millisecond temporal precision</a></p></li>
<li><p>molecular fmri (bartelle)</p></li>
</ul>
</li>
<li><p>MRS</p></li>
<li><p>event-related optical signal = near-infrared spectroscopy</p></li>
</ul>
</li>
<li><p>implantable</p>
<ul class="simple">
<li><p>neural dust</p></li>
</ul>
</li>
</ul>
</section>
<section id="interventions">
<h3><span class="section-number">5.5.7.2. </span>interventions<a class="headerlink" href="#interventions" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>optogenetic stimulation</p></li>
<li><p>tms</p>
<ul>
<li><p>genetically-targeted tms: <a class="reference external" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4846560/">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4846560/</a></p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://www.psychiatry.org/patients-families/ect#:~:text=Learn%20about%20Electroconvulsive%2C%20therapy,the%20patient%20is%20under%20anesthesia.">ect - Electroconvulsive Therapy</a>  (sometimes also called electroshock therapy)</p>
<ul>
<li><p>Identifying Recipients of Electroconvulsive Therapy: Data From Privately Insured Americans (<a class="reference external" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6248332/">wilkinon…roenheck, 2018</a>) - 100k ppl per year</p></li>
<li><p>can differ in its application in three ways</p>
<ul>
<li><p>electrode placement</p>
<ul>
<li><p>used to be bilateral, now unilateral is more popular</p></li>
</ul>
</li>
<li><p>electrical waveform of the stimulus</p>
<ul>
<li><p>used to be sinusoid, now brief pulse is more popular (has gotten briefer over time)</p></li>
</ul>
</li>
<li><p>treatment frequency</p></li>
</ul>
</li>
<li><p>public perception is largely negative (owing in large part to its portrayal in <em>One flew over the Cuckoo’s nest</em>)</p></li>
<li><p>research</p>
<ul>
<li><p>How Does Electroconvulsive Therapy Work? Theories on its Mechanism (<a class="reference external" href="https://journals.sagepub.com/doi/10.1177/070674371105600104">bolwig, 2011</a>)</p>
<ul>
<li><p>generalized seizures</p></li>
<li><p>normalization of neuroendocrine dysfunction in melancholic depression</p></li>
<li><p>increased hippocampal neurogenesis and synaptogenesis</p></li>
</ul>
</li>
<li><p>Electroconvulsive therapy: How modern techniques improve patient outcomes (<a class="reference external" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4193538/pdf/nihms497537.pdf">tirmizi, 2012)</a></p></li>
<li><p>The neurobiological effects of electroconvulsive therapy studied through magnetic resonance – what have we learnt and where do we go? (<a class="reference external" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8630079/pdf/nihms-1710166.pdf">ousdal et al. 2022</a>)</p></li>
<li><p>Clinical EEG slowing induced by electroconvulsive therapy is better described by increased frontal aperiodic activity (<a class="reference external" href="https://www.nature.com/articles/s41398-023-02634-9">mith…soltani, 2023</a>)</p></li>
</ul>
</li>
</ul>
</li>
<li><p>local microstimulation with invasive electrodes</p></li>
</ul>
</section>
<section id="datasets">
<h3><span class="section-number">5.5.7.3. </span>datasets<a class="headerlink" href="#datasets" title="Link to this heading">#</a></h3>
<section id="language">
<h4><span class="section-number">5.5.7.3.1. </span>language<a class="headerlink" href="#language" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p>fMRI</p>
<ul>
<li><p>A natural language fMRI dataset for voxelwise encoding models (<a class="reference external" href="https://www.biorxiv.org/content/10.1101/2022.09.22.509104v1.abstract?%3Fcollection=">lebel, … huth, 2022</a>)</p>
<ul>
<li><p>8 participants listening to ~6 hours each of the moth radio hour</p></li>
<li><p>3 of the particpants have ~20 hours (~95 stories, 33k timepoints)</p></li>
</ul>
</li>
<li><p>Narratives Dataset (<a class="reference external" href="http://fcon_1000.projects.nitrc.org/indi/retro/Narratives.html">Nastase et al. 2019</a>) - more subjects, less data per subject</p>
<ul>
<li><p>345 subjects, 891 functional scans, and 27 diverse stories of varying duration totaling ~4.6 hours of unique stimuli (~43,000 words) and total collection time is ~6.4 days</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://www.nature.com/articles/s41597-019-0020-y">Schoffelen et al. 2019</a>: 100 subjects recorded with fMRI and MEG, listening to de-contextualised sentences and word lists, no repeated session</p></li>
<li><p><a class="reference external" href="https://www.nature.com/articles/nature17637">Huth et al. 2016</a> released data from <a class="reference external" href="https://github.com/HuthLab/speechmodeltutorial">one subject</a></p></li>
<li><p>Visual and linguistic semantic representations are aligned at the border of human visual cortex (<a class="reference external" href="https://www.nature.com/articles/s41593-021-00921-6#data-availability">popham, huth et al. 2021</a>) - compared semantic maps obtained from two functional magnetic resonance imaging experiments in the same participants: one that used silent movies as stimuli and another that used narrative stories (<a class="reference external" href="https://berkeley.app.box.com/s/l95gie5xtv56zocsgugmb7fs12nujpog">data link</a>)</p></li>
</ul>
</li>
<li><p>MEG datasets</p>
<ul>
<li><p>MEG-MASC (<a class="reference external" href="https://www.nature.com/articles/s41597-023-02752-5">gwilliams…king, 2023</a>) - 27 English-speaking subjects MEG, each ~2 hours of story listening, punctuated by random word lists and comprehension questions in the MEG scanner. Usually each subject listened to four distinct fictional stories twice</p></li>
<li><p>WU-Minn human connectome project (<a class="reference external" href="https://www.nature.com/articles/s41597-022-01382-7">van Essen et al. 2013</a>) - 72 subjects recorded with fMRI and MEG as part of the Human Connectome Project, listening to 10 minutes of short stories, no repeated session</p></li>
<li><p><a class="reference external" href="https://www.nature.com/articles/s41597-022-01382-7">Armeni et al. 2022</a>: 3 subjects recorded with MEG, listening to 10 hours of Sherlock Holmes, no repeated session</p></li>
</ul>
</li>
<li><p>EEG</p>
<ul>
<li><p><a class="reference external" href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0207741">Brennan &amp; Hale, 2019</a>: 33 subjects recorded with EEG, listening to 12 min of a book chapter, no repeated session</p></li>
<li><p><a class="reference external" href="https://www.cell.com/current-biology/pdf/S0960-9822(18)30146-5.pdf">Broderick et al. 2018</a>: 9–33 subjects recorded with EEG, conducting different speech tasks, no repeated sessions</p></li>
</ul>
</li>
<li><p>ECoG</p>
<ul>
<li><p>The “Podcast” ECoG dataset for modeling neural activity during
natural language comprehension (<a class="reference external" href="https://www.biorxiv.org/content/10.1101/2025.02.14.638352v1.full.pdf">zada…hasson, 2025</a>) - 9 subjects listening to the same story</p>
<ul>
<li><p>30-min story (1330 total electrodes, ~5000 spoken words (non-unique)) has female interviewer/voiceover and a male speaker, occasionally background music</p></li>
<li><p>contextual word embeddings from GPT-2 XL (middle layer) accounted for most of the variance across nearly all the electrodes tested</p></li>
</ul>
</li>
<li><p>Brain Treebank: Large-scale intracranial recordings from naturalistic language stimuli (<a class="reference external" href="https://arxiv.org/pdf/2411.08343">wang…barbu, 2024</a>)</p>
<ul>
<li><p>Some works on this dataset</p>
<ul>
<li><p>BrainBERT: Self-supervised representation learning for intracranial recordings (<a class="reference external" href="https://arxiv.org/abs/2302.14367">wang…barbu, 2023</a>)</p></li>
<li><p>Revealing Vision-Language Integration in the Brain with Multimodal Networks (<a class="reference external" href="https://arxiv.org/abs/2406.14481">subramaniam…barbu, 2024</a>)</p></li>
<li><p>Population Transformer: Learning Population-Level Representations of Neural Activity (<a class="reference external" href="https://pmc.ncbi.nlm.nih.gov/articles/PMC11177958/">chau…barbu, 2024</a>)</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>single-cell</p>
<ul>
<li><p>Semantic encoding during language comprehension at single-cell resolution (<a class="reference external" href="https://www.nature.com/articles/s41586-024-07643-2">jamali…fedorenko, williams, 2024</a>) - extremely small dataset released: mostly sentences</p></li>
</ul>
</li>
<li><p>cross-modality (language-adjacent)</p>
<ul>
<li><p>language</p>
<ul>
<li><p>A synchronized multimodal neuroimaging dataset to study brain language processing (<a class="reference external" href="https://openneuro.org/datasets/ds004078/versions/1.2.1">wang…zong, 2023</a>)</p></li>
</ul>
</li>
<li><p>language-adjacent</p>
<ul>
<li><p>NeuroBOLT data (<a class="reference external" href="https://arxiv.org/abs/2410.05341">li…chang, 2024</a>; code <a class="reference external" href="https://drive.google.com/file/d/1s9LzdBx1afGYiGbpi3p-oFh-CnYLyYqM/view?usp=sharing">link</a>)</p></li>
<li><p>An open-access dataset of naturalistic viewing using simultaneous EEG-fMRI (<a class="reference external" href="https://www.nature.com/articles/s41597-023-02458-8">telesford…franco, 2023</a>)</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</section>
<section id="misc">
<h4><span class="section-number">5.5.7.3.2. </span>misc<a class="headerlink" href="#misc" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p><a class="reference external" href="https://osf.io/mknfu/">non-human primate optogenetics datasets</a></p></li>
<li><p><a class="reference external" href="https://www.visualdata.io/">vision dsets</a></p>
<ul>
<li><p>MRNet: knee MRI diagnosis</p></li>
</ul>
</li>
<li><p><a class="reference external" href="http://datalad.org/datasets.html">datalad lots of stuff</a></p></li>
<li><p>calcium imaging records in mice</p>
<ul>
<li><p>Recordings of ten thousand neurons in visual cortex during spontaneous behaviors (<a class="reference external" href="https://figshare.com/articles/dataset/Recordings_of_ten_thousand_neurons_in_visual_cortex_during_spontaneous_behaviors/6163622">stringer et al. 2018</a>) - 10k neuron responses to 2800 images</p></li>
</ul>
</li>
<li><p>neuropixels probes</p>
<ul>
<li><p><a class="reference external" href="https://portal.brain-map.org/explore/circuits/visual-coding-neuropixels">10k neurons visual coding</a> from allen institute</p></li>
<li><p>this probe has also been used in <a class="reference external" href="https://www.cell.com/neuron/pdf/S0896-6273(19)30428-3.pdf">macaques</a></p></li>
</ul>
</li>
<li><p><a class="reference external" href="http://observatory.brain-map.org/visualcoding">allen institute calcium imaging</a></p>
<ul>
<li><p>An experiment is the unique combination of one mouse, one imaging depth (e.g. 175 um from surface of cortex), and one visual area (e.g. “Anterolateral visual area” or “VISal”)</p></li>
</ul>
</li>
<li><p>predicting running, facial cues</p>
<ul>
<li><p>dimensionality reduction</p>
<ul>
<li><p>enforcing bottleneck in the deep model</p></li>
<li><p>how else to do dim reduction?</p></li>
</ul>
</li>
</ul>
</li>
<li><p>overview: <a class="reference external" href="http://www.scholarpedia.org/article/Encyclopedia_of_computational_neuroscience">http://www.scholarpedia.org/article/Encyclopedia_of_computational_neuroscience</a></p></li>
<li><p>keeping up to date: <a class="reference external" href="https://sanjayankur31.github.io/planet-neuroscience/">https://sanjayankur31.github.io/planet-neuroscience/</a></p></li>
<li><p><em>lots of good data</em>: <a class="reference external" href="http://home.earthlink.net/~perlewitz/index.html">http://home.earthlink.net/~perlewitz/index.html</a></p></li>
<li><p>connectome</p>
<ul>
<li><p>fly brain: <a class="reference external" href="http://temca2data.org/">http://temca2data.org/</a></p></li>
</ul>
</li>
<li><p><em>models</em></p>
<ul>
<li><p>senseLab: <a class="reference external" href="https://senselab.med.yale.edu/">https://senselab.med.yale.edu/</a></p>
<ul>
<li><p>modelDB - has NEURON code</p></li>
</ul>
</li>
<li><p>model databases: <a class="reference external" href="http://www.cnsorg.org/model-database">http://www.cnsorg.org/model-database</a></p></li>
<li><p>comp neuro databases: <a class="reference external" href="http://home.earthlink.net/~perlewitz/database.html">http://home.earthlink.net/~perlewitz/database.html</a></p></li>
</ul>
</li>
<li><p><em>raw misc data</em></p>
<ul>
<li><p>crcns data: <a class="reference external" href="http://crcns.org/">http://crcns.org/</a></p>
<ul>
<li><p>visual cortex data (gallant)</p></li>
<li><p>hippocampus spike trains</p></li>
</ul>
</li>
<li><p>allen brain atlas: <a class="reference external" href="http://www.brain-map.org/">http://www.brain-map.org/</a></p>
<ul>
<li><p>includes calcium-imaging dataset: <a class="reference external" href="http://help.brain-map.org/display/observatory/Data+-+Visual+Coding">http://help.brain-map.org/display/observatory/Data+-+Visual+Coding</a></p></li>
</ul>
</li>
<li><p>wikipedia page: <a class="reference external" href="https://en.wikipedia.org/wiki/List_of_neuroscience_databases">https://en.wikipedia.org/wiki/List_of_neuroscience_databases</a></p></li>
</ul>
</li>
<li><p><em>human fMRI datasets</em>: <a class="reference external" href="https://docs.google.com/document/d/1bRqfcJOV7U4f-aa3h8yPBjYQoLXYLLgeY6_af_N2CTM/edit">https://docs.google.com/document/d/1bRqfcJOV7U4f-aa3h8yPBjYQoLXYLLgeY6_af_N2CTM/edit</a></p></li>
<li><p>Kay et al 2008 has data on responses to images</p></li>
<li><p><em>calcium imaging</em> for spike sorting: <a class="reference external" href="http://spikefinder.codeneuro.org/">http://spikefinder.codeneuro.org/</a></p>
<ul>
<li><p>spikes: <a class="reference external" href="http://www2.le.ac.uk/departments/engineering/research/bioengineering/neuroengineering-lab/software">http://www2.le.ac.uk/departments/engineering/research/bioengineering/neuroengineering-lab/software</a></p></li>
</ul>
</li>
<li><p>More datasets available at <a class="reference external" href="https://openneuro.org/search/modality/mri">openneuro</a> and visual cortex data on <a class="reference external" href="https://crcns.org/data-sets/vc">crcns</a></p></li>
</ul>
<p><strong>misc ideas</strong></p>
<ul class="simple">
<li><p>could a neuroscientist understand a deep neural network? - use neural tracing to build up wiring diagram / function</p></li>
<li><p>prediction-driven dimensionality reduction</p></li>
<li><p>deep heuristic for model-building</p></li>
<li><p>joint prediction of different input/output relationships</p></li>
<li><p>joint prediction of neurons from other areas</p></li>
</ul>
</section>
</section>
<section id="eeg">
<h3><span class="section-number">5.5.7.4. </span>eeg<a class="headerlink" href="#eeg" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>directly model time series</p>
<ul>
<li><p>BENDR: using transformers and a contrastive self-supervised learning task to learn from massive amounts of EEG data (<a class="reference external" href="https://arxiv.org/abs/2101.12037">kostas…rudzicz, 2021</a>)</p></li>
<li><p>Neuro-GPT: Developing A Foundation Model for EEG (<a class="reference external" href="https://arxiv.org/abs/2311.03764">cui…leahy, 2023</a>)</p></li>
</ul>
</li>
<li><p>model frequency bands</p>
<ul>
<li><p>EEG foundation model: Learning Topology-Agnostic EEG Representations with Geometry-Aware Modeling (<a class="reference external" href="https://openreview.net/pdf?id=hiOUySN0ub">yi…dongsheng li, 2023</a>)</p></li>
</ul>
</li>
<li><p>Strong Prediction: Language Model Surprisal Explains Multiple N400 Effects  (<a class="reference external" href="https://direct.mit.edu/nol/article/5/1/107/115605/Strong-Prediction-Language-Model-Surprisal">michaelov…coulson, 2024</a>)</p></li>
</ul>
</section>
<section id="cross-subject-modeling">
<h3><span class="section-number">5.5.7.5. </span>cross-subject modeling<a class="headerlink" href="#cross-subject-modeling" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Aligning Brains into a Shared Space Improves their Alignment to Large Language Models (<a class="reference external" href="https://www.biorxiv.org/content/10.1101/2024.06.04.597448v1">bhattacharjee, zaida…, hasson, goldstein, nastase, 2024</a>)</p></li>
<li><p>while a coarse alignment exists across individual brains (<a class="reference external" href="https://academic.oup.com/scan/article/14/6/667/5489905">Nastase et al., 2019</a>; <a class="reference external" href="https://www.nature.com/articles/s41597-021-01033-3">2021</a>), the finer cortical topographies for language representation exhibit significant idiosyncrasies among individuals (<a class="reference external" href="https://journals.physiology.org/doi/full/10.1152/jn.00032.2010">Fedorenko et al., 2010</a>; <a class="reference external" href="https://www.sciencedirect.com/science/article/abs/pii/S1053811912006817">Nieto-Castañón &amp; Fedorenko, 2012</a>; <a class="reference external" href="https://journals.physiology.org/doi/full/10.1152/jn.00753.2019">Braga et al., 2020</a>; <a class="reference external" href="https://www.nature.com/articles/s41597-022-01645-3">Lipkin et al., 2022</a>)</p></li>
<li><p>hyperalignment techniques have been developed in fMRI research to aggregate information across subjects into a unified information space while overcoming the misalignment of functional topographies across subjects (<a class="reference external" href="https://www.cell.com/neuron/fulltext/S0896-6273(15)00933-2">Haxby et al., 2011</a>; shared response model <a class="reference external" href="https://proceedings.neurips.cc/paper/2015/hash/b3967a0e938dc2a6340e258630febd5a-Abstract.html">Chen et al., 2015</a>; <a class="reference external" href="https://academic.oup.com/cercor/article/26/6/2919/1754308">Guntupalli…Haxby, 2016</a>; <a class="reference external" href="https://elifesciences.org/articles/56601">Haxby et al., 2020</a>; <a class="reference external" href="https://direct.mit.edu/imag/article/doi/10.1162/imag_a_00032/117980">Feilong et al., 2023</a>)</p></li>
<li><p>shared response model <a class="reference external" href="https://proceedings.neurips.cc/paper/2015/hash/b3967a0e938dc2a6340e258630febd5a-Abstract.html">Chen et al., 2015</a> - learns orthonormal, linear subject-specific transformations that map from each subject’s response  space to a shared space based on a subset of training data, then uses these learned transformations to map a subset of test data into the shared space</p></li>
</ul>
</section>
</section>
<section id="fmri">
<h2><span class="section-number">5.5.8. </span>fMRI<a class="headerlink" href="#fmri" title="Link to this heading">#</a></h2>
<section id="id1">
<h3><span class="section-number">5.5.8.1. </span>language<a class="headerlink" href="#id1" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Mapping Brains with Language Models: A Survey (<a class="reference external" href="https://arxiv.org/abs/2306.05126">Karamolegkou et al. 2023</a>)</p></li>
<li><p>The language network as a natural kind within the broader landscape of the human brain (<a class="reference external" href="https://www.researchgate.net/publication/379785120_The_language_network_as_a_natural_kind_within_the_broader_landscape_of_the_human_brain">fedorenko, ivanova, &amp; regev, 2024</a>)</p>
<ul>
<li><p>language processing involves converting linguistic stimuli (audio, vision) -&gt; linguistic forms (words, word sequences) -&gt; meaning and then back</p></li>
<li><p>averaging over individuals is often infeasible - instead, localizers (which show particular contrasts to subjects) can help identify functional regions</p>
<ul>
<li><p>most popular localizer uses contrasts between sentences and pronounceable non-word sequences (New Method for fMRI Investigations of Language: Defining ROIs Functionally in Individual Subjects; <a class="reference external" href="https://journals.physiology.org/doi/full/10.1152/jn.00032.2010">fedorenko…kanwisher, 2010</a>)</p></li>
</ul>
</li>
<li><p>language network is generally left-localized and in lateral frontal areas &amp; lateral temporal areas</p>
<ul>
<li><p><img alt="fedorenko_fig1" src="../../_images/fedorenko_fig1.png" /></p></li>
</ul>
</li>
<li><p>language areas engage during both comprehension and production; are input and output modality-independent</p></li>
<li><p>damage to left-hemisphere frontal/temporal brain areas leads to aphasia (deficits in language comprehension and production)</p></li>
</ul>
</li>
<li><p>Language is widely distributed throughout the brain (<a class="reference external" href="https://www.nature.com/articles/s41583-024-00903-0">drijvers, small, &amp; skipper, 2025</a>) - respond that rather than a “language network”, the ‘language network’ could more simply be conceived of as a collection of hierarchically organized auditory association cortices communicating with functional connectivity hubs that coordinate a whole-brain distribution of contextually determined and, thus, highly variable ‘peripheral’ regions</p></li>
<li><p>Semantic encoding during language comprehension at single-cell resolution (<a class="reference external" href="https://www.nature.com/articles/s41586-024-07643-2">jamali…fedorenko, williams, 2024</a>)</p></li>
<li><p>interpreting brain encoding models</p>
<ul>
<li><p><a class="reference external" href="https://www.nature.com/articles/s42003-022-03036-1#Sec9">Brains and algorithms partially converge in natural language processing</a> (caucheteux &amp; king, 2022)</p>
<ul>
<li><p>best brain-mapping are obtained from the middle layers of DL models</p></li>
<li><p>whether an algorithm maps onto the brain primarily depends on its ability to predict words context</p></li>
<li><p>average ROIs across many subjects</p></li>
<li><p>test “compositionality” of features</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://www.biorxiv.org/content/10.1101/2022.10.14.512299.abstract">Tracking the online construction of linguistic meaning through negation</a> (zuanazzi, …, remi-king, poeppel, 2022)</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1906.01539">Blackbox meets blackbox: Representational Similarity and Stability Analysis of Neural Language Models and Brains</a> (abnar, … zuidema, emnlp workshop, 2019) - use RSA to compare representations from language models with fMRI data from Wehbe et al. 2014</p></li>
<li><p><a class="reference external" href="https://www.nature.com/articles/s41562-022-01516-2">Evidence of a predictive coding hierarchy in the human brain listening to speech</a> (caucheteux, gramfot, &amp; king, 2023)</p></li>
</ul>
</li>
<li><p>encoding models</p>
<ul>
<li><p>Seminal language-semantics fMRI study (<a class="reference external" href="https://www.nature.com/articles/nature17637">huth…gallant, 2016</a>) - build mapping of semantic concepts across cortex using word vecs</p>
<ul>
<li><p>Crafting Interpretable Embeddings for Language Neuroscience by Asking LLMs Questions (<a class="reference external" href="https://openreview.net/pdf?id=mxMvWwyBWe">benara et al. 2024</a>)</p></li>
<li><p>A generative framework to bridge data-driven models and scientific theories in language neuroscience (<a class="reference external" href="https://arxiv.org/abs/2410.00812">antonello et al. 2024</a>)</p></li>
<li><p>Explanations of Deep Language Models Explain Language
Representations in the Brain (<a class="reference external" href="https://arxiv.org/pdf/2502.14671">rahimi…daliri, 2025</a>) - build features using attribution methods and find some small perf. improvements in early language areas</p></li>
</ul>
</li>
<li><p>Deep language algorithms predict semantic comprehension from brain activity <a class="reference external" href="https://www.nature.com/articles/s41598-022-20460-9">(caucheteux, gramfort, &amp; king, facebook, 2022)</a> - predicts fMRI with gpt-2 on the narratives dataset</p>
<ul>
<li><p>GPT‐2 representations predict fMRI response + extent to which subjects understand corresponding narratives</p></li>
<li><p>compared different encoding features: phoneme, word, gpt-2 layers, gpt-2 attention sizes</p></li>
<li><p>brain mapping finding: auditory cortices integrate information over short time windows, and the fronto-parietal areas combine supra-lexical information over long time windows</p></li>
<li><p>gpt2 models predict brain responses well <a class="reference external" href="https://www.biorxiv.org/content/10.1101/2020.07.03.186288v2.abstract">(caucheteux &amp; king, 2021)</a></p></li>
<li><p><a class="reference external" href="https://proceedings.mlr.press/v139/caucheteux21a.html">Disentangling syntax and semantics in the brain with deep networks</a> (caucheteux, gramfort, &amp; king, 2021) - identify which brain networks are involved in syntax, semantics, compositionality</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://proceedings.neurips.cc/paper/2018/hash/f471223d1a1614b58a7dc45c9d01df19-Abstract.html">Incorporating Context into Language Encoding Models for fMRI</a> (jain &amp; huth, 2018) - LSTMs improve encoding model</p>
<ul>
<li><p><a class="reference external" href="https://www.pnas.org/doi/abs/10.1073/pnas.2105646118">The neural architecture of language: Integrative modeling converges on predictive processing</a> (schrimpf, .., tenenbaum, fedorenko, 2021) - transformers better predict brain responses to natural language (and larger transformers predict better)</p></li>
<li><p><a class="reference external" href="https://direct.mit.edu/nol/article/doi/10.1162/nol_a_00087/113632/Predictive-Coding-or-Just-Feature-Discovery-An">Predictive Coding or Just Feature Discovery? An Alternative Account of Why Language Models Fit Brain Data | Neurobiology of Language</a> (antonello &amp; huth, 2022)</p>
<ul>
<li><p>LLM brain encoding performance correlates not only with their perplexity, but also generality (skill at many different tasks) and translation performance</p></li>
</ul>
</li>
<li><p>Prediction with RNN beats ngram models on individual-sentence fMRI prediction (<a class="reference external" href="https://www.jneurosci.org/content/41/18/4100">anderson…lalor, 2021</a>)</p></li>
<li><p>Interpret transformer-based models and find top predictions in specific regions, like left middle temporal gyrus (LMTG) and left occipital complex (LOC) (<a class="reference external" href="https://ieeexplore.ieee.org/document/9223750/">sun et al. 2021</a>)</p></li>
<li><p>Lexical-Semantic Content, Not Syntactic Structure, Is the Main Contributor to ANN-Brain Similarity of fMRI Responses in the Language Network  (<a class="reference external" href="https://direct.mit.edu/nol/article/5/1/7/116784/Lexical-Semantic-Content-Not-Syntactic-Structure">kauf…andreas, fedorenko, 2024</a>) - lexical semantic sentence content, not syntax, drive alignment.</p></li>
<li><p>Artificial Neural Network Language Models Predict Human Brain Responses to Language Even After a Developmentally Realistic Amount of Training  (<a class="reference external" href="https://direct.mit.edu/nol/article/5/1/43/119156/Artificial-Neural-Network-Language-Models-Predict">hosseini…fedorenko, 2024</a>) - models trained on a developmentally plausible amount of data (100M tokens) already align closely with human benchmarks</p></li>
<li><p>Improving semantic understanding in speech language models via brain-tuning (<a class="reference external" href="https://arxiv.org/abs/2410.09230">moussa…toneva, 2024</a>)</p></li>
</ul>
</li>
</ul>
</li>
<li><p>changing experimental design</p>
<ul>
<li><p>Semantic representations during language comprehension are affected by context (i.e. how langauge is presented) (<a class="reference external" href="https://www.biorxiv.org/content/10.1101/2021.12.15.472839v1.full.pdf">deniz…gallant, 2021</a>) - stimuli with more context (stories, sentences) evoke better responses than stimuli with little context (Semantic Blocks, Single Words)</p></li>
<li><p>Combining computational controls with natural text reveals new aspects of meaning composition (<a class="reference external" href="https://www.biorxiv.org/content/biorxiv/early/2022/08/09/2020.09.28.316935.full.pdf">toneva, mitchell, &amp; wehbe, 2022</a>) - study word interactions by using encoding vector emb(phrase) - emb(word1) - emb(word2)…</p></li>
<li><p>Driving and suppressing the human language network using large language models (<a class="reference external" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10120732/">tuckute, …, shrimpf, kay, &amp; fedorenko, 2023</a>)</p>
<ul>
<li><p>use encoding models to sort thousands of sentences and then show them</p>
<ul>
<li><p>alternatively, use gradient-based modifications to transform a random sentence to elicit larger responses, but this works worse</p></li>
</ul>
</li>
<li><p>surprisal and well- formedness of linguistic input are key determinants of response strength in the language network</p></li>
</ul>
</li>
</ul>
</li>
<li><p>multilingual stuff</p>
<ul>
<li><p>Bilingual language processing relies on shared semantic representations that are modulated by each language (<a class="reference external" href="https://www.biorxiv.org/content/10.1101/2024.06.24.600505v1">chen…klein, gallant, deniz, 2024</a>) - shared semantic representations are modulated by each language</p></li>
<li><p>An investigation across 45 languages and 12 language families reveals a universal language network (<a class="reference external" href="https://www.nature.com/articles/s41593-022-01114-5#data-availability">malik-moraleda…fedorenko, 2022</a>)</p></li>
<li><p>Multilingual Computational Models Reveal Shared Brain Responses to 21 Languages (<a class="reference external" href="https://www.biorxiv.org/content/10.1101/2025.02.01.636044v1">gregor de varda, malik-moraleda…tuckute, fedorenko, 2025</a>)</p></li>
<li><p>Constructed languages are processed by the same brain mechanisms as natural languages (<a class="reference external" href="https://www.biorxiv.org/content/10.1101/2023.07.28.550667v2">malik-moraleda…fedorenko, 2023</a>)</p></li>
</ul>
</li>
</ul>
</section>
<section id="semantic-decoding">
<h3><span class="section-number">5.5.8.2. </span>semantic decoding<a class="headerlink" href="#semantic-decoding" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>duality between encoding and decoding (e.g. for probing smth like syntax in LLM)</p>
<ul>
<li><p>esp. when things are localized like in fMRI</p></li>
<li><p>Interpreting encoding and decoding models (<a class="reference external" href="https://arxiv.org/pdf/1812.00278.pdf">kriegerskorte &amp; douglas, 2019</a>)</p></li>
<li><p>Encoding and decoding in fMRI (<a class="reference external" href="https://www.sciencedirect.com/science/article/abs/pii/S1053811910010657">naselaris, kay, nishimoto, &amp; gallant, 2011</a>)</p></li>
<li><p>Causal interpretation rules for encoding and decoding models in neuroimaging (<a class="reference external" href="https://www.sciencedirect.com/science/article/abs/pii/S105381191500052X">weichwald…grosse-wentrup, 2015</a>)</p>
<ul>
<li><p>experimental setup can be <strong>stimulus-based</strong>, if the experimental conditions precede the measured brain states (e.g. podcast listening) or <strong>response-based</strong> (e.g. prediction of the laterality of a movement from pre-movement brain state features)</p></li>
<li><p>for stimulus-based experiments, encoding model is the causal direction</p></li>
</ul>
</li>
</ul>
</li>
<li><p>language</p>
<ul>
<li><p>Semantic reconstruction of continuous language from non-invasive brain recordings (<a class="reference external" href="https://www.nature.com/articles/s41593-023-01304-9">tang, lebel, jain, &amp; huth, 2023</a>) - reconstruct continuous natural language from fMRI, including to imagined speech</p></li>
<li><p>Brain-to-Text Decoding: A Non-invasive Approach via Typing (<a class="reference external" href="https://scontent.fphl1-1.fna.fbcdn.net/v/t39.2365-6/475464888_600710912891423_9108680259802499048_n.pdf?_nc_cat=102&amp;amp;ccb=1-7&amp;amp;_nc_sid=3c67a6&amp;amp;_nc_ohc=EryvneL7DMcQ7kNvgFI6M7D&amp;amp;_nc_oc=Adi15_Ln_aPZ_nUY7RyiXzmEzdKu0opFDIwv3J7P55siQ-yn-FUdKQ6_H6PZBKiwBiY&amp;amp;_nc_zt=14&amp;amp;_nc_ht=scontent.fphl1-1.fna&amp;amp;_nc_gid=A441zcs56M0HTpo4ZEEWBSk&amp;amp;oh=00_AYAZ7fX4RhYWqMu2aMria3GoOB6uMNIiIciUQzU0vXy3Tw&amp;amp;oe=67AC0C96">levy…king, 2025</a>) - decode characters typed from MEG/EEG</p></li>
<li><p>From Thought to Action: How a Hierarchy of Neural Dynamics Supports Language Production (<a class="reference external" href="https://ai.meta.com/research/publications/from-thought-to-action-how-a-hierarchy-of-neural-dynamics-supports-language-production/">zhang, levy, …king, 2025</a>) - when decoding during typing, first decode phrase, then word, then syllable, then letter</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2208.12266">Decoding speech from non-invasive brain recordings</a> (defossez, caucheteux, …, remi-king, 2022)</p></li>
</ul>
</li>
<li><p>vision</p>
<ul>
<li><p>Decoding the Semantic Content of Natural Movies from Human Brain Activity (<a class="reference external" href="https://www.frontiersin.org/journals/systems-neuroscience/articles/10.3389/fnsys.2016.00081/full">huth…gallant, 2016</a>) - direct decoding of concepts from movies using hierarchical logistic regression</p>
<ul>
<li><p>interpreting weights from a decoding model can be tricky, even if if a concept is reflected in the voxel, it may not be uniquely reflected in the voxel and therefore assigned low weight</p></li>
</ul>
</li>
<li><p>Reconstructing Visual Experiences from Brain Activity Evoked by Natural Movies (<a class="reference external" href="https://www.sciencedirect.com/science/article/pii/S0960982211009377">nishimoto, …, gallant, 2011</a>)</p></li>
<li><p>Brain Decoding: Toward Real Time Reconstruction of Visual Perception (<a class="reference external" href="https://ai.meta.com/static-resource/image-decoding">Benchetrit…king, 2023</a>) - use MEG to do visual reconstruction</p></li>
<li><p>Seeing Beyond the Brain: Conditional Diffusion Model with Sparse Masked Modeling for Vision Decoding (<a class="reference external" href="https://arxiv.org/pdf/2211.06956.pdf">chen et al. 2022</a>)</p></li>
<li><p>Aligning brain functions boosts the decoding of visual semantics in novel subjects (<a class="reference external" href="https://arxiv.org/abs/2312.06467">thual…king, 2023</a>) - align across subjects before doing decoding</p></li>
<li><p>A variational autoencoder provides novel, data-driven features that explain functional brain representations in a naturalistic navigation task (<a class="reference external" href="https://jov.arvojournals.org/article.aspx?articleid=2792546">cho, zhang, &amp; gallant, 2023</a>)</p></li>
<li><p>What’s the Opposite of a Face? Finding Shared Decodable Concepts and their Negations in the Brain (<a class="reference external" href="https://arxiv.org/abs/2405.17663">efird…fyshe, 2024</a>) - build clustering shared across subjects in CLIP space</p></li>
</ul>
</li>
</ul>
</section>
<section id="theories-of-explanation">
<h3><span class="section-number">5.5.8.3. </span>theories of explanation<a class="headerlink" href="#theories-of-explanation" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>The generalizability crisis (<a class="reference external" href="https://mzettersten.github.io/assets/pdf/ManyBabies_BBS_commentary.pdf">yarkoni, 2020</a>) - there is widespread difficulty in converting informal verbal hypotheses into quantitative models</p></li>
<li><p>Formalising the role of behaviour in neuroscience (<a class="reference external" href="https://onlinelibrary.wiley.com/doi/10.1111/ejn.16372">piantadosi &amp; gallistel, 2024</a>) - can build isomorphisms between behavior and mathematical theories of representations</p></li>
<li><p><a class="reference external" href="https://www.neurosynth.org/analyses/terms/">NeuroSynth website</a></p>
<ul>
<li><p>Large-scale automated synthesis of human functional neuroimaging data (<a class="reference external" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3146590/pdf/nihms-300972.pdf">yarkoni, poldrack, nichols, van essen, &amp; wager, 2011</a>)</p></li>
<li><p>NeuroQuery, comprehensive meta-analysis of human brain mapping (<a class="reference external" href="https://elifesciences.org/articles/53385">dockes, poldrack, …, yarkonig, suchanek, thirion, &amp; varoquax</a>) [<a class="reference external" href="https://neuroquery.org/query?text=checkerboard">website</a>]</p>
<ul>
<li><p>train on keywords to directly predict weights for each query-expanded keyword and the produce linearly combined brainmap</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</section>
<section id="speech-ecog">
<h3><span class="section-number">5.5.8.4. </span>speech / ECoG<a class="headerlink" href="#speech-ecog" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Improving semantic understanding in speech language models via brain-tuning (<a class="reference external" href="https://arxiv.org/abs/2410.09230">moussa, klakow, &amp; toneva, 2024</a>)</p>
<ul>
<li><p>BrainWavLM: Fine-tuning Speech Representations with Brain Responses to Language (<a class="reference external" href="https://arxiv.org/abs/2502.08866">vattikonda, vaidya, antonello, &amp; huth, 2025</a>)</p></li>
</ul>
</li>
<li><p>A shared model-based linguistic space for transmitting our thoughts from brain to brain in natural conversations (<a class="reference external" href="https://www.cell.com/neuron/fulltext/S0896-6273(24)00460-4">zada…hasson, 2024</a>)</p>
<ul>
<li><p>previous inter-subject correlation analyses directly map between speaker’s brain activity &amp; listener’s brain activity during communication</p></li>
<li><p>this work adds a semantic feature space to predict speaker/listener activity &amp; partitions predicting the other person’s brain activity from these</p></li>
</ul>
</li>
</ul>
</section>
</section>
<section id="advanced-topics">
<h2><span class="section-number">5.5.9. </span>advanced topics<a class="headerlink" href="#advanced-topics" title="Link to this heading">#</a></h2>
<section id="high-dimensional-hyperdimensional-computing">
<h3><span class="section-number">5.5.9.1. </span>high-dimensional (hyperdimensional) computing<a class="headerlink" href="#high-dimensional-hyperdimensional-computing" title="Link to this heading">#</a></h3>
<p><em>computing with random high-dim vectors (also known as vector-symbolic architectures)</em></p>
<p>Good overview website: <a class="reference external" href="https://www.hd-computing.com">https://www.hd-computing.com</a></p>
<ul class="simple">
<li><p><a class="reference external" href="https://www.youtube.com/watch?v=82syi1BH_YY">ovw talk</a> (kanerva, 2022)</p>
<ul>
<li><p>has slide with related references</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://link.springer.com/article/10.1007/s10462-021-10110-3">A comparison of vector symbolic architectures</a> (schlegel et al. 2021)</p></li>
</ul>
<p><strong>motivation</strong></p>
<ul class="simple">
<li><p>high-level overview</p>
<ul>
<li><p>draw inspiration from circuits not single neurons</p></li>
<li><p>the brain’s circuits are high-dimensional</p></li>
<li><p>elements are stochastic not deterministic</p></li>
<li><p>no 2 brains are alike yet they exhibit the same behavior</p></li>
</ul>
</li>
<li><p>basic question of comp neuro: what kind of computing can explain behavior produced by spike trains?</p>
<ul>
<li><p>recognizing ppl by how they look, sound, or behave</p></li>
<li><p>learning from examples</p></li>
<li><p>remembering things going back to childhood</p></li>
<li><p>communicating with language</p></li>
</ul>
</li>
</ul>
<p><strong>operations</strong></p>
<ul>
<li><p>ex. vectors <span class="math notranslate nohighlight">\(A\)</span>, <span class="math notranslate nohighlight">\(B\)</span> both <span class="math notranslate nohighlight">\(\in \{ +1, -1\}^{10,000}\)</span> (also extends to real / complex vectors)</p></li>
<li><p>3 operations</p>
<ol class="arabic simple">
<li><p><strong>addition</strong>: A + B = (0, 0, 2, 0, 2,-2, 0,  ….)</p></li>
</ol>
<ul class="simple">
<li><p>alternatively, could take mean</p></li>
</ul>
<ol class="arabic simple">
<li><p><strong>multiplication</strong>: A * B =  (-1, -1, -1, 1, 1, -1, 1, …) - this is <strong>XOR</strong></p></li>
</ol>
<ul class="simple">
<li><p>want this to be invertible, distribute over addition, preserve distance, and be dissimilar to the vectors being multiplied</p></li>
<li><p>number of ones after multiplication is the distance between the two original vectors</p></li>
<li><p>can represent a dissimilar set vector by using multiplication</p></li>
</ul>
<ol class="arabic simple">
<li><p><strong>permutation</strong>: shuffles values (like bit-shift)</p></li>
</ol>
<ul class="simple">
<li><p>ex. rotate (bit shift with wrapping around)</p></li>
<li><p>multiply by rotation matrix (where each row and col contain exactly one 1)</p></li>
<li><p>can think of permutation as a list of numbers 1, 2, …, n in permuted order</p></li>
<li><p>many properties similar to multiplication</p></li>
<li><p>random permutation randomizes</p></li>
</ul>
</li>
<li><p>secondary operations</p>
<ul class="simple">
<li><p>weighting by a scalar</p></li>
<li><p>similarity = dot product (sometimes normalized)</p>
<ul>
<li><p>A <span class="math notranslate nohighlight">\(\cdot\)</span> A = 10k</p></li>
<li><p>A <span class="math notranslate nohighlight">\(\cdot\)</span> A = 0 (orthogonal)</p></li>
<li><p>in high-dim spaces, almost all pairs of vectors are dissimilar A <span class="math notranslate nohighlight">\(\cdot\)</span> B = 0</p></li>
<li><p>goal: similar meanings should have large similarity</p></li>
</ul>
</li>
<li><p>normalization</p>
<ul>
<li><p>for binary vectors, just take the sign</p></li>
<li><p>for non-binary vectors, scalar weight</p></li>
</ul>
</li>
<li><p>fractional binding - can bind different amounts rather than binary similar / dissimilar</p></li>
</ul>
</li>
</ul>
<p><strong>data structures</strong></p>
<p>the operations above allow for encoding many normal data structures into a single vector</p>
<ol class="arabic simple">
<li><p><strong>set</strong> - can be represented with a sum (since the sum is similar to all the vectors)</p></li>
</ol>
<ul class="simple">
<li><p>can find a stored set using any element</p></li>
<li><p>if we don’t store the sum, can probe with the sum and keep subtracting the vectors we find</p></li>
</ul>
<ol class="arabic simple">
<li><p><strong>multiset</strong> = bag (stores set with frequency counts) - can store things with order by adding them multiple times, but hard to actually retrieve frequencies</p></li>
<li><p><strong>sequence</strong> - could have each element be an address pointing to the next element</p></li>
</ol>
<ul class="simple">
<li><p>problem - hard to represent sequences that share a subsequence (could have pointers which skip over the subsquence)</p></li>
<li><p>soln: index elements based on permuted sums</p>
<ul>
<li><p>can look up an element based on previous element or previous string of elements</p></li>
</ul>
</li>
<li><p>could do some kind of weighting also</p></li>
</ul>
<ol class="arabic simple">
<li><p><strong>pairs</strong> - could just multiply (XOR), but then get some weird things, e.g. A * A = <strong>0</strong></p></li>
</ol>
<ul class="simple">
<li><p>instead, permute then multiply</p></li>
<li><p>can use these to index (address, value) pairs and make more complex data structures</p></li>
</ul>
<ol class="arabic simple">
<li><p><strong>named tuples</strong> - have smth like (name: x, date: m, age: y)  and store as holistic vector <span class="math notranslate nohighlight">\(H = N*X + D *  M + A * Y\)</span></p></li>
</ol>
<ul class="simple">
<li><p>individual attribute value can be retrieved using vector for individual key</p></li>
<li><p>representation substituting is a little trickier….</p>
<ul>
<li><p>we blur what is a value and what is a variable</p></li>
<li><p>can do this for a pair or for a named tuple with new values</p>
<ul>
<li><p>this doesn’t always work</p></li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>examples</strong></p>
<ul class="simple">
<li><p>ex. semantic word vectors</p>
<ul>
<li><p>goal: get good semantic vectors for words</p>
<ul>
<li><p>baseline (e.g. latent-semantic analysis LSA): make matrix of word counts, where each row is a word, and each column is a document</p></li>
<li><p>add counts to each column – row vector becomes semantic vector</p></li>
</ul>
</li>
<li><p>HD computing alternative: each row is a word, but each document is assigned a few ~10 columns at random</p>
<ul>
<li><p>the number of columns doesn’t scale with the number of documents</p></li>
<li><p>can also do this randomness for the rows (so the number of rows &lt; the number of words)</p></li>
<li><p>can still get semantic vector for a row/column by adding together the rows/columns which are activated by that row/column</p></li>
</ul>
</li>
</ul>
</li>
<li><p>ex. semantic word vectors 2 (like word2vec)</p>
<ul>
<li><p>each word in vocab is given 2 vectors</p>
<ul>
<li><p>random-indexing vector - fixed random from the beginning</p></li>
<li><p>semantic vector - starts at 0</p></li>
</ul>
</li>
<li><p>as we traverse sequence, for each word, add random-indexing vector from words right before/after it to its semantic vector</p>
<ul>
<li><p>can also permute them before adding to preserve word order (e.g. permutations as a means to encode order in word space (<a class="reference external" href="https://www.diva-portal.org/smash/record.jsf?pid=diva2:1042478">kanerva, 2008</a>))</p>
<ul>
<li><p>can instead use placeholder vector to help bring in word order (e.g. BEAGLE - <a class="reference external" href="https://cseweb.ucsd.edu//~gary/PAPER-SUGGESTIONS/jones-mewhort-psych-rev-2007.pdf">Jones &amp; Mewhort, 2007</a>)</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>ex. learning rules by example</p>
<ul>
<li><p>particular instance of a rule is a rule (e.g mother-son-baby <span class="math notranslate nohighlight">\(\to\)</span> grandmother)</p>
<ul>
<li><p>as we get more examples and average them, the rule gets better</p></li>
<li><p>doesn’t always work (especially when things collapse to identity rule)</p></li>
</ul>
</li>
</ul>
</li>
<li><p>ex. what is the dollar of mexico? (<a class="reference external" href="https://redwood.berkeley.edu/wp-content/uploads/2020/05/kanerva2010what.pdf">kanerva, 2010</a>)</p>
<ul>
<li><p>initialize US = (NAME * USA) + (MONEY * DOLLAR)</p></li>
<li><p>initialize MEXICO = (NAME * MEXICO) + (MONEY * PESO)</p></li>
<li><p>query: “Dollar of Mexico”? = DOLLAR * US * MEXICO = PESO</p></li>
</ul>
</li>
<li><p>ex. <a class="reference external" href="https://iis-people.ee.ethz.ch/~arahimi/papers/DATE16_HD.pdf">text classification</a> (najafabadi et al. 2016)</p></li>
<li><p>ex. language classification - “Language Recognition using Random Indexing” (<a class="reference external" href="https://arxiv.org/abs/1412.7026">joshi et al. 2015</a>)</p>
<ul>
<li><p>scalable, easily use any-order ngrams</p></li>
<li><p>data</p>
<ul>
<li><p>train: given million bytes of text per language (in the same alphabet)</p></li>
<li><p>test: new sentences for each language</p></li>
</ul>
</li>
<li><p>training: compute a 10k profile vector for each language and for each test sentence</p>
<ul>
<li><p>could encode each letter with a seed vector which is 10k</p></li>
<li><p>instead encode trigrams with <strong>rotate and multiply</strong></p>
<ul>
<li><p>1st letter vec rotated by 2 * 2nd letter vec rotated by 1 * 3rd letter vec</p></li>
<li><p>ex. THE = r(r(T)) * r(H) * r(E)</p></li>
<li><p>approximately orthogonal to all the letter vectors and all the other possible trigram vectors…</p></li>
</ul>
</li>
<li><p>profile = sum of all trigram vectors (taken sliding)</p>
<ul>
<li><p>ex. banana = ban + ana + nan + ana</p></li>
<li><p>profile is like a histogram of trigrams</p></li>
</ul>
</li>
</ul>
</li>
<li><p>testing</p>
<ul>
<li><p>compare each test sentence to profiles via dot product</p></li>
<li><p>clusters similar languages</p></li>
<li><p>can query the letter most likely to follow “TH”</p>
<ul>
<li><p>form query vector <span class="math notranslate nohighlight">\(Q = r(r(T)) * r(H)\)</span></p></li>
<li><p>query by using multiply <span class="math notranslate nohighlight">\(X = Q\)</span> * english-profile-vec</p></li>
<li><p>find closest letter vecs to <span class="math notranslate nohighlight">\(X\)</span>: yields “e”</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>details</strong></p>
<ul class="simple">
<li><p>frequent “stopwords” should be ignored</p></li>
<li><p>mathematical background</p>
<ul>
<li><p>randomly chosen vecs are dissimilar</p></li>
<li><p>sum vector is similar to its argument vectors</p></li>
<li><p>product vector and permuted vector are dissimilar to their argument vectors</p></li>
<li><p>multiplication distibutes over addition</p></li>
<li><p>permutation distributes over both additions and multiplication</p></li>
<li><p>multiplication and permutations are invertible</p></li>
<li><p>addition is approximately invertible</p></li>
</ul>
</li>
<li><p>comparison to DNNs</p>
<ul>
<li><p>both do statistical learning from data</p></li>
<li><p>data can be noisy</p></li>
<li><p>both use high-dim vecs although DNNs get bad with him dims (e.g. 100k)</p></li>
<li><p>new codewords are made from existing ones</p></li>
<li><p>HD memory is a separate func</p></li>
<li><p>HD algos are transparent, incremental (on-line), scalable</p>
<ul>
<li><p>somewhat closer to the brain…cerebellum anatomy seems to better match HD</p></li>
</ul>
</li>
<li><p>HD: holistic (distributed repr.) is robust</p></li>
</ul>
</li>
</ul>
<p><strong>HD papers</strong></p>
<p><a class="reference external" href="https://github.com/HyperdimensionalComputing/collection">HDComputing Github Repos</a> (see <a class="reference external" href="https://github.com/hyperdimensional-computing/torchhd">torchhd</a>)</p>
<ul class="simple">
<li><p><a class="reference external" href="https://link.springer.com/content/pdf/10.1007/s12559-009-9009-8.pdf">HD computing overview paper</a> (Kanerva, 2009)</p>
<ul>
<li><p>in these high dimensions, most points are close to equidistant from one another (L1 distance), and are approximately orthogonal (dot product is 0)</p></li>
<li><p>memory</p>
<ul>
<li><p><em>heteroassociative</em> - can return stored <em>X</em> based on its address <em>A</em></p></li>
<li><p><em>autoassociative</em> - can return stored <em>X</em> based on a noisy version of <em>X</em> (since it is a point attractor), maybe with some iteration</p>
<ul>
<li><p>this adds robustness to the memory</p></li>
<li><p>this also removes the need for addresses altogether</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>Classification and Recall With Binary Hyperdimensional Computing: Tradeoffs in Choice of Density and Mapping Characteristics (<a class="reference external" href="https://ieeexplore.ieee.org/abstract/document/8331890?casa_token=FbderL4T3RgAAAAA:LfP2kRSJwhY5z4OHMqvNDrxmSpyIMLzGs80vGj_IdBXVhVVDwZg1tfIeD2nj0S5N7T2YsRrOcg">kleyko et al. 2018</a>)</p>
<ul>
<li><p>note: for sparse vectors, might need some threshold before computing mean (otherwise will have too many zeros)</p></li>
</ul>
</li>
<li><p>Neural Statistician (<a class="reference external" href="https://arxiv.org/abs/1606.02185">Edwards &amp; Storkey, 2016</a>) summarises a dataset by averaging over their embeddings</p></li>
<li><p>kanerva machine (<a class="reference external" href="https://arxiv.org/pdf/1804.01756.pdf">yu…lillicrap, 2018</a>)</p>
<ul>
<li><p>like a VAE where the prior is derived from an adaptive memory store</p></li>
</ul>
</li>
<li><p>theory of sequence indexing and working memory in RNNs</p>
<ul>
<li><p>trying to make key-value pairs</p></li>
<li><p>VSA as a structured approach for understanding neural networks</p></li>
<li><p>reservoir computing = state-dependent network = echos-state network = liquid state machine - try to represen sequential temporal data - builds representations on the fly</p></li>
</ul>
</li>
<li><p>different names</p>
<ul>
<li><p>Tony plate: <a class="reference external" href="https://ieeexplore.ieee.org/abstract/document/377968?casa_token=L3jgIZw7e5QAAAAA:m7VbqpNlZkL3kPU1faJe6XDVIxi5N55iToDKMndnknmBFFP7Boi2HZMI2ODCkzX0oXbanAqsZBg">holographic reduced representation</a> (1995)</p>
<ul>
<li><p>related to TPR by paul smolensky</p></li>
</ul>
</li>
<li><p>ross gayler: multiply-add-permute arch</p></li>
<li><p>gayler &amp; levi: vector-symbolic arch</p></li>
<li><p>gallant &amp; okaywe: matrix binding with additive terms</p></li>
<li><p>fourier holographic reduced reprsentations (FHRR; Plate)</p></li>
<li><p>…many more names</p></li>
</ul>
</li>
<li><p>connecting to DNNs</p>
<ul>
<li><p>Attention Approximates Sparse Distributed Memory <a class="reference external" href="https://arxiv.org/pdf/2111.05498.pdf">https://arxiv.org/pdf/2111.05498.pdf</a></p></li>
<li><p>The Kanerva Machine: A Generative Distributed Memory (<a class="reference external" href="https://arxiv.org/abs/1804.01756">wu…lillicrap, 2018</a>)</p></li>
</ul>
</li>
</ul>
</section>
<section id="dynamic-routing-between-capsules">
<h3><span class="section-number">5.5.9.2. </span>dynamic routing between capsules<a class="headerlink" href="#dynamic-routing-between-capsules" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>hinton 1981 - reference frames require structured representations</p>
<ul>
<li><p>mapping units vote for different orientations, sizes, positions based on basic units</p></li>
<li><p>mapping units <strong>gate the activity</strong> from other types of units - weight is dependent on if mapping is activated</p></li>
<li><p>top-down activations give info back to mapping units</p></li>
<li><p>this is a hopfield net with three-way connections (between input units, output units, mapping units)</p></li>
<li><p>reference frame is a key part of how we see - need to vote for transformations</p></li>
</ul>
</li>
<li><p>olshausen, anderson, &amp; van essen 1993 - dynamic routing circuits</p>
<ul>
<li><p>ran simulations of such things (hinton said it was hard to get simulations to work)</p></li>
<li><p>learn things in object-based reference frames</p></li>
<li><p>inputs -&gt; outputs has weight matrix gated by control</p></li>
</ul>
</li>
<li><p>zeiler &amp; fergus 2013 - visualizing things at intermediate layers - deconv (by dynamic routing)</p>
<ul>
<li><p>save indexes of max pooling (these would be the control neurons)</p></li>
<li><p>when you do deconv, assign max value to these indexes</p></li>
</ul>
</li>
<li><p>arathom 02 - map-seeking circuits</p></li>
<li><p>tenenbaum &amp; freeman 2000 - bilinear models</p>
<ul>
<li><p>trying to separate content + style</p></li>
</ul>
</li>
<li><p>hinton et al 2011 - transforming autoencoders - trained neural net to learn to shift imge</p></li>
<li><p>sabour et al 2017 - dynamic routing between capsules</p>
<ul>
<li><p>units output a vector (represents info about reference frame)</p></li>
<li><p>matrix transforms reference frames between units</p></li>
<li><p>recurrent control units settle on some transformation to identify reference frame</p></li>
</ul>
</li>
<li><p>notes from this <a class="reference external" href="https://towardsdatascience.com/capsule-neural-networks-part-2-what-is-a-capsule-846d5418929f">blog post</a></p>
<ul>
<li><p>problems with cnns</p>
<ul>
<li><p>pooling loses info</p></li>
<li><p>don’t account for spatial relations between image parts</p></li>
<li><p>can’t transfer info to new viewpoints</p></li>
</ul>
</li>
<li><p><strong>capsule</strong> - vector specifying the features of an object (e.g. position, size, orientation, hue texture) and its likelihood</p>
<ul>
<li><p>ex. an “eye” capsule could specify the probability it exists, its position, and its size</p></li>
<li><p>magnitude (i.e. length) of vector represents probability it exists (e.g. there is an eye)</p></li>
<li><p>direction of vector represents the instantiation parameters (e.g. position, size)</p></li>
</ul>
</li>
<li><p>hierarchy</p>
<ul>
<li><p>capsules in later layers are functions of the capsules in lower layers, and since capsule has extra properties can ask questions like “are both eyes similarly sized?”</p>
<ul>
<li><p>equivariance = we can ensure our net is invariant to viewpoints by checking for all similar rotations/transformations in the same amount/direction</p></li>
</ul>
</li>
<li><p>active capsules at one level make predictions for the instantiation parameters of higher-level capsules</p>
<ul>
<li><p>when multiple predictions agree, a higher-level capsule is activated</p></li>
</ul>
</li>
</ul>
</li>
<li><p>steps in a capsule (e.g. one that recognizes faces)</p>
<ul>
<li><p>receives an input vector (e.g. representing eye)</p></li>
<li><p>apply affine transformation - encodes spatial relationships (e.g. between eye and where the face should be)</p></li>
<li><p>applying weighted sum by the C weights, learned by the routing algorithm</p>
<ul>
<li><p>these weights are learned to group similar outputs to make higher-level capsules</p></li>
</ul>
</li>
<li><p>vectors are squashed so their magnitudes are between 0 and 1</p></li>
<li><p>outputs a vector</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</section>
<section id="hierarchical-temporal-memory-htm-numenta">
<h3><span class="section-number">5.5.9.3. </span>hierarchical temporal memory (htm, numenta)<a class="headerlink" href="#hierarchical-temporal-memory-htm-numenta" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>binary synapses and learns by modeling the growth of new synapses and the decay of unused synapses</p></li>
<li><p>separates aspects of brains and neurons that are essential for intelligence from those that depend on brain implementation</p></li>
<li><p>terminology changed from HTM to Thousand Brains Theory</p></li>
</ul>
<section id="necortical-structure">
<h4><span class="section-number">5.5.9.3.1. </span>necortical structure<a class="headerlink" href="#necortical-structure" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p>evolution yields physical/logical hierarchy of brain regions</p></li>
<li><p>neocortex is like a flat sheet</p></li>
<li><p>neocortex regions are similar and do similar computation</p>
<ul>
<li><p>Mountcastle 1978: vision regions are vision becase they receive visual input</p></li>
<li><p>number of regions / connectivity seems to be genetic</p></li>
</ul>
</li>
<li><p>before necortex, brain regions were homogenous: spinal cord, brain stem, basal ganglia, …</p></li>
<li><p><img alt="cortical_columns" src="../../_images/cortical_columns.png" /></p></li>
</ul>
</section>
<section id="principles">
<h4><span class="section-number">5.5.9.3.2. </span>principles<a class="headerlink" href="#principles" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p>common algorithms accross neocortex</p></li>
<li><p>hierarchy</p></li>
<li><p><strong>sparse distributed representations (SDR)</strong> - vectors with thousands of bits, mostly 0s</p>
<ul>
<li><p>bits of representation encode semantic properties</p></li>
<li><p>ex. k-winner-take-all layer (needs boosting term to favor units that are activated less frequently so that a few neurons don’t take all the info)</p></li>
</ul>
</li>
<li><p>inputs</p>
<ul>
<li><p>data from the senses</p></li>
<li><p>copy of the motor commands</p>
<ul>
<li><p>“sensory-motor” integration - perception is stable while the eyes move</p></li>
</ul>
</li>
</ul>
</li>
<li><p>patterns are constantly changing</p></li>
<li><p>necortex tries to control old brain regions which control muscles</p></li>
<li><p><strong>learning</strong>: region accepts stream of sensory data + motor commands</p>
<ul>
<li><p>learns of changes in inputs</p></li>
<li><p>ouputs motor commands</p></li>
<li><p>only knows how its output changes its input</p></li>
<li><p>must learn how to control behavior via <em>associative linking</em></p></li>
</ul>
</li>
<li><p>sensory encoders - takes input and turnes it into an SDR</p>
<ul>
<li><p>engineered systems can use non-human senses</p></li>
</ul>
</li>
<li><p>behavior needs to be incorporated fully</p></li>
<li><p>temporal memory - is a memory of sequences</p>
<ul>
<li><p>everything the neocortex does is based on memory and recall of sequences of patterns</p></li>
</ul>
</li>
<li><p>on-line learning</p>
<ul>
<li><p>prediction is compared to what actually happens and forms the basis of learning</p></li>
<li><p>minimize the error of predictions</p></li>
</ul>
</li>
<li><p>performance works better on chips like FPGAs compared to GPUs</p></li>
</ul>
</section>
<section id="papers">
<h4><span class="section-number">5.5.9.3.3. </span>papers<a class="headerlink" href="#papers" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p>A thousand brains: toward biologically constrained AI (<a class="reference external" href="https://link.springer.com/article/10.1007/s42452-021-04715-0">hole &amp; ahmad, 2021</a>)</p></li>
<li><p>A Theory of How Columns in the Neocortex Enable Learning the Structure of the World (<a class="reference external" href="https://www.frontiersin.org/articles/10.3389/fncir.2017.00081/full">hawkins et al. 2017</a>)</p>
<ul>
<li><p>single column - integrate touches over time - represent objects properly</p></li>
<li><p>multiple columns - integrate spatial inputs - make things fast</p>
<ul>
<li><p>like different sensory patches (e.g. different fingers or different rods on the retina) are all simultaneously voting</p></li>
</ul>
</li>
<li><p>network model that learns the structure of objects through movement</p></li>
<li><p>object recognition</p>
<ul>
<li><p>over time individual columns integrate changing inputs to recognize complete objects</p></li>
<li><p>through existing lateral connections</p></li>
</ul>
</li>
<li><p>within each column, neocortex is calculating a location representation</p>
<ul>
<li><p>locations relative to each other = <strong>allocentric</strong></p></li>
</ul>
</li>
<li><p>much more motion involved</p></li>
</ul>
</li>
<li><p>“Why Neurons Have Thousands of Synapses, A Theory of Sequence Memory in Neocortex”</p>
<ul>
<li><p>learning and recalling sequences of patterns</p></li>
<li><p>neuron with lots of synapses can learn transitions of patterns</p></li>
<li><p>network of these can form robust memory</p></li>
</ul>
</li>
<li><p>How Can We Be So Dense? The Benefits of Using Highly Sparse Representations (<a class="reference external" href="https://arxiv.org/abs/1903.11257">ahmda &amp; scheinkman, 2019</a>)</p>
<ul>
<li><p>high-dim sparse representations are more robust</p></li>
<li><p>info content of sparse vectors increases with dimensionality, without introducing additional non-zeros</p></li>
</ul>
</li>
</ul>
</section>
</section>
<section id="forgetting">
<h3><span class="section-number">5.5.9.4. </span>forgetting<a class="headerlink" href="#forgetting" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Continual Lifelong Learning with Neural Networks: A Review (<a class="reference external" href="https://arxiv.org/pdf/1802.07569.pdf">parisi…kanan, wermter, 2019</a>)</p>
<ul>
<li><p>main issues is <em>catastrophic forgetting</em> / <em>stability-plasticity dilemma</em></p></li>
<li><p><img alt="Screen Shot 2020-01-01 at 11.49.32 AM" src="../../_images/forgetting.png" /></p></li>
<li><p>2 types of plasticity</p>
<ul>
<li><p>Hebbian plasticity (Hebb 1949) for positive feedback instability</p></li>
<li><p>compensatory homeostatic plasticity which stabilizes neural activity</p></li>
</ul>
</li>
<li><p>approaches: regularization, dynamic architectures (e.g. add more nodes after each task), memory replay</p></li>
</ul>
</li>
</ul>
</section>
<section id="maximal-exciting-inputs">
<h3><span class="section-number">5.5.9.5. </span>maximal exciting inputs<a class="headerlink" href="#maximal-exciting-inputs" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>single-neuron (macaque)</p>
<ul>
<li><p>Neural population control via deep image synthesis (<a class="reference external" href="https://www.science.org/doi/abs/10.1126/science.aav9436">bashivan, kar, &amp; dicarlo, 2019</a>)</p></li>
<li><p>A biologically-inspired hierarchical convolutional energy model predicts V4 responses to natural videos (<a class="reference external" href="https://www.biorxiv.org/content/10.1101/2024.12.16.628781v1">oliver, winter, dupre la tour, eickenberg, &amp; gallant, 2024</a>)</p></li>
<li><p>Energy Guided Diffusion for Generating Neurally Exciting Images (<a class="reference external" href="https://www.biorxiv.org/content/10.1101/2023.05.18.541176v1">pierzchlewicz, …, tolias, sinz, 2023</a>)</p></li>
<li><p>Evolving images for visual neurons using a deep generative network reveals coding principles and neuronal preferences (<a class="reference external" href="https://www.sciencedirect.com/science/article/pii/S0092867419303915">ponce…livingstone, 2019</a>)</p></li>
<li><p>The DeepTune framework for modeling and characterizing neurons in visual cortex area V4 (<a class="reference external" href="https://www.biorxiv.org/content/10.1101/465534v1.abstract">abbasi-asl, …, yu, 2018</a>)</p></li>
<li><p>Compact deep neural network models of visual cortex (<a class="reference external" href="https://www.biorxiv.org/content/10.1101/2023.11.22.568315v1.abstract">cowley, stan, pillow, &amp; smith, 2023</a>)</p></li>
</ul>
</li>
<li><p>differentiating stimuli</p>
<ul>
<li><p>Model metamers reveal divergent invariances between biological and artificial neural networks (<a class="reference external" href="https://www.nature.com/articles/s41593-023-01442-0">feather…madry, mcdermott, 2024</a>) - studies that have used carefully designed stimuli have revealed that ANNs do not always align with humans</p></li>
<li><p>Universality of representation in biological and artificial neural networks (<a class="reference external" href="https://www.biorxiv.org/content/10.1101/2024.12.26.629294v1.full.pdf">hosseini…fedorenko, 2024</a>) - developed a method to identify stimuli that systematically vary the degree of inter-model representation agreement between ANNs and brains</p></li>
</ul>
</li>
<li><p>XDream: Finding preferred stimuli for visual neurons using generative networks and gradient-free optimization (<a class="reference external" href="https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1007973">2020</a>)</p></li>
<li><p>CORNN: Convex optimization of recurrent neural networks for rapid inference of neural dynamics (<a class="reference external" href="https://arxiv.org/abs/2311.10200">dinc…tanaka, 2023</a>) - mouse population control</p></li>
<li><p>real-time mouse v1</p>
<ul>
<li><p>Inception in visual cortex: in vivo-silico loops reveal most exciting images (<a class="reference external" href="https://www.biorxiv.org/content/10.1101/506956.abstract">2018</a>)</p></li>
</ul>
</li>
<li><p>Adept: Adaptive stimulus selection for optimizing neural population responses (<a class="reference external" href="https://papers.nips.cc/paper/6738-adaptive-stimulus-selection-for-optimizing-neural-population-responses.pdf">cowley…byron yu, 2017</a>)</p>
<ul>
<li><p>select next image using kernel regression from CNN embeddings</p></li>
<li><p>pick next stimulus in closed-loop (“adaptive sampling” = “optimal experimental design”) for macaque v4</p></li>
</ul>
</li>
<li><p>From response to stimulus: adaptive sampling in sensory physiology (<a class="reference external" href="https://www.sciencedirect.com/science/article/pii/S095943880700092X">2007</a>)</p></li>
<li><p>find the smallest number of stimuli needed to fit parameters of a model that predicts the recorded neuron’s activity from the
stimulus</p></li>
<li><p>maximizing firing rates via genetic algorithms</p></li>
<li><p>maximizing firing rate via gradient ascent</p></li>
<li><p><a class="reference external" href="https://www.frontiersin.org/articles/10.3389/fncir.2013.00101/full">Adaptive stimulus optimization for sensory systems neuroscience</a></p>
<ul>
<li><p>2 general approaches: gradient-based approaches + genetic algorithms</p></li>
<li><p>can put constraints on stimulus space</p></li>
<li><p>stimulus adaptation</p></li>
<li><p>might want iso-response surfaces</p></li>
<li><p>maximally informative stimulus ensembles (Machens, 2002)</p></li>
<li><p>model-fitting: pick to maximize info-gain w/ model params</p></li>
<li><p>using fixed stimulus sets like white noise may be deeply problematic for efforts to identify non-linear hierarchical network models due to continuous parameter confounding (DiMattina and Zhang, 2010)</p></li>
<li><p>use for model selection</p></li>
</ul>
</li>
<li><p>Brain Diffusion for Visual Exploration: Cortical Discovery using Large Scale Generative Models (<a class="reference external" href="https://arxiv.org/abs/2306.03089">luo…wehbe, tarr, 2023</a>)</p></li>
</ul>
</section>
<section id="population-coding">
<h3><span class="section-number">5.5.9.6. </span>population coding<a class="headerlink" href="#population-coding" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Linking neural population formatting to function (<a class="reference external" href="https://www.biorxiv.org/content/10.1101/2025.01.03.631242v1.full.pdf">ruff…cohen, 2025</a>) - the function of a brain area is more related to how different types of information are combined (formatted) than merely whether that information is present</p></li>
<li><p>Towards the neural population doctrine (saxena…cunningham, 2019)</p>
<ul>
<li><p>correlated trial-to-trial variability</p>
<ul>
<li><p>Ni et al. showed that the correlated variability in V4 neurons during attention and learning — processes that have inherently different timescales — robustly decreases</p></li>
<li><p>‘choice’ decoder built on neural activity in the first PC performs as well as one built on the full dataset, suggesting that the relationship of neural variability to behavior lies in a relatively small subspace of the state space.</p></li>
</ul>
</li>
<li><p>decoding</p>
<ul>
<li><p>more neurons only helps if neuron doesn’t lie in span of previous neurons</p></li>
</ul>
</li>
<li><p>encoding</p>
<ul>
<li><p>can train dnn goal-driven or train dnn on the neural responses directly</p></li>
</ul>
</li>
<li><p>testing</p>
<ul>
<li><p>important to be able to test population structure directly</p></li>
</ul>
</li>
</ul>
</li>
<li><p><em>population vector coding</em> - ex. neurons coded for direction sum to get final direction</p></li>
<li><p>reduces uncertainty</p></li>
<li><p><em>correlation coding</em> - correlations betweeen spikes carries extra info</p></li>
<li><p><em>independent-spike coding</em> - each spike is independent of other spikes within the spike train</p></li>
<li><p><em>position coding</em> - want to represent a position</p>
<ul>
<li><p>for grid cells, very efficient</p></li>
</ul>
</li>
<li><p><em>sparse coding</em></p></li>
<li><p>hard when noise between neurons is correlated</p></li>
<li><p>measures of information</p></li>
<li><p>eda</p>
<ul>
<li><p>plot neuron responses</p></li>
<li><p>calc neuron covariances</p></li>
</ul>
</li>
</ul>
</section>
<section id="interesting-misc-papers">
<h3><span class="section-number">5.5.9.7. </span>interesting misc papers<a class="headerlink" href="#interesting-misc-papers" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>berardino 17 eigendistortions</p>
<ul>
<li><p><strong>Fisher info matrix</strong> under certain assumptions = <span class="math notranslate nohighlight">\(Jacob^TJacob\)</span> (pixels x pixels) where <em>Jacob</em> is the Jacobian matrix for the function f action on the pixels x</p></li>
<li><p>most and least noticeable distortion directions corresponding to the eigenvectors of the Fisher info matrix</p></li>
</ul>
</li>
<li><p>gao_19_v1_repr</p>
<ul>
<li><p>don’t learn from images - v1 repr should come from motion like it does in the real world</p></li>
<li><p>repr</p>
<ul>
<li><p>vector of local content</p></li>
<li><p>matrix of local displacement</p></li>
</ul>
</li>
<li><p>why is this repr nice?</p>
<ul>
<li><p>separate reps of static image content and change due to motion</p></li>
<li><p>disentangled rotations</p></li>
</ul>
</li>
<li><p>learning</p>
<ul>
<li><p>predict next image given current image + displacement field</p></li>
<li><p>predict next image vector given current frame vectors + displacement</p></li>
</ul>
</li>
</ul>
</li>
<li><p>friston_10_free_energy</p>
<ul>
<li><p><img alt="friston_free_energy" src="../../_images/friston_free_energy.png" /></p></li>
</ul>
</li>
</ul>
</section>
<section id="navigation">
<h3><span class="section-number">5.5.9.8. </span>navigation<a class="headerlink" href="#navigation" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>cognitive maps (tolman 1940s) - idea that rats in mazes learn spatial maps</p></li>
<li><p><strong>place cells</strong> (o’keefe 1971) - in the hippocampus - fire to indicate one’s current location</p>
<ul>
<li><p>remap to new locations</p></li>
</ul>
</li>
<li><p><strong>grid cells</strong> (moser &amp; moser 2005) - in the entorhinal cotex (provides inputs to the hippocampus) - not particular locations but rather hexagonal coordinate system</p>
<ul>
<li><p>grid cells fire if the mouse is in any location at the vertex (or center) of one of the hexagons</p></li>
</ul>
</li>
<li><p><img alt="Screen Shot 2019-05-10 at 1.25.02 PM" src="../../_images/mouse.png" /></p></li>
<li><p>there are grid cells with larger/smaller hexagons, different orientations, different offsets</p></li>
<li><p>can look for grid cells signature in fmri: <a class="reference external" href="https://www.nature.com/articles/nature08704">https://www.nature.com/articles/nature08704</a></p></li>
<li><p>other places with grid cell-like behavior</p></li>
<li><p>eye movement task</p></li>
<li><p>some evidence for grid cells in cortex</p>
<ul>
<li><p>Constantinescu, A., O’Reilly, J., Behrens, T. (2016) Organizing Conceptual Knowledge in Humans with a Gridlike Code. Science</p></li>
<li><p>Doeller, C. F., Barry, C., &amp; Burgess, N. (2010). Evidence for grid cells in a human memory network. Nature</p></li>
</ul>
</li>
<li><p>some evidence for “time cells” like place cells for time</p></li>
<li><p>sound frequency task <a class="reference external" href="https://www.nature.com/articles/nature21692">https://www.nature.com/articles/nature21692</a></p></li>
<li><p>2d “bird space” <a class="reference external" href="https://science.sciencemag.org/content/352/6292/1464.full?ijkey=sXaWNaNjkIcik&amp;amp;keytype=ref&amp;amp;siteid=sci">task</a></p></li>
</ul>
</section>
<section id="neuromorphic-computing">
<h3><span class="section-number">5.5.9.9. </span>neuromorphic computing<a class="headerlink" href="#neuromorphic-computing" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>neuromorphic examples</p>
<ul>
<li><p>differential pair sigmoid yields sigmoid-like function</p>
<ul>
<li><p>can compute <span class="math notranslate nohighlight">\(tanh\)</span> function really simply to simulate</p></li>
</ul>
</li>
<li><p>silicon retina</p>
<ul>
<li><p>lateral inhibition exists (gap junctions in horizontal cells)</p></li>
<li><p>analog VLSI retina: center-surround receptive field is very low energy</p></li>
<li><p>mead &amp; mahowald 1989</p></li>
</ul>
</li>
</ul>
</li>
<li><p>computation requires energy (otherwise signals would dissipate)</p>
<ul>
<li><p>von neumann architecture: CPU - bus (data / address) - Memory</p></li>
<li><p>moore’s law ending (in terms of cost, clock speed, etc.)</p>
<ul>
<li><p>ex. errors increase as device size decreases (and can’t tolerate any errors)</p></li>
</ul>
</li>
<li><p>neuromorphic computing</p>
<ul>
<li><p>brain ~ 20 Watts</p></li>
<li><p>exploit intrinsic transistor physics (need extremely small amounts of current)</p></li>
<li><p>exploit electronics laws kirchoff’s law, ohm’s law</p></li>
<li><p>new materials (ex. memristor - 3d crossbar array)</p></li>
<li><p>can’t just do biological mimicry - need to understand the principles</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</section>
<section id="locality-sensitive-hashing">
<h3><span class="section-number">5.5.9.10. </span>locality sensitive hashing<a class="headerlink" href="#locality-sensitive-hashing" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>locality-sensitive hashing is a <a class="reference external" href="https://en.wikipedia.org/wiki/Fuzzy_hashing">fuzzy hashing</a> technique that hashes similar input items into the same “buckets” with high probability</p>
<ul>
<li><p>hash collisions are maximized, rather than minimized as they are in dictionaries</p></li>
<li><p>finding embeddings via DNNs is a sepcial case of this (e.g. might call it “semantic hashing”)</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://www.biorxiv.org/content/biorxiv/early/2017/08/25/180471.full.pdf">random projections in the brain</a>….doing locality sensitive hashing (basically nearest neighbors)</p></li>
</ul>
</section>
</section>
<section id="neuro-inspired-ai-niai">
<h2><span class="section-number">5.5.10. </span>neuro-inspired ai (niAI)<a class="headerlink" href="#neuro-inspired-ai-niai" title="Link to this heading">#</a></h2>
<section id="neuro-dl-reviews">
<h3><span class="section-number">5.5.10.1. </span>neuro-dl reviews<a class="headerlink" href="#neuro-dl-reviews" title="Link to this heading">#</a></h3>
<ul>
<li><p>Blog post (<a class="reference external" href="https://xcorr.net/2023/01/01/2022-in-review-neuroai-comes-of-age/">xcorr, 2023</a>)</p></li>
<li><p>Neuroscience-Inspired Artificial Intelligence (<a class="reference external" href="https://www.cell.com/neuron/pdf/S0896-6273(17)30509-3.pdf">hassabis et al. 2017</a>)</p></li>
<li><p>Catalyzing next-generation Artificial Intelligence through NeuroAI (<a class="reference external" href="https://arxiv.org/abs/2210.08340">zador, …bengio, dicarlo, lecun, …sejnowski, tsao, 2022</a>)</p></li>
<li><p>Computational language modeling and the promise of in silico experimentation (<a class="reference external" href="https://direct.mit.edu/nol/article/doi/10.1162/nol_a_00101/114613/Computational-language-modeling-and-the-promise-of">jain, vo, wehbe, &amp; huth, 2023</a>) - 4 experimental design examples</p>
<ul class="simple">
<li><p>compare concrete &amp; abstract words (<a class="reference external" href="https://direct.mit.edu/jocn/article-abstract/17/6/905/4017/Distinct-Brain-Systems-for-Processing-Concrete-and">binder et al. 2005</a>)</p></li>
<li><p>contrast-based study of composition in 2-word phrase (<a class="reference external" href="https://www.jneurosci.org/content/31/8/2801.short">Bemis &amp; Pylkkanen, 2011</a>)</p></li>
<li><p>checks for effects between group and individual (<a class="reference external" href="https://www.jneurosci.org/content/31/8/2906">lerner et al. 2011</a>)</p></li>
<li><p>forgetting behavior using controlled manipulations (<a class="reference external" href="https://www.sciencedirect.com/science/article/pii/S0896627320301367">chien &amp; honey, 2020</a>)</p></li>
</ul>
</li>
<li><p>Dissociating language and thought in large language models (<a class="reference external" href="https://arxiv.org/abs/2301.06627">mahowald, …, tenebaum, fedorenko, 2023</a>)</p>
<ul>
<li><p>2 competences</p>
<ol class="arabic simple">
<li><p>formal linguistic competence - knowledge of rules and patterns of a given language</p></li>
<li><p>functional linguistic competence - cognitive abilities required for language understanding and use in the real world, e.g. formal reasoning, world knowledge, situation modeling, communicative intent</p>
<ul class="simple">
<li><p>much of world knowledge is implied: people are much more likely to communicate new or unusual information rather than commonly known facts</p></li>
</ul>
</li>
</ol>
<ul class="simple">
<li><p>language and thought are robustly dissociable in the brain</p>
<ul>
<li><p>aphasia studies: despite the nearly complete loss of linguistic abilities, some individuals with severe aphasia have intact non-linguistic cognitive abilities: they can play chess, compose music, solve arithmetic problems and logic puzzles, …</p></li>
<li><p>fMRI studies: the language network is extremely selective for language processing: it responds robustly and reliably when people listen to, read, or generate sentences , but not when they perform arithmetic tasks, engage in logical reasoning, understand computer programs, listen to music, …</p></li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2209.12407">Merrill et al. [2022]</a> - semantic information is in-principle learnable from language data</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2208.02957">Piantadosi and Hill [2022]</a> - an argument that models can genuinely learn meaning</p></li>
<li><p>Structured, flexible, and robust: benchmarking and improving large language models towards more human-like behavior in out-of-distribution reasoning tasks (<a class="reference external" href="http://arxiv.org/abs/2205.05718">collins…tenebaum, 2022</a>)</p>
<ul class="simple">
<li><p>as situation gets more OOD, LLM gets worse compared to human, e.g. <code class="docutils literal notranslate"><span class="pre">Get</span> <span class="pre">your</span> <span class="pre">sofa</span> <span class="pre">onto</span> <span class="pre">the</span> <span class="pre">roof</span> <span class="pre">of</span> <span class="pre">your</span> <span class="pre">house,</span> <span class="pre">without</span> <span class="pre">using</span> <span class="pre">a</span> <span class="pre">pulley,</span> <span class="pre">a</span> <span class="pre">ladder,</span> <span class="pre">a</span> <span class="pre">crane...</span></code></p></li>
</ul>
</li>
<li><p>recommendations</p>
<ul class="simple">
<li><p>modularity, curated data / diverse objectives, new benchmarks</p></li>
</ul>
</li>
</ul>
</li>
<li><p>Neurocompositional computing: From the Central Paradox of Cognition to a new generation of AI systems (<a class="reference external" href="https://ojs.aaai.org/index.php/aimagazine/article/view/18599">smolensky, …, gao, 2022</a>)</p></li>
<li><p>A Path Towards Autonomous Machine Intelligence (<a class="reference external" href="https://openreview.net/pdf?id=BZ5a1r-kVsf">lecun 2022</a>)</p></li>
<li><p><a class="reference external" href="https://www.semanticscholar.org/paper/Towards-NeuroAI%3A-Introducing-Neuronal-Diversity-Fan-Li/c0aae24f2e250c7d4b5aab608622dbb933f43a4d">Towards NeuroAI: Introducing Neuronal Diversity into Artificial Neural Networks</a> (2023)</p></li>
<li><p>A rubric for human-like agents andNeuroAI (<a class="reference external" href="https://royalsocietypublishing.org/doi/epdf/10.1098/rstb.2021.0446">momennejad, 2022</a>): 3 axes - human-like behavior, neural plausibility, &amp; engineering</p></li>
<li><p><a class="reference external" href="https://www.semanticscholar.org/paper/Designing-Ecosystems-of-Intelligence-from-First-Friston-Ramstead/98fcb39694d628788b555932f96134280f6a008e">Designing Ecosystems of Intelligence from First Principles</a> (friston et al. 2022)</p></li>
<li><p><a class="reference external" href="https://www.semanticscholar.org/paper/NeuroAI-A-strategic-opportunity-for-Norway-and-Nichele-S%C3%A6b%C3%B8/b5e7bacfdd6d080fce402a27b36757f6246eef4d">NeuroAI - A strategic opportunity for Norway and Europe</a> (2022)</p></li>
<li><p><a class="reference external" href="https://www.annualreviews.org/doi/abs/10.1146/annurev-neuro-100120-085519">Perceptual Inference, Learning, and Attention in a Multisensory World</a> (nopponey, 2021)</p></li>
<li><p><a class="reference external" href="https://www.sciencedirect.com/science/article/pii/S0896627319307408">Engineering a Less Artificial Intelligence</a> (sinz…tolias, 2019) - overview of ideas to make DNNs more brain-like</p></li>
</ul>
</section>
<section id="credit-assignment">
<h3><span class="section-number">5.5.10.2. </span>credit assignment<a class="headerlink" href="#credit-assignment" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Backpropagation and the brain (<a class="reference external" href="https://www.nature.com/articles/s41583-020-0277-3">lillicrap…hinton, 2020</a>)</p></li>
<li><p>Inferring neural activity before plasticity as a foundation for learning beyond backpropagation (<a class="reference external" href="https://www.nature.com/articles/s41593-023-01514-1">song…bogacz, 2024</a>) - use energy minimization before updating weights to help decide which weights to update</p></li>
</ul>
</section>
<section id="biological-constraints-for-dnns">
<h3><span class="section-number">5.5.10.3. </span>biological constraints for DNNs<a class="headerlink" href="#biological-constraints-for-dnns" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Aligning DNN with brain responses</p>
<ul>
<li><p>haven’t found anything like this for NLP</p></li>
<li><p>Aligning Model and Macaque Inferior Temporal Cortex Representations Improves Model-to-Human Behavioral Alignment and Adversarial Robustness (<a class="reference external" href="https://www.biorxiv.org/content/10.1101/2022.07.01.498495v1.abstract">dapello, kar, shrimpf…cox, dicarlo, 2022</a>) - finetune CNN embedding to match monkey brain (IT electrode recordings) before making classifications</p></li>
<li><p><a class="reference external" href="https://proceedings.neurips.cc/paper/2021/hash/06a9d51e04213572ef0720dd27a84792-Abstract.html">Towards robust vision by multi-task learning on monkey visual cortex</a> (safarani…sinz, 2021) - simultaneously predict monkey v1 (electrode data) and imagenet</p></li>
<li><p><a class="reference external" href="https://www.sciencedirect.com/science/article/pii/S0893608020302549?casa_token=UBMLt-J8JvgAAAAA:kWdL43r-oYZUUn4Mh41Z2XrMk7FU2WNJKXAvAdWmUjxKCgmTflUfV1tugLFLvQuUX9231x-6">Improved object recognition using neural networks trained to mimic the brain’s statistical properties - ScienceDirect</a> (federer et al. 2020) - simultaneously train CNN to classify objects + have similar reprs to monkey electrode data</p></li>
<li><p><a class="reference external" href="https://proceedings.neurips.cc/paper/2019/hash/70117ee3c0b15a2950f1e82a215e812b-Abstract.html">Learning from brains how to regularize machines</a> (li …, tolias 2019) - regularize intermediate representations using mouse v1 data (optical imaging) for image classification</p></li>
<li><p>A Neurobiological Evaluation Metric for Neural Network Model Search (<a class="reference external" href="https://openaccess.thecvf.com/content_CVPR_2019/html/Blanchard_A_Neurobiological_Evaluation_Metric_for_Neural_Network_Model_Search_CVPR_2019_paper.html">blanchard, …, bashivan, scheirer, 2019</a>) - compare fMRI kernel matrix to DNN kernel matrix - find that the closer it is, the better a network is (and use this metric to perform early stopping)</p></li>
<li><p>aligning with experimental/psychological data</p>
<ul>
<li><p><a class="reference external" href="https://openreview.net/forum?id=c0l2YolqD2T">How Well Do Unsupervised Learning Algorithms Model Human Real-time and Life-long Learning? | OpenReview</a> (zhuang…dicarlo, yamins, 2022)</p></li>
</ul>
</li>
</ul>
</li>
<li><p>Biologically-inspired DNNs (not data-driven)</p>
<ul>
<li><p>Relating transformers to models and neural representations of the hippocampal formation (<a class="reference external" href="https://arxiv.org/abs/2112.04035">whittington, warren, &amp; behrens, 2022</a>)</p>
<ul>
<li><p>transformers, when equipped with recurrent position encodings, replicate the pre- cisely tuned spatial representations of the hippocampal formation; most notably place and grid cells</p></li>
</ul>
</li>
<li><p>Emergence of foveal image sampling from learning to attend in visual scenes (<a class="reference external" href="https://arxiv.org/abs/1611.09430">cheung, weiss, &amp; olshausen, 2017</a>) - using neural attention model, learn a retinal sampling lattice</p>
<ul>
<li><p>can figure out what parts of the input the model focuses on</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://proceedings.neurips.cc/paper/2020/hash/98b17f068d5d9b7668e19fb8ae470841-Abstract.html">Simulating a Primary Visual Cortex at the Front of CNNs Improves Robustness to Image Perturbations</a> (dapello…cox, dicarlo, 2020) - biologically inspired early neural-network layers (gabors etc.) improve robustness of CNNs</p>
<ul>
<li><p><a class="reference external" href="https://proceedings.neurips.cc/paper/2019/hash/7813d1590d28a7dd372ad54b5d29d033-Abstract.html">Brain-Like Object Recognition with High-Performing Shallow Recurrent ANNs</a> (kubilius, schrimpt, kar, …, yamins, dicarlo, 2019)</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2110.10645">Combining Different V1 Brain Model Variants to Improve Robustness to Image Corruptions in CNNs</a> (baidya, dapello, dicarlo, &amp; marques, 2021)</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://proceedings.neurips.cc/paper/2019/hash/c535e3a7f97daf1c4b1eb03cc8e31623-Abstract.html">Surround Modulation: A Bio-inspired Connectivity Structure for Convolutional Neural Networks</a> (hasani, …, aghajan, 2019) - add inhibitory lateral connections in CNNs</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1703.09202">Biologically inspired protection of deep networks from adversarial attacks</a> (nayebi &amp; ganguli, 2017) - change training to get highly nonlinear, saturated neural nets</p></li>
<li><p><a class="reference external" href="https://www.nature.com/articles/s41583-021-00473-5">Biological constraints on neural network models of cognitive function</a> (pulvermuller, …, wennekers, 2021) - review on biological constraints</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2210.01768">Disentangling with Biological Constraints: A Theory of Functional Cell Types</a></p></li>
</ul>
</li>
</ul>
</section>
<section id="id2">
<h3><span class="section-number">5.5.10.4. </span>overview<a class="headerlink" href="#id2" title="Link to this heading">#</a></h3>
<p><strong>explaining concepts from neuroscience to inform deep learning</strong></p>
<p>The brain currently outperforms deep learning in a number of different ways: efficiency, parallel computation, not forgetting, robustness. Thus, in these areas and others, the brain can offer high-level inspiration as well as more detailed algorithmic ideas on how to solve complex problems.</p>
<p>We begin with some history and perspective before further exploring these concepts at 3 levels: (1) the neuron level, (2) the network level, and (3) high-level concepts.</p>
<p><strong>brief history</strong></p>
<p>The history of deep learning is intimately linked with neuroscience. In vision, the idea of hierarchical processing dates back to Hubel and Weisel <dt-cite key="hubel1962receptive"></dt-cite> and the modern idea of convolutional neural networks dates back to the necognitron<dt-cite key="fukushima1982neocognitron"></dt-cite>.</p>
<p>Ranges from neurally-inspired -&gt; biologically plausible</p>
<p>Computational neuroscientists often discuss understanding computation at Marr’s 3 levels of understanding: (1) computational, (2) algorithmic, and (3) mechanistic<dt-cite key="marr1976understanding"></dt-cite>. The first two levels are most crucial to understanding here, while the third may yield insights for the field of neuromorphic computing <dt-cite key="schuman2017survey"></dt-cite>.</p>
<p><strong>cautionary notes</strong></p>
<p>There are dangers in deep learning researchers constraining themselves to biologically plausible algorithms. First, the underlying hardware of the brain and modern von Neumman-based architectures is drastically different and one should not assume that the same algorithms will work on both systems. Several examples, such as backpropagation, were derived by deviating from the mindset of mimicking biology.</p>
<p>Second, the brain does not solve probleDangers for going too far…. One wouldn’t want to draw inspiration from the retina to put a hole in the camera.</p>
<p><img width="50%" src="figs/retina.png"></img>
Gallery of brain failures. Example, inside-out retina, V1 at back…</p>
<p><strong>neuron-level</strong></p>
<p>The fundamental unit of the brain is the neuron, which takes inputs from other neurons and then provides an output.</p>
<p>Individual neurons perform varying computations. Some neurons have been show to linearly sum their inputs <dt-cite key="singh2017consensus"></dt-cite></p>
<ul class="simple">
<li><p>neurons are complicated (perceptron -&gt; … -&gt; detailed comparmental model)</p></li>
</ul>
<p>For more information, see a very good review on modeling individual neurons<dt-cite key="herz2006modeling"></dt-cite>.</p>
<ul class="simple">
<li><p>converting to spikes introduces noise <dt-cite key="carandini2004amplification"></dt-cite>- perhaps just price of long-distance communication</p></li>
</ul>
<p><strong>network-level</strong></p>
<p>Artificial neural networks can compute in several different ways. There is some evidence in the visual system that neurons in higher layers of visual areas can, to some extent, be predicted linearly by higher layers of deep networks<dt-cite key="yamins2014performance"></dt-cite>. However, this certainly isn’t true in general. Key factors</p>
<p>For the simplest intuition, here we provide an example of a canonical circuit for computing the maximum of a number of elements: the winner-take-all circuit.</p>
<p>Other network structures, such as that of the hippocampus are surely useful as well.</p>
<p>Questions at this level bear on population coding, or how groups of neurons jointly represent information.</p>
<p><strong>engram</strong> - unit of <a class="reference external" href="https://en.wikipedia.org/wiki/Cognition">cognitive</a> information imprinted in a physical substance, theorized to be the means by which <a class="reference external" href="https://en.wikipedia.org/wiki/Memory">memories</a> are stored</p>
<p><strong>high-level concepts</strong></p>
<p>Key concepts differentiate the learning process. Online,</p>
<ul class="simple">
<li><p>learning</p></li>
<li><p>high-level</p>
<ul>
<li><p>attention</p></li>
<li><p>memory</p></li>
<li><p>robustness</p></li>
<li><p>recurrence</p></li>
<li><p>topology</p></li>
<li><p>glial cells</p></li>
</ul>
</li>
<li><p>inspirations</p>
<ul>
<li><p>canonical cortical microcircuits</p></li>
<li><p>nested loop architectures</p></li>
<li><p>avoiding catostrophic forgetting through synaptic complexity</p></li>
<li><p>learning asymmetric recurrent generative models</p></li>
</ul>
</li>
<li><p>spiking networks (<a class="reference external" href="https://github.com/Hananel-Hazan/bindsnet">bindsnet</a>)</p></li>
<li><p>Computational Theory of Mind</p>
<ul>
<li><p>Classical associationism</p></li>
<li><p>Connectionism</p></li>
<li><p>Situated cognition</p></li>
<li><p>Memory-prediction framework</p></li>
<li><p>Fractal Theory: <a class="reference external" href="https://www.youtube.com/watch?v=axaH4HFzA24">https://www.youtube.com/watch?v=axaH4HFzA24</a></p></li>
<li><p>Brain sheets are made of cortical columns (about .3mm diameter, 1000 neurons / column)</p>
<ul>
<li><p>Have ~6 layers</p></li>
</ul>
</li>
</ul>
</li>
<li><p>Brain as a Computer – Analog VLSI and Neural Systems by Mead (VLSI – very large scale integration)</p></li>
<li><p>Process info</p></li>
<li><p>Signals represented by potential</p>
<ul>
<li><p>Signals are amplified = gain</p></li>
<li><p>Power supply</p></li>
<li><p>Knowledge is not stored in knowledge of the parts, but in their connections</p></li>
<li><p>Based on electrically charged entities interacting with energy barriers</p></li>
<li><p><a class="reference external" href="http://en.wikipedia.org/wiki/Computational_theory_of_mind">http://en.wikipedia.org/wiki/Computational_theory_of_mind</a></p></li>
<li><p><a class="reference external" href="http://scienceblogs.com/developingintelligence/2007/03/27/why-the-brain-is-not-like-a-co/">http://scienceblogs.com/developingintelligence/2007/03/27/why-the-brain-is-not-like-a-co/</a></p></li>
<li><p>Brain’ storage capacity is about 2.5 petabytes (Scientific American, 2005)</p></li>
<li><p>Electronics</p></li>
<li><p>Voltage can be thought of as water in a reservoir at a height</p></li>
<li><p>It can flow down, but the water will never reach above the initial voltage</p></li>
<li><p>A capacitor is like a tank that collects the water under the reservoir</p></li>
<li><p>The capacitance is the cross-sectional area of the tank</p></li>
<li><p>Capacitance – electrical charge required to raise the potential by 1 volt</p></li>
<li><p>Conductance = 1/ resistance = mho, siemens</p></li>
<li><p>We could also say the word is a computer with individuals being the processors – with all the wasted thoughts we have – the solution is probably to identify global problems and channel people’s focus towards working on them</p></li>
<li><p>Brain chip: <a class="reference external" href="http://www.research.ibm.com/articles/brain-chip.shtml">http://www.research.ibm.com/articles/brain-chip.shtml</a></p></li>
<li><p>Brains are not digital</p></li>
<li><p>Brains don’t have a CPU</p></li>
<li><p>Memories are not separable from processing</p></li>
<li><p>Asynchronous and continuous</p></li>
<li><p>Details of brain substrate matter</p></li>
<li><p>Feedback and Circular Causality</p></li>
<li><p>Asking questions</p></li>
<li><p>Brains has lots of sensors</p></li>
<li><p>Lots of cellular diversity</p></li>
<li><p>NI uses lots of parallelism</p></li>
<li><p>Delays are part of the computation</p></li>
</ul>
</li>
<li><p><a class="reference external" href="http://timdettmers.com/">http://timdettmers.com/</a></p>
<ul>
<li><p>problems with brain simulations</p>
<ul>
<li><p>Not possible to test specific scientific hypotheses (compare this to the large hadron collider project with its perfectly defined hypotheses)</p></li>
<li><p>Does not simulate real brain processing (no firing connections, no biological interactions)</p></li>
<li><p>Does not give any insight into the functionality of brain processing (the meaning of the simulated activity is not assessed)</p></li>
</ul>
</li>
<li><p>Neuron information processing parts</p>
<ul>
<li><p>Dendritic spikes are like first layer of conv net</p></li>
<li><p>Neurons will typically have a genome that is different from the original genome that you were assigned to at birth. Neurons may have additional or fewer chromosomes and have sequences of information removed or added from certain chromosomes.</p></li>
<li><p><a class="reference external" href="http://timdettmers.com/2015/03/26/convolution-deep-learning/">http://timdettmers.com/2015/03/26/convolution-deep-learning/</a></p></li>
<li><p>The adult brain has 86 billion neurons, about 10 trillion synapse, and about 300 billion dendrites (tree-like structures with synapses on them</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./notes/neuro"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="sensory_input.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">5.4. </span>sensory input</p>
      </div>
    </a>
    <a class="right-next"
       href="disease.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">5.6. </span>disease</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">5.5.1. introduction</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#overview">5.5.1.1. overview</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#history">5.5.1.2. history</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#types-of-models">5.5.1.3. types of models</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#biophysical-models">5.5.2. biophysical models</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#modeling-neurons">5.5.2.1. modeling neurons</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simplified-model-neurons">5.5.2.2. simplified model neurons</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#modeling-dendrites-axons">5.5.2.3. modeling dendrites / axons</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#circuit-modeling-basics">5.5.2.4. circuit-modeling basics</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#action-potentials">5.5.2.5. action potentials</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#physics-of-computation">5.5.2.6. physics of computation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#spiking-neurons">5.5.2.7. spiking neurons</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#neural-coding">5.5.3. neural coding</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#neural-encoding">5.5.3.1. neural encoding</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#neural-decoding">5.5.3.2. neural decoding</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#information-theory">5.5.3.3. information theory</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#computing-with-networks">5.5.4. computing with networks</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#modeling-connections-between-neurons">5.5.4.1. modeling connections between neurons</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#intro-to-network-models">5.5.4.2. intro to network models</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#recurrent-networks">5.5.4.3. recurrent networks</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hopfield-nets">5.5.4.4. hopfield nets</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#learning">5.5.5. learning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#supervised-learning">5.5.5.1. supervised learning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#unsupervised-learning">5.5.5.2. unsupervised learning</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#hebbian-learning-and-pca">5.5.5.2.1. hebbian learning and pca</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#synaptic-plasticity-hebb-s-rule-and-statistical-learning">5.5.5.3. synaptic plasticity, hebb’s rule, and statistical learning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tensor-product-representation-tpr">5.5.5.4. tensor product representation (TPR)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sparse-coding-and-predictive-coding">5.5.5.5. sparse coding and predictive coding</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sparse-distributed-coding">5.5.5.6. sparse, distributed coding</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#self-organizing-maps-kohonen-maps">5.5.5.7. self-organizing maps = kohonen maps</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#probabilistic-models-inference">5.5.6. probabilistic models + inference</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#boltzmann-machines">5.5.6.1. boltzmann machines</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-driven-neuroscience">5.5.7. data-driven neuroscience</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-types">5.5.7.1. data types</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interventions">5.5.7.2. interventions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#datasets">5.5.7.3. datasets</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#language">5.5.7.3.1. language</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#misc">5.5.7.3.2. misc</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#eeg">5.5.7.4. eeg</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cross-subject-modeling">5.5.7.5. cross-subject modeling</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fmri">5.5.8. fMRI</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">5.5.8.1. language</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#semantic-decoding">5.5.8.2. semantic decoding</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#theories-of-explanation">5.5.8.3. theories of explanation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#speech-ecog">5.5.8.4. speech / ECoG</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#advanced-topics">5.5.9. advanced topics</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#high-dimensional-hyperdimensional-computing">5.5.9.1. high-dimensional (hyperdimensional) computing</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dynamic-routing-between-capsules">5.5.9.2. dynamic routing between capsules</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hierarchical-temporal-memory-htm-numenta">5.5.9.3. hierarchical temporal memory (htm, numenta)</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#necortical-structure">5.5.9.3.1. necortical structure</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#principles">5.5.9.3.2. principles</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#papers">5.5.9.3.3. papers</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#forgetting">5.5.9.4. forgetting</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#maximal-exciting-inputs">5.5.9.5. maximal exciting inputs</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#population-coding">5.5.9.6. population coding</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interesting-misc-papers">5.5.9.7. interesting misc papers</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#navigation">5.5.9.8. navigation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#neuromorphic-computing">5.5.9.9. neuromorphic computing</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#locality-sensitive-hashing">5.5.9.10. locality sensitive hashing</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#neuro-inspired-ai-niai">5.5.10. neuro-inspired ai (niAI)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#neuro-dl-reviews">5.5.10.1. neuro-dl reviews</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#credit-assignment">5.5.10.2. credit assignment</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#biological-constraints-for-dnns">5.5.10.3. biological constraints for DNNs</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">5.5.10.4. overview</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Chandan Singh
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright None.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  <p>
Many of these images are taken from resources on the web.
</p>
</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>