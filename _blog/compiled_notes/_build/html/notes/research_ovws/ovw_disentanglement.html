
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>1.2. disentanglement</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notes/research_ovws/ovw_disentanglement';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="1.3. omics" href="ovw_omics.html" />
    <link rel="prev" title="1.1. transfer learning" href="ovw_transfer_learning.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.png" class="logo__image only-light" alt=" - Home"/>
    <script>document.write(`<img src="../../_static/logo.png" class="logo__image only-dark" alt=" - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    overview 👋
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="research_ovws.html">1. research_ovws</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="ovw_transfer_learning.html">1.1. transfer learning</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">1.2. disentanglement</a></li>
<li class="toctree-l2"><a class="reference internal" href="ovw_omics.html">1.3. omics</a></li>
<li class="toctree-l2"><a class="reference internal" href="ovw_llms.html">1.4. llms</a></li>
<li class="toctree-l2"><a class="reference internal" href="ovw_complexity.html">1.5. complexity</a></li>
<li class="toctree-l2"><a class="reference internal" href="ovw_interesting_science.html">1.6. interesting science</a></li>
<li class="toctree-l2"><a class="reference internal" href="ovw_dl_theory.html">1.7. dl theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="ovw_scat.html">1.8. scattering transform</a></li>
<li class="toctree-l2"><a class="reference internal" href="ovw_ml_medicine.html">1.9. ml in medicine</a></li>
<li class="toctree-l2"><a class="reference internal" href="ovw_causal_inference.html">1.10. causal inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="ovw_uncertainty.html">1.11. uncertainty</a></li>
<li class="toctree-l2"><a class="reference internal" href="ovw_interp.html">1.12. interpretability</a></li>
<li class="toctree-l2"><a class="reference internal" href="ovw_generalization.html">1.13. generalization</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cs/cs.html">2. cs</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../cs/retrieval.html">2.1. info retrieval</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cs/data_structures.html">2.2. data structures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cs/languages.html">2.3. languages</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cs/software.html">2.4. software engineering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cs/quantum.html">2.5. quantum</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cs/algo.html">2.6. algorithms</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cs/graphs.html">2.7. graphs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cs/os.html">2.8. os</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cs/arch.html">2.9. architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cs/reproducibility.html">2.10. reproducibility</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cs/comp_theory.html">2.11. cs theory</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../math/math.html">3. math</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../math/differential_equations.html">3.1. differential equations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../math/proofs.html">3.2. proofs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../math/analysis.html">3.3. real analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../math/linear_algebra.html">3.4. linear algebra</a></li>
<li class="toctree-l2"><a class="reference internal" href="../math/signals.html">3.5. signals</a></li>
<li class="toctree-l2"><a class="reference internal" href="../math/optimization.html">3.6. optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../math/calculus.html">3.7. calculus</a></li>
<li class="toctree-l2"><a class="reference internal" href="../math/chaos.html">3.8. chaos</a></li>
<li class="toctree-l2"><a class="reference internal" href="../math/math_basics.html">3.9. math basics</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../stat/stat.html">4. stat</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../stat/graphical_models.html">4.1. graphical models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../stat/data_analysis.html">4.2. data analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../stat/testing.html">4.3. testing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../stat/causal_inference.html">4.4. causal inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../stat/info_theory.html">4.5. info theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../stat/linear_models.html">4.6. linear models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../stat/time_series.html">4.7. time series</a></li>
<li class="toctree-l2"><a class="reference internal" href="../stat/game_theory.html">4.8. game theory</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../ml/ml.html">5. ml</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../ml/kernels.html">5.1. kernels</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ml/nlp.html">5.2. nlp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ml/comp_vision.html">5.3. computer vision</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ml/structure_ml.html">5.4. structure learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ml/classification.html">5.5. classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ml/unsupervised.html">5.6. unsupervised</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ml/deep_learning.html">5.7. deep learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ml/feature_selection.html">5.8. feature selection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ml/learning_theory.html">5.9. learning theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ml/evaluation.html">5.10. evaluation</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../ai/ai.html">6. ai</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../ai/llms.html">6.1. llms</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ai/search.html">6.2. search</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ai/decisions_rl.html">6.3. decisions, rl</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ai/fairness_sts.html">6.4. fairness, sts</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ai/cogsci.html">6.5. cognitive science</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ai/ai_futures.html">6.6. ai futures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ai/logic.html">6.7. logic</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ai/philosophy.html">6.8. philosophy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ai/psychology.html">6.9. psychology</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ai/knowledge_rep.html">6.10. representations</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../neuro/neuro.html">7. neuro</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../neuro/disease.html">7.1. disease</a></li>
<li class="toctree-l2"><a class="reference internal" href="../neuro/brain_basics.html">7.2. brain basics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../neuro/vissci.html">7.3. vision</a></li>
<li class="toctree-l2"><a class="reference internal" href="../neuro/comp_neuro.html">7.4. comp neuro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../neuro/sensory_input.html">7.5. sensory input</a></li>
<li class="toctree-l2"><a class="reference internal" href="../neuro/memory.html">7.6. memory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../neuro/motor.html">7.7. motor system</a></li>
<li class="toctree-l2"><a class="reference internal" href="../neuro/development.html">7.8. development</a></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/csinva/csinva.github.io" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/notes/research_ovws/ovw_disentanglement.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>disentanglement</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#vaes">1.2.1. VAEs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#disentangled-vae-losses">1.2.1.1. disentangled vae losses</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#disentangled-vae-in-code">1.2.1.2. disentangled vae in code</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#vaes-for-interpretation">1.2.1.3. vaes for interpretation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#various-vaes">1.2.1.4. various vaes</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gans">1.2.2. GANs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-based-disentangle-during-training">1.2.2.1. model-based (disentangle during training)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#post-hoc-disentangle-after-training">1.2.2.2. post-hoc (disentangle after training)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#misc">1.2.3. misc</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#semi-supervised-disentanglement">1.2.4. (semi)-supervised disentanglement</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluating-disentanglement">1.2.5. evaluating disentanglement</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#non-deep-methods">1.2.6. non-deep methods</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <div class="iframe-box" style="margin-top: 0px">
<iframe class="iframe" src="https://csinva.github.io/notes/cheat_sheets/disentanglement_cheat_sheet#/"
        frameborder="0" width="100%" height="auto" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>
</div>
<section class="tex2jax_ignore mathjax_ignore" id="disentanglement">
<h1><span class="section-number">1.2. </span>disentanglement<a class="headerlink" href="#disentanglement" title="Link to this heading">#</a></h1>
<section id="vaes">
<h2><span class="section-number">1.2.1. </span>VAEs<a class="headerlink" href="#vaes" title="Link to this heading">#</a></h2>
<p><em>Some good disentangled VAE implementations are <a class="reference external" href="https://github.com/YannDubs/disentangling-vae">here</a> and more general VAE implementations are <a class="reference external" href="https://github.com/AntixK/PyTorch-VAE">here</a></em>. Tensorflow implementations available <a class="reference external" href="https://github.com/google-research/disentanglement_lib">here</a></p>
<p>The goal is to obtain a nice latent representation <span class="math notranslate nohighlight">\(\mathbf z\)</span> for our inputs <span class="math notranslate nohighlight">\(\mathbf x\)</span>. To do this, we learn parameters <span class="math notranslate nohighlight">\(\phi\)</span> for the encoder <span class="math notranslate nohighlight">\(p_\phi( \mathbf z\vert \mathbf x)\)</span> and <span class="math notranslate nohighlight">\(\theta\)</span> for the decoder <span class="math notranslate nohighlight">\(q_{\mathbf \theta} ( \mathbf x\vert \mathbf z)\)</span>. We do this with the standard vae setup, whereby a code <span class="math notranslate nohighlight">\(z\)</span> is sampled, using the output of the encoder (intro to VAEs <a class="reference external" href="https://towardsdatascience.com/intuitively-understanding-variational-autoencoders-1bfe67eb5daf">here</a>).</p>
<section id="disentangled-vae-losses">
<h3><span class="section-number">1.2.1.1. </span>disentangled vae losses<a class="headerlink" href="#disentangled-vae-losses" title="Link to this heading">#</a></h3>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>reconstruction loss</p></th>
<th class="head"><p>compactness prior loss</p></th>
<th class="head text-center"><p>total correlation loss</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>encourages accurate reconstruction of the input</p></td>
<td><p>encourages points to be compactly placed in space</p></td>
<td class="text-center"><p>encourages latent variables to be independent</p></td>
</tr>
</tbody>
</table>
</div>
<ul class="simple">
<li><p>summarizing the losses</p>
<ul>
<li><p><strong>reconstruction loss</strong> - measures the quality of the reconstruction, the form of the loss changes based on the assumed distribution of the likelihood of each pixel</p>
<ul>
<li><p><em>binary cross entropy loss</em> - corresopnds to bernoulli distr., most common - doesn’t penalize (0.1, 0.2) and (0.4, 0.5) the same way, which might be problematic</p></li>
<li><p><em>mse loss</em> - gaussian distr. - tends to focus on a fex pixels that are very wrong</p></li>
<li><p><em>l1 loss</em> - laplace distr.</p></li>
</ul>
</li>
<li><p><strong>compactness prior loss</strong></p>
<ul>
<li><p>doesn’t use the extra injected latent noise</p></li>
<li><p>tries to push all the points to the same place</p></li>
<li><p>emphasises smoothness of z, using as few dimensions of z as possible, and the main axes of z to capture most of the data variability</p></li>
<li><p>usually assume prior is standard normal, resulting in pushing the code means to 0 and code variance to 1</p></li>
<li><p>we can again split this term <span class="math notranslate nohighlight">\(\sum_i \underbrace{\text{KL} \left(p_\phi( \mathbf z_i\vert \mathbf x)\:\vert\vert\:prior(\mathbf z_i) \right)}_{\text{compactness prior loss}} = \underbrace{\sum_i I(x; z)}_{\text{mutual info}} + \underbrace{\text{KL} \left(p_\phi( \mathbf z_i)\:\vert\vert\:prior(\mathbf z_i) \right)}_{\text{factorial prior loss}}\)</span></p>
<ul>
<li><p>(see <a class="reference external" href="https://arxiv.org/pdf/1802.05983.pdf">factor-vae paper for proof</a>)</p></li>
</ul>
</li>
</ul>
</li>
<li><p><strong>total correlation loss</strong> - encourages factors to be independent</p>
<ul>
<li><p>measures dependence between marginals of the latent vars</p></li>
<li><p>intractable (requires pass through the whole dset)</p></li>
<li><p>instead sample <span class="math notranslate nohighlight">\(dec_\phi(\mathbf z\vert \mathbf x)\)</span> and create <span class="math notranslate nohighlight">\(\prod_j dec_\phi( \mathbf z_i\vert \mathbf x) \)</span> by permuting across the batch dimension</p>
<ul>
<li><p>now, calculate the kl with the <em>density-ratio trick</em> - train a classifier to approximate the ratio from these terms</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</section>
<section id="disentangled-vae-in-code">
<h3><span class="section-number">1.2.1.2. </span>disentangled vae in code<a class="headerlink" href="#disentangled-vae-in-code" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">## Reconstruction + KL divergence losses summed over all elements and batch</span>
<span class="k">def</span><span class="w"> </span><span class="nf">loss_function</span><span class="p">(</span><span class="n">x_reconstructed</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">  Params</span>
<span class="sd">  ------</span>
<span class="sd">  x_reconstructed: torch.Tensor</span>
<span class="sd">		Reconstructed input, with values between 0-1</span>
<span class="sd">	x: torch.Tensor</span>
<span class="sd">		input, values unrestricted</span>
<span class="sd">  &#39;&#39;&#39;</span>
  
  <span class="c1">## reconstruction loss (assuming bernoulli distr.)</span>
  <span class="c1">## BCE = sum_i [x_rec_i * log(x_i) + (1 - x_rec_i) * log(1-x_i)]</span>
	<span class="n">rec_loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">binary_cross_entropy</span><span class="p">(</span><span class="n">x_reconstructed</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span><span class="p">)</span>

  <span class="c1">## compactness prior loss</span>
	<span class="c1">## 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)</span>
	<span class="n">KLD</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">logvar</span> <span class="o">-</span> <span class="n">mu</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="n">logvar</span><span class="o">.</span><span class="n">exp</span><span class="p">())</span>
  
  <span class="c1">## total correlation loss (calculate tc-vae way)</span>
	<span class="n">z_sample</span> <span class="o">=</span> <span class="n">mu</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">exp</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">logvar</span><span class="p">))</span>
	<span class="n">log_pz</span><span class="p">,</span> <span class="n">log_qz</span><span class="p">,</span> <span class="n">log_prod_qzi</span><span class="p">,</span> <span class="n">log_q_zCx</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">z_sample</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span><span class="p">)</span>
  <span class="c1">## I[z;x] = KL[q(z,x)\vert\vertq(x)q(z)] = E_x[KL[q(z\vertx)\vert\vertq(z)]]</span>
  <span class="n">mi_loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">log_q_zCx</span> <span class="o">-</span> <span class="n">log_qz</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
  <span class="c1">## TC[z] = KL[q(z)\vert\vert\prod_i z_i]</span>
  <span class="n">tc_loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">log_qz</span> <span class="o">-</span> <span class="n">log_prod_qzi</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
  <span class="c1">## dw_kl_loss is KL[q(z)\vert\vertp(z)] instead of usual KL[q(z\vertx)\vert\vertp(z))]</span>
  <span class="n">dw_kl_loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">log_prod_qzi</span> <span class="o">-</span> <span class="n">log_pz</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
  
	<span class="k">return</span> <span class="n">rec_loss</span> <span class="o">+</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">KLD</span>
</pre></div>
</div>
</section>
<section id="vaes-for-interpretation">
<h3><span class="section-number">1.2.1.3. </span>vaes for interpretation<a class="headerlink" href="#vaes-for-interpretation" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://proceedings.neurips.cc/paper/2020/file/56f9f88906aebf4ad985aaec7fa01313-Paper.pdf">icam</a> (bass et al. 2020) - learn disentangled repr using vae with adv loss to make repr class-relevant</p>
<ul>
<li><p><a class="reference external" href="https://openaccess.thecvf.com/content_cvpr_2018/html/Baumgartner_Visual_Feature_Attribution_CVPR_2018_paper.html">va-gan</a> (baumgartner et al. 2018) - interpret features in GAN space</p></li>
</ul>
</li>
</ul>
</section>
<section id="various-vaes">
<h3><span class="section-number">1.2.1.4. </span>various vaes<a class="headerlink" href="#various-vaes" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/abs/1312.6114">vae</a> (kingma &amp; welling, 2013)</p></li>
<li><p><a class="reference external" href="https://openreview.net/references/pdf?id=Sy2fzU9gl">beta-vae</a> (higgins et al. 2017) - add hyperparameter <span class="math notranslate nohighlight">\(\beta\)</span> to weight the compactness prior term</p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1804.03599.pdf">beta-vae H</a> (burgess et al. 2018) - add parameter <span class="math notranslate nohighlight">\(C\)</span> to control the contribution of the compactness prior term</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\overbrace{\mathbb  E_{p_\phi(\mathbf z\vert \mathbf x)}}^{\text{samples}} [ \underbrace{-\log q_{\mathbf \theta} ( \mathbf x\vert \mathbf z)}_{\text{reconstruction loss}} ]      		+ \textcolor{teal}{\beta}\; \vert\sum_i \underbrace{\text{KL} \left(p_\phi( \mathbf z_i\vert \mathbf x)\:\vert\vert\:prior(\mathbf z_i) \right)}_{\text{compactness prior loss}} -C\vert\)</span></p></li>
<li><p>C is gradually increased from zero (allowing for a larger compactness prior loss) until good quality reconstruction is achieved</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1802.05983">factor-vae</a> (kim &amp; minh 2018) - adds total correlation loss term</p>
<ul>
<li><p>computes <em>total correlation loss term</em> using discriminator (can we discriminate between the samples when we shuffle over the batch dimension or not?)</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1802.04942">beta-TC-VAE = beta-total-correlation VAE</a> (chen et al. 2018) - same objective but computed without need for discriminator</p>
<ul>
<li><p>use minibatch-weighted sampling to compute each of the 3 terms that make up the original VAE <em>compactness prior loss</em></p></li>
<li><p>main idea is to better approximate <span class="math notranslate nohighlight">\(q(z)\)</span> by weighting samples appropriately - biased, but easier to compute</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1802.06765">Interpretable VAEs for nonlinear group factor analysis</a></p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1711.01558.pdf">Wasserstein Auto-Encoders</a> (tolstikhin et al.) - removes the mutual info part of the loss</p>
<ul>
<li><p>wasserstein distance = earth-movers distance, how far apart are 2 distrs</p></li>
<li><p>minimizes wasserstein distance + penalty which is similar to auto-encoding penalty,  without the mutual info term</p></li>
<li><p>another intuition: rather than map each point to a ball (since VAE adds noise to each latent repr), we only constraint the overall distr of Z, potentially making reconstructions less blurry (but potentially making latent space less smooth)</p></li>
<li><p><img alt="wae" src="../../_images/wae.png" /></p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/2004.04467.pdf">Adversarial Latent Autoencoder</a> (pidhorskyi et al. 2020)</p>
<ul>
<li><p>improve quality of generated VAE reconstructions by using a different setup which allows for using a GAN loss</p></li>
<li><p><img alt="alae" src="../../_images/alae.png" /></p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1812.06775.pdf">Variational Autoencoders Pursue PCA Directions (by Accident)</a></p>
<ul>
<li><p>local orthogonality of the embedding transformation</p></li>
<li><p>prior <span class="math notranslate nohighlight">\(p(z)\)</span> is standard normal, so encoder is assumed to be Gaussian with a certain mean, and <strong>diagonal covariance</strong></p></li>
<li><p>disentanglement is sensitive to rotations of the latent embeddings but reconstruction err doesn’t care</p></li>
<li><p>for linear autoencoder w/ square-error as reconstruction loss, we recover PCA decomp</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1812.02833.pdf">Disentangling Disentanglement in Variational Autoencoders</a> (2019)</p>
<ul>
<li><p>independence can be too simplistic, instead 2 things:</p>
<ul>
<li><p>the latent encodings of data having an appropriate level of overlap</p>
<ul>
<li><p>keeps encodings from just being a lookup table</p></li>
<li><p>when encoder is unimodal, <span class="math notranslate nohighlight">\(I(x; z)\)</span> gives us a good handle on this</p></li>
</ul>
</li>
<li><p>prior structure on the latents (e.g. independence, sparsity)</p></li>
</ul>
</li>
<li><p>to trade these off, can penalize divergence between <span class="math notranslate nohighlight">\(q_\phi(z)\)</span> and <span class="math notranslate nohighlight">\(p(z)\)</span></p></li>
<li><p>nonisotropic priors -  isotropic priors are only good up to rotation in the latent space</p>
<ul>
<li><p>by chossing a nonisotropic prior (e.g. nonisotropic gaussian), can learn certain directions more easily</p></li>
</ul>
</li>
<li><p>sparse prior - can help do clustering</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://www.biorxiv.org/content/10.1101/2020.07.17.207993v1.full.pdf">VAE-SNE: a deep generative model for simultaneous dimensionality reduction and clustering</a> (graving &amp; couzin 2020) - reduce dims + cluster without specifying number of clusters</p>
<ul>
<li><p><img alt="Screen Shot 2020-09-10 at 11.40.10 PM" src="../../_images/sne_eq.png" /></p></li>
<li><p><strong>stochastic neighbor regularizer</strong> that optimizes pairwise similarity kernels between original and latent distrs. to strengthen local neighborhood preservation</p>
<ul>
<li><p>can use different neighbor kernels, e.g. t-SNE similarity (van der Maaten &amp; Hinton, 2008) or Gaussian SNE kernel (Hinton &amp; Roweis, 2003)</p></li>
<li><p>perplexity annealing technique (Kobak and Berens, 2019) - decay the size of local neighborhoods during training (helps to preserve structure at multiple scales)</p></li>
</ul>
</li>
<li><p><strong>Gaussian mixture prior</strong> for learning latent distr. (with very large number of clusters)</p>
<ul>
<li><p>at the end, merge clusters using a sparse watershed (see <a class="reference external" href="https://iopscience.iop.org/article/10.1088/1478-3975/14/1/015002/meta">todd et al. 2017</a>)</p></li>
</ul>
</li>
<li><p>extensive evaluation - test several datasets / methods and evaluate how well the first 2 dimensions preserve the following:</p>
<ul>
<li><p>global - correlation between pairwise distances in orig/latent spaces</p></li>
<li><p>local - both metric (distance- or radius-based) and topological (neighbor-based) neighborhoods which are 1% of total embedding size</p></li>
<li><p>fine-scale - neighborhoods which are &lt;1% of total embedding size</p></li>
<li><p>temporal info (for time-series data only) - correlation between latent and original temporal derivatives</p></li>
<li><p><strong>likelihood</strong> on out-of-sample data</p></li>
</ul>
</li>
<li><p>further advancements</p>
<ul>
<li><p>embed into polar coordinates (rather than Euclidean) helps a lot</p></li>
<li><p>convolutional VAE-SNE - extract features from images using some pre-trained net and then run VAE-SNE on these features</p></li>
</ul>
</li>
<li><p>background: earlier works also used SNE objective for regularization - starts with van der Maaten 2009 (parametric t-SNE)</p></li>
<li><p>future work: density-preserving versions of t-SNE, modeling hierarchical structure in vae, conditional t-SNE kernel</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1612.05299">A Survey of Inductive Biases for Factorial Representation-Learning</a> (ridgeway 2016)</p>
<ul>
<li><p>desiderata</p>
<ul>
<li><p><strong>compact</strong></p></li>
<li><p><strong>faithful</strong> - preserve info required for task</p></li>
<li><p><strong>explicitly</strong> represent the attributes required for the task at hand</p></li>
<li><p><strong>interpretable</strong> by humans</p></li>
</ul>
</li>
<li><p>factorial representation - attributes are statistically independent and can provide a userful bias for learning</p>
<ul>
<li><p>“compete” - factors are more orthogonal</p></li>
<li><p>“cooperate” - factors are more similar</p></li>
<li><p>bias on distribution of factors</p>
<ul>
<li><p>PCA - minimize reconstruction err. subject to orthogonal weights</p></li>
<li><p>ICA - maximize non-Gaussianity (can also have sparse ICA)</p></li>
</ul>
</li>
<li><p>bias on factors being invariant to certain types of changes</p>
<ul>
<li><p>ISA (independent subspace analysis) - 2 layer model where first layer is linear, 2nd layer pools first layer (not maxpool, more like avgpool), sparsity at second layer</p>
<ul>
<li><p>i.e. 1st layer cooperates, 2nd layer competes</p></li>
</ul>
</li>
<li><p>VQ - vector quantizer - like ISA but first layer filters now compete and 2nd layer cooperates</p></li>
<li><p>SOM - encourages topographic map by enforcing nearby filters to be similar</p></li>
</ul>
</li>
<li><p>bias in how factors are combined</p>
<ul>
<li><p>linear combination - PCA/ICA</p></li>
<li><p>multilinear models - multiplicative interactions between factors (e.g on top of ISA)</p></li>
<li><p>functional parts - factor components are combined to construct the output</p>
<ul>
<li><p>ex. NMF - parts can only add, not substract to total output</p></li>
<li><p>ex. have each pixel in the output be represented by only one factor in a VQ</p></li>
</ul>
</li>
<li><p>hierarchical layers</p>
<ul>
<li><p>ex. R-ICA - recursive ICA - run ICA on coefficients from previous layer (after some transformation)</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>supervision bias</p>
<ul>
<li><p>constraints on some examples</p>
<ul>
<li><p>e.g. some groups have same value for a factor</p></li>
<li><p>e.g. some examples have similar distances (basis for MDS = multidimensional scaling)</p></li>
<li><p>e.g. analogies between examples</p></li>
<li><p>can do all of these things with auto-encoders</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>more papers</p>
<ul>
<li><p><a class="reference external" href="https://arxiv.org/abs/1706.02262">infoVAE</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1711.00848">dipVAE</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1711.00937">vq-vae</a> - latent var is discrete, prior is learned</p></li>
<li><p><a class="reference external" href="http://papers.nips.cc/paper/7174-learning-disentangled-representations-with-semi-supervised-deep-generative-models">Learning Disentangled Representations with Semi-Supervised Deep Generative Models</a></p>
<ul>
<li><p>specify graph structure for some of the vars and learn the rest</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</section>
</section>
<section id="gans">
<h2><span class="section-number">1.2.2. </span>GANs<a class="headerlink" href="#gans" title="Link to this heading">#</a></h2>
<section id="model-based-disentangle-during-training">
<h3><span class="section-number">1.2.2.1. </span>model-based (disentangle during training)<a class="headerlink" href="#model-based-disentangle-during-training" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>disentangling architectures</p>
<ul>
<li><p><a class="reference external" href="https://arxiv.org/abs/1606.03657">InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets</a> (chen et al. 2016)</p>
<ul>
<li><p>encourages <span class="math notranslate nohighlight">\(I(x; c)\)</span> to be high for a subset of the latent variables <span class="math notranslate nohighlight">\(z\)</span></p>
<ul>
<li><p>slightly different than vae - defined under the distribution <span class="math notranslate nohighlight">\(p(c) p(x\vert c)\)</span> whereas vae uses <span class="math notranslate nohighlight">\(p_{data}(x)enc(z\vert x)\)</span></p></li>
</ul>
</li>
<li><p>mutual info is intractable so optimizes a lower bound</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1812.04948">Stylegan</a> (karras et al. 2018)</p>
<ul>
<li><p>introduced perceptual path length and linear separability to measure the disentanglement property of latent space</p></li>
<li><p><img alt="stylegan" src="../../_images/stylegan.png" /></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1912.04958">Stylegan2</a> (karras et al. 2019): <img alt="stylegan2" src="../../_images/stylegan2.png" /></p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\psi\)</span> scales the deviation of <em>w</em> from the average - <span class="math notranslate nohighlight">\(\psi=1\)</span> is original, moving towards 0 improves quality but reduces variety</p></li>
<li><p>also has jacobian penalty on mapping from style space <span class="math notranslate nohighlight">\(w\)</span> to output image <span class="math notranslate nohighlight">\(y\)</span></p></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1711.05415">DNA-GAN: Learning Disentangled Representations from Multi-Attribute Images</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1911.05210">Clustering by Directly Disentangling Latent Space</a> - clustering in the latent space of a gan</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2003.03461">Semi-Supervised StyleGAN for Disentanglement Learning</a> - further improvements on StyleGAN using labels in the training data</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2008.10599">The Hessian Penalty: A Weak Prior for Unsupervised Disentanglement</a> (peebles et al. 2020)</p>
<ul>
<li><p>if we perturb a single component of a network’s input, then we would like the change in the output to be independent of the other input components</p></li>
<li><p>minimize off-diagonal entries of Hessian matrix (can be obtained with finite differences)</p>
<ul>
<li><p>smoother + more disentangled + shrinkage in latent space</p></li>
</ul>
</li>
<li><p>Hessian penalty is for a scalar - they define penalty as max penalty over Hessian over all pixels in the generator</p></li>
<li><p>unbiased stochastic estimator for the Hessian penalty (Hutchinson estimator)</p></li>
<li><p>they apply this penalty with <span class="math notranslate nohighlight">\(z\)</span> as input, but different intermediate activations as output</p></li>
</ul>
</li>
</ul>
</section>
<section id="post-hoc-disentangle-after-training">
<h3><span class="section-number">1.2.2.2. </span>post-hoc (disentangle after training)<a class="headerlink" href="#post-hoc-disentangle-after-training" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>mapping latent space</p>
<ul>
<li><p><a class="reference external" href="https://arxiv.org/pdf/2005.09635.pdf">InterFaceGAN: Interpreting the Disentangled Face Representation Learned by GANs</a> (shen et al. 2020)</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1907.10786">Interpreting the Latent Space of GANs for Semantic Face Editing</a> (shen et al. 2020)</p>
<ul>
<li><p>find latent directions for each binary attribute, as directions which separate the classes using linear svm</p>
<ul>
<li><p>validation accuracies in tab 1 are high…much higher for all data (because they have high confidence level on attribute scores maybe) - for PGGAN but not StyleGAN</p></li>
</ul>
</li>
<li><p>intro of this paper gives good survey of how people have studied GAN latent space</p></li>
<li><p>few papers posthoc analyze learned latent repr.</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1907.07171">On the “steerability” of generative adversarial networks</a> (jahanian et al. 2020)</p>
<ul>
<li><p>learn to approximate edits to images, such as zooms</p>
<ul>
<li><p>linear walk is as effective as more complex non-linear walks for learning this</p></li>
<li><p>nonlinear setting - learn a neural network which applies a small perturbation in a specific direction (e.g. zooming)</p>
<ul>
<li><p>to move further in this space, repeatedly apply the function</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2004.13166">A Disentangling Invertible Interpretation Network for Explaining Latent Representations</a> (esser et al. 2020) - map latent space to interpretable space, with invertible neural network</p>
<ul>
<li><p>interpretable space factorizes, so is disentangled</p></li>
<li><p>individual concepts (e.g. color) can use multiple interpretable latent dims</p></li>
<li><p>instead of user-supplied interpretable concepts, user supplies two sketches which demonstrate a change in a concept - these sketches are used w/ style transfer to create data points which describe the concept</p></li>
<li><p>alternatively, with no user-supplied concepts, try to get independent components in unsupervised way</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2005.07728">Disentangling in Latent Space by Harnessing a Pretrained Generator</a> (nitzan et al. 2020)</p>
<ul>
<li><p>learn to map attributes onto latent space of stylegan</p></li>
<li><p>works using two images at a time and 2 encoders</p>
<ul>
<li><p>for each image, predict attributes + identity, then mix the attributes</p></li>
</ul>
</li>
<li><p>results look realy good, but can’t vary one attribute at a time (have to transfer all attributes from the new image)</p></li>
</ul>
</li>
<li><p><a class="reference external" href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Taihong_Xiao_ELEGANT_Exchanging_Latent_ECCV_2018_paper.pdf">ELEGANT: Exchanging Latent Encodings with GAN for Transferring Multiple Face Attributes</a> (xiao et al. 2018)</p>
<ul>
<li><p>trains 2 images at a time - swap an attribute that differs between the images and reconstruct images that have the transferred attribute</p></li>
</ul>
</li>
</ul>
</li>
<li><p>bias</p>
<ul>
<li><p><a class="reference external" href="https://www.overleaf.com/project/5e6aa80234ed3e0001b9ac23">Towards causal benchmarking of bias in computer vision algorithms</a> (balakrishnan et al. 2020) - use human annotations to disentangle latent space</p>
<ul>
<li><p>synthesis approach can alter multiple attributes at a time to produce grid-like matched samples of images we call <em>transects</em></p></li>
<li><p>find directions + orthogonalize same as shen et al. 2020</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1906.06439">Detecting Bias with Generative Counterfactual Face Attribute Augmentation</a> (denton et al. 2019) - identify latent dims by training a classifier in the latent space on groundtruth attributes of the training images</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1907.07165">Explaining Classifiers with Causal Concept Effect (CaCE)</a> (goyal et al. 2020) - use vae to disentangle / alter concepts to probe classifier</p></li>
</ul>
</li>
<li><p>post-hoc</p>
<ul>
<li><p><a class="reference external" href="https://arxiv.org/abs/1911.00483">Explanation by Progressive Exaggeration</a> (singla et al. 2019)</p>
<ul>
<li><p>progressively change image to negate the prediction, keeping most features fixed</p>
<ul>
<li><p>want to learn mapping <span class="math notranslate nohighlight">\(I(x, \delta)\)</span> which produces realistic image that changes features by <span class="math notranslate nohighlight">\(\delta\)</span></p></li>
</ul>
</li>
<li><p>3 losses: <strong>data consistency</strong> (perturbed samples should look real), <strong>prediction changes</strong> (perturbed samples should appropriately alter prediction), <strong>self-consistency</strong> (applying reverse perturbatino should bring x back to original, and <span class="math notranslate nohighlight">\(\delta=0\)</span> should return identity)</p></li>
<li><p>moving finds ways to generate images that do change the wanted attribute (and don’t change the others too much)</p></li>
<li><p>minor</p>
<ul>
<li><p>used human experiments</p></li>
<li><p>limited to binary classification</p></li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1711.05611">Interpreting Deep Visual Representations via Network Dissection</a> (zhou et al. 2017)</p>
<ul>
<li><p>obtain image attributes for each z (using classifier, not human labels)</p>
<ul>
<li><p>this classifier may put bias back in</p></li>
</ul>
</li>
<li><p>to find directions representing an attribute, train a linear model to predict it from z</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1811.10597">GAN Dissection: Visualizing and Understanding Generative Adversarial Networks</a> (bau et al. 2018) - identify group of interpretable units based on segmentation of training images</p>
<ul>
<li><p>find directions which allow for altering the attributes</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2004.02546">GANSpace: Discovering Interpretable GAN Controls</a> - use PCA in the latent space (w for styleGAN, activation-space at a specific layer for BigGAN) to select directions</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2004.14367">Editing in Style: Uncovering the Local Semantics of GANs</a> (collins et al. 2020) - use k-means on gan activations to find meaningful clusters (with quick human annotation)</p>
<ul>
<li><p>add style transfer using target/source image</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2002.03754">Unsupervised Discovery of Interpretable Directions in the GAN Latent Space</a> - loss function which tries to recover random shifts made to the latent space</p></li>
</ul>
</li>
</ul>
</section>
</section>
<section id="misc">
<h2><span class="section-number">1.2.3. </span>misc<a class="headerlink" href="#misc" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/abs/2006.08558">Learning Diverse and Discriminative Representations via the Principle of Maximal Coding Rate Reduction</a> (yu, …, &amp; ma, 2020)</p>
<ul>
<li><p>goal: learn low-dimensional structure from high-dim (labeled or unlabeled) data</p></li>
<li><p>approach: instead of cross-entropy loss, use <strong>maximal coding rate reduction</strong> = MCR loss function to learn linear feature space where:</p>
<ul>
<li><p><em>inter-class discriminative</em> - features of samples from different classes/clusters are uncorrelated + different low-dim linear subspaces</p></li>
<li><p><em>intra-class compressible</em> - features of samples from same class/cluster are correlated (i.e. belong to low-dim linear subspace)</p></li>
<li><p><em>maximally diverse</em> - dimension (or variance) of features for each class/cluster should be as large as possible as long as uncorrelated from other classes/clusters</p></li>
</ul>
</li>
<li><p>related to nonlinear generalized PCA</p></li>
<li><p>given random variable <span class="math notranslate nohighlight">\(z\)</span> and precision <span class="math notranslate nohighlight">\(\epsilon\)</span>, rate distortion <span class="math notranslate nohighlight">\(R(z, \epsilon)\)</span> is minimal number of bits to encode <span class="math notranslate nohighlight">\(z\)</span> such that expected decoding err is less than <span class="math notranslate nohighlight">\(\epsilon\)</span></p>
<ul>
<li><p>can compute from finite samples</p></li>
<li><p>can compute for each class (diagonal matrices represent class/cluster membership in loss function)</p></li>
<li><p>MCR maximizes (rate distortion for all features) - (rate distortion for all data separated into classes)</p>
<ul>
<li><p>like a generalization of information gain</p></li>
</ul>
</li>
</ul>
</li>
<li><p>evaluation</p>
<ul>
<li><p>with label corruption performs better</p></li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2011.05787">Learned Equivariant Rendering without Transformation Supervision</a> - separate foreground / background using video</p></li>
</ul>
</section>
<section id="semi-supervised-disentanglement">
<h2><span class="section-number">1.2.4. </span>(semi)-supervised disentanglement<a class="headerlink" href="#semi-supervised-disentanglement" title="Link to this heading">#</a></h2>
<p><strong>these papers use some form of supervision for the latent space when disentangling</strong></p>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/pdf/2003.06581.pdf">Semi-supervised Disentanglement with Independent Vector Variational Autoencoders</a></p>
<ul>
<li><p><img alt="Screen Shot 2020-05-21 at 12.47.22 PM" src="../../_images/semi_supervised_vae.png" /></p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1706.00400">Learning Disentangled Representations with Semi-Supervised Deep Generative Models</a> - put priors on interpretable variables during training and learn the rest</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1910.09772">Weakly Supervised Disentanglement with Guarantees</a></p>
<ul>
<li><p>prove results on disentanglement for rank pairing</p></li>
<li><p>different types of available supervision<img alt="Screen Shot 2020-05-21 at 1.05.19 PM" src="../../_images/unsupervised_settings.png" /></p>
<ul>
<li><p><strong>restricted labeling</strong> - given labels for some groundtruth factors (e.g. label “glasses”, “gender” for all images)</p></li>
<li><p>match pairing - given pairs or groups (e.g. these images all have glasses)</p></li>
<li><p>rank pairing - label whether a feature is greater than another (e.g. this image has darker skin tone than this one)</p></li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1906.01044">Weakly Supervised Disentanglement by Pairwise Similarities</a> - use pairwise supervision</p></li>
</ul>
</section>
<section id="evaluating-disentanglement">
<h2><span class="section-number">1.2.5. </span>evaluating disentanglement<a class="headerlink" href="#evaluating-disentanglement" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="http://proceedings.mlr.press/v97/locatello19a/locatello19a.pdf">Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations</a> (locatello et al. 2019)</p>
<ul>
<li><p>state of disentanglement is very poor…depends a lot on architecture/hyperparameters</p></li>
<li><p>good way to evaluate: make explicit inductive biases, investigate benefits of this disentanglement</p></li>
<li><p>defining disentanglement - compact, interpretable, independent, helpful for downstream tasks, causal inference</p>
<ul>
<li><p>a change in one <em>factor of variation</em> should lead to a change in a single factor in the learned repr.</p></li>
</ul>
</li>
<li><p>unsupervised learning of disentangled reprs. is impossible without inductive biases</p></li>
</ul>
</li>
<li><p><em>note</em> - vae’s come with reconstruction loss + compactness prior loss which can be looked at on their own</p></li>
<li><p>data</p>
<ul>
<li><p><a class="reference external" href="https://github.com/deepmind/dsprites-dataset/">dsprites dataset</a> has known latent factors we try to recover</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://medium.com/uci-nlp/summary-beta-vae-learning-basic-visual-concepts-with-a-constrained-variational-framework-91ad843b49e8">beta-vae <strong>disentanglement metric score</strong> = higgins metric</a> - see if we can capture known disentangled repr. using pairs of things where only one thing changes</p>
<ul>
<li><p>start with a known generative model that has an observed set of independent and interpretable factors (e.g. scale, color, etc.) that can be used to simulate data.</p></li>
<li><p>create a dataset comprised of pairs of generated data for which a single factor is held constant (e.g. a pair of images which have objects with the same color).</p></li>
<li><p>use the inference network to map each pair of images to a pair of latent variables.</p></li>
<li><p>train a linear classifier to predict which interpretable factor was held constant based on the latent representations. The accuracy of this predictor is the disentanglement metric score.</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1910.05587">Evaluating Disentangled Representations</a> (sepliarskaia et al. 2019)</p>
<ul>
<li><p>defn 1  (Higgins et al., 2017; Kim and Mnih, 2018; Eastwood and Williams, 2018) = <strong>factorVAE metric</strong>: A disentangled representation is a representation where a change in one latent dimension corresponds to a change in one generative factor while being relatively invariant to changes in other generative factors.</p></li>
<li><p>defn 2 (Locatello et al., 2018; Kumar et al., 2017): A disentangled representation is a representation where a change in a single generative factor leads to a change in a single factor in the learned representation.</p></li>
<li><p>metrics</p>
<ul>
<li><p><strong>DCI</strong>: Eastwood and Williams (2018) - informativeness based on predicting gt factors using latent factors</p></li>
<li><p><strong>SAP</strong>: Kumar et al. (2017) - how much does top latent factor match gt more than 2nd latent factor</p></li>
<li><p><strong>mutual info gap MIG</strong>: Chen et al. 2018 - mutual info to compute the same thing</p></li>
<li><p><strong>modularity</strong> (ridgeway &amp; mozer, 2018) - if each dimension of r(x) depends on at most a factor of variation using their mutual info</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</section>
<section id="non-deep-methods">
<h2><span class="section-number">1.2.6. </span>non-deep methods<a class="headerlink" href="#non-deep-methods" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/pdf/1907.04809.pdf">unifying vae and nonlinear ica</a> (khemakhem et al. 2020)</p>
<ul>
<li><p>ICA</p>
<ul>
<li><p>maximize non-gaussianity of <span class="math notranslate nohighlight">\(z\)</span> - use kurtosis, negentropy</p></li>
<li><p>minimize mutual info between components of <span class="math notranslate nohighlight">\(z\)</span> - use KL, max entropyd</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./notes/research_ovws"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="ovw_transfer_learning.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">1.1. </span>transfer learning</p>
      </div>
    </a>
    <a class="right-next"
       href="ovw_omics.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">1.3. </span>omics</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#vaes">1.2.1. VAEs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#disentangled-vae-losses">1.2.1.1. disentangled vae losses</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#disentangled-vae-in-code">1.2.1.2. disentangled vae in code</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#vaes-for-interpretation">1.2.1.3. vaes for interpretation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#various-vaes">1.2.1.4. various vaes</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gans">1.2.2. GANs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-based-disentangle-during-training">1.2.2.1. model-based (disentangle during training)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#post-hoc-disentangle-after-training">1.2.2.2. post-hoc (disentangle after training)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#misc">1.2.3. misc</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#semi-supervised-disentanglement">1.2.4. (semi)-supervised disentanglement</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluating-disentanglement">1.2.5. evaluating disentanglement</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#non-deep-methods">1.2.6. non-deep methods</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Chandan Singh
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright None.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  <p>
Many of these images are taken from resources on the web.
</p>
</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>