
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>7.11. dl theory</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notes/research_ovws/ovw_dl_theory';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="7.12. scattering transform" href="ovw_scat.html" />
    <link rel="prev" title="7.10. complexity" href="ovw_complexity.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.png" class="logo__image only-light" alt=" - Home"/>
    <script>document.write(`<img src="../../_static/logo.png" class="logo__image only-dark" alt=" - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    overview 👋
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../ai/ai.html">1. ai</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../ai/knowledge_rep.html">1.1. representations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ai/psychology.html">1.2. psychology</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ai/fairness_sts.html">1.3. fairness, sts</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ai/philosophy.html">1.4. philosophy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ai/ai_futures.html">1.5. ai futures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ai/cogsci.html">1.6. cognitive science</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ai/llms.html">1.7. llms</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ai/logic.html">1.8. logic</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ai/search.html">1.9. search</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ai/decisions_rl.html">1.10. decisions, rl</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../math/math.html">2. math</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../math/linear_algebra.html">2.1. linear algebra</a></li>
<li class="toctree-l2"><a class="reference internal" href="../math/optimization.html">2.2. optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../math/differential_equations.html">2.3. differential equations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../math/chaos.html">2.4. chaos</a></li>
<li class="toctree-l2"><a class="reference internal" href="../math/math_basics.html">2.5. math basics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../math/signals.html">2.6. signals</a></li>
<li class="toctree-l2"><a class="reference internal" href="../math/calculus.html">2.7. calculus</a></li>
<li class="toctree-l2"><a class="reference internal" href="../math/proofs.html">2.8. proofs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../math/analysis.html">2.9. real analysis</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../ml/ml.html">3. ml</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../ml/unsupervised.html">3.1. unsupervised</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ml/structure_ml.html">3.2. structure learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ml/learning_theory.html">3.3. learning theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ml/deep_learning.html">3.4. deep learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ml/comp_vision.html">3.5. computer vision</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ml/kernels.html">3.6. kernels</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ml/nlp.html">3.7. nlp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ml/feature_selection.html">3.8. feature selection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ml/evaluation.html">3.9. evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ml/classification.html">3.10. classification</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../stat/stat.html">4. stat</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../stat/time_series.html">4.1. time series</a></li>
<li class="toctree-l2"><a class="reference internal" href="../stat/graphical_models.html">4.2. graphical models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../stat/causal_inference.html">4.3. causal inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../stat/game_theory.html">4.4. game theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../stat/info_theory.html">4.5. info theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../stat/linear_models.html">4.6. linear models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../stat/data_analysis.html">4.7. data analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../stat/testing.html">4.8. testing</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../neuro/neuro.html">5. neuro</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../neuro/motor.html">5.1. motor system</a></li>
<li class="toctree-l2"><a class="reference internal" href="../neuro/memory.html">5.2. memory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../neuro/development.html">5.3. development</a></li>
<li class="toctree-l2"><a class="reference internal" href="../neuro/sensory_input.html">5.4. sensory input</a></li>
<li class="toctree-l2"><a class="reference internal" href="../neuro/comp_neuro.html">5.5. comp neuro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../neuro/disease.html">5.6. disease</a></li>
<li class="toctree-l2"><a class="reference internal" href="../neuro/vissci.html">5.7. vision</a></li>
<li class="toctree-l2"><a class="reference internal" href="../neuro/brain_basics.html">5.8. brain basics</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cs/cs.html">6. cs</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../cs/comp_theory.html">6.1. cs theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cs/graphs.html">6.2. graphs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cs/retrieval.html">6.3. info retrieval</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cs/data_structures.html">6.4. data structures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cs/os.html">6.5. os</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cs/quantum.html">6.6. quantum</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cs/software.html">6.7. software engineering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cs/algo.html">6.8. algorithms</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cs/arch.html">6.9. architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cs/languages.html">6.10. languages</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cs/reproducibility.html">6.11. reproducibility</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="research_ovws.html">7. research_ovws</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="ovw_disentanglement.html">7.1. disentanglement</a></li>
<li class="toctree-l2"><a class="reference internal" href="ovw_uncertainty.html">7.2. uncertainty</a></li>
<li class="toctree-l2"><a class="reference internal" href="ovw_generalization.html">7.3. generalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="ovw_causal_inference.html">7.4. causal inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="ovw_omics.html">7.5. omics</a></li>
<li class="toctree-l2"><a class="reference internal" href="ovw_ml_medicine.html">7.6. ml in medicine</a></li>
<li class="toctree-l2"><a class="reference internal" href="ovw_llms.html">7.7. llms</a></li>
<li class="toctree-l2"><a class="reference internal" href="ovw_transfer_learning.html">7.8. transfer learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="ovw_interp.html">7.9. interpretability</a></li>
<li class="toctree-l2"><a class="reference internal" href="ovw_complexity.html">7.10. complexity</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">7.11. dl theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="ovw_scat.html">7.12. scattering transform</a></li>
<li class="toctree-l2"><a class="reference internal" href="ovw_interesting_science.html">7.13. interesting science</a></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/csinva/csinva.github.io" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/notes/research_ovws/ovw_dl_theory.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>dl theory</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#theoretical-studies">7.11.1. theoretical studies</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#functional-approximation">7.11.1.1. functional approximation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#inductive-bias-implicit-regularization-gradient-descent-finds-good-minima">7.11.1.2. inductive bias=implicit regularization: gradient descent finds good minima</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#semantic-biases-what-correlations-will-a-net-learn">7.11.1.3. semantic biases: what correlations will a net learn?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#expressiveness-what-can-a-dnn-represent">7.11.1.4. expressiveness: what can a dnn represent?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#complexity-generalization-dnns-are-low-rank-redundant-parameters">7.11.1.5. complexity + generalization: dnns are low-rank / redundant parameters</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#nearest-neighbor-comparisons">7.11.1.6. nearest neighbor comparisons</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#kernels">7.11.1.7. kernels</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#random-projections">7.11.1.8. random projections</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implicit-dl-optimization">7.11.1.9. implicit dl + optimization</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#statistical-physics">7.11.1.10. statistical physics</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#empirical-studies">7.11.2. empirical studies</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interesting-empirical-papers">7.11.2.1. interesting empirical papers</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#adversarial-robustness">7.11.2.2. adversarial + robustness</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tools-for-analyzing">7.11.2.3. tools for analyzing</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#misc-theoretical-areas">7.11.2.4. misc theoretical areas</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#comparing-representations">7.11.2.5. comparing representations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simple-papers">7.11.2.6. simple papers</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#adam-vs-sgd">7.11.2.7. adam vs sgd</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#memorization-background">7.11.2.8. memorization background</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#probabilistic-inference">7.11.2.9. probabilistic inference</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#architecture-search-background">7.11.2.10. architecture search background</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bagging-and-boosting">7.11.2.11. bagging and boosting</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#basics">7.11.3. basics</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="dl-theory">
<h1><span class="section-number">7.11. </span>dl theory<a class="headerlink" href="#dl-theory" title="Link to this heading">#</a></h1>
<p><a class="reference external" href="http://www.offconvex.org/">off convex blog</a></p>
<section id="theoretical-studies">
<h2><span class="section-number">7.11.1. </span>theoretical studies<a class="headerlink" href="#theoretical-studies" title="Link to this heading">#</a></h2>
<p>DNNs display many surprising properties</p>
<ul class="simple">
<li><p>surprising: <a class="reference external" href="https://arxiv.org/abs/1802.08760">more parameters yields better generalization</a></p></li>
<li><p>surprising: lowering training error should be harder</p></li>
</ul>
<p>Many things seem to contribute to the inductive bias of DNNs: SGD, dropout, early stopping, resnets, convolution, more layers…all of these are tangled together and many things correlate with generalization error…what are the important things and how do they contribute?</p>
<p>some more concrete questions:</p>
<ul class="simple">
<li><p>what is happening when training err stops going down but val err keeps going down (interpolation regime)?</p></li>
<li><p>what are good statistical markers of an effectively trained DNN?</p></li>
<li><p>how far apart are 2 nets?</p></li>
<li><p><em>verification</em> - does dnn satisfy a specification (e.g <span class="math notranslate nohighlight">\(l_p\)</span> robustness)</p>
<ul>
<li><p><em>convex barrier</em> - limitation in the tightness of the bounds obtainable by the convex relaxation of the output of a neural network</p></li>
</ul>
</li>
</ul>
<section id="functional-approximation">
<h3><span class="section-number">7.11.1.1. </span>functional approximation<a class="headerlink" href="#functional-approximation" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>dnns are very hard to study in the parameter space (e.g. swapping two parameters changes things like the Hessian), easier to to study in the function space (e.g. the input-output relationship)</p></li>
<li><p>nonlinear approximation (e.g. sparse coding) - 2 steps</p></li>
</ul>
<ol class="arabic simple">
<li><p>construct a dictionary function (T)</p></li>
<li><p>learn linear combination of the dictionary elements (g)</p></li>
</ol>
<ul class="simple">
<li><p>background</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(L^2\)</span> function (or function space) is square integrable: <span class="math notranslate nohighlight">\(|f|^2 = \int_X |f|^2 d\mu\)</span>, and <span class="math notranslate nohighlight">\(|f|\)</span> is its <span class="math notranslate nohighlight">\(L_2\)</span>-norm</p></li>
<li><p><strong>Hilbert space</strong> - vector space w/ additional structure of inner product which allows length + angle to be measured</p>
<ul>
<li><p>complete - there are enough limits in the space to allow calculus techniques (is a <em>complete metric space</em>)</p></li>
</ul>
</li>
</ul>
</li>
<li><p>composition allows an approximation of a function through level sets (split it up and approximate on these sets) - Zuowei Shen (<a class="reference external" href="http://www.ipam.ucla.edu/programs/workshops/workshop-iii-geometry-of-big-data/?tab=schedule">talk</a>, <a class="reference internal" href="#../../../drive/papers/dl_theory/shen_19_composition_dl_slides.pdf"><span class="xref myst">slides</span></a>)</p>
<ul>
<li><p>composition operation allows an approximation of a function f through level sets of f –</p></li>
<li><p>one divides up the range of f into equal intervals and approximate the functions on these sets</p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1902.10170.pdf">nonlinear approximation via compositions</a> (shen 2019)</p></li>
</ul>
</li>
<li><p>how do the weights in each layer help this approximation to be more effective?</p>
<ul>
<li><p>here are some thoughts – If other layers are like the first layer, the weights “whiten” or make the inputs more independent or random projections – that is basically finding PC directions for low-rank inputs.</p></li>
<li><p>are the outputs from later layers more or less low - rank?</p></li>
<li><p>I wonder how this “whitening” helps level set estimation…</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1112.4205">takagi functions</a></p></li>
<li><p><a class="reference external" href="https://www.math.tamu.edu/~rdevore/publications/170.pdf">nonlinear approximation and (deep) relu nets</a> - also comes with slides</p></li>
</ul>
</section>
<section id="inductive-bias-implicit-regularization-gradient-descent-finds-good-minima">
<h3><span class="section-number">7.11.1.2. </span>inductive bias=implicit regularization: gradient descent finds good minima<a class="headerlink" href="#inductive-bias-implicit-regularization-gradient-descent-finds-good-minima" title="Link to this heading">#</a></h3>
<p><em>DL learns solutions that generalize even though it can find many which don’t due to its inductive bias.</em></p>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/pdf/1803.08367.pdf">gd bousquet paper</a></p></li>
<li><p><a class="reference external" href="http://papers.nips.cc/paper/5486-identifying-and-attacking-the-saddle-point-problem-in-high-dimensional-non-convex-optimization">in high dims, local minima are usually saddles (ganguli)</a></p></li>
<li><p>early stopping is very similar to ridge regression</p></li>
<li><p>ridge regression: soln will lie in <span class="math notranslate nohighlight">\(p-dim\)</span> row-space of X (span of the rows)</p>
<ul>
<li><p>when <span class="math notranslate nohighlight">\(\lambda \to 0\)</span>, will give us min-norm soln (basically because we project onto <span class="math notranslate nohighlight">\(col(X)\)</span>)</p></li>
<li><p>early stopping in least squares</p>
<ul>
<li><p>if we initialize at 0, GD soln will always be in the row-space of X</p></li>
<li><p>GD will converge to min-norm soln (any soln not in the row-space will necessarily have larger norm)</p></li>
<li><p>similar to ridge (endpoints are the same) and can related their risks very closely when <span class="math notranslate nohighlight">\(\lambda = 1/t\)</span>, where <span class="math notranslate nohighlight">\(t\)</span> is GD time iterate</p>
<ul>
<li><p>assume gradient flow: take step-size to 0</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1805.12076">srebro understanding over-parameterization	</a></p>
<ul>
<li><p>ex. gunasekar et al 2017: unconstrained matrix completion</p>
<ul>
<li><p>grad descent on U, V yields min nuclear norm solution</p></li>
</ul>
</li>
<li><p>ex. <a class="reference external" href="http://www.jmlr.org/papers/volume19/18-188/18-188.pdf">soudry et al 2017</a></p>
<ul>
<li><p>sgd on logistic reg. gives hard margin svm</p></li>
<li><p>deep linear net gives the same thing - doesn’t actually changed anything</p></li>
</ul>
</li>
<li><p>ex. <a class="reference external" href="http://papers.nips.cc/paper/8156-implicit-bias-of-gradient-descent-on-linear-convolutional-networks">gunaskar, 2018</a></p>
<ul>
<li><p>linear convnets give smth better - minimum l1 norm in discrete fourier transform</p></li>
</ul>
</li>
<li><p>ex. savarese 2019</p>
<ul>
<li><p>infinite width relu net 1-d input</p></li>
<li><p>weight decay minimization minimizes derivative of TV</p></li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1805.08522">implicit bias towards simpler models</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1902.05040.pdf">How do infinite width bounded norm networks look in function space?</a> (savarese…srebro 2019)</p>
<ul>
<li><p>minimal norm fit for a sample is given by a linear spline interpolation (2 layer net)</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1809.10374">analytic theory of generalization + transfer (ganguli 19)</a></p>
<ul>
<li><p>deep linear nets learn important structure of the data first (less noisy eigenvectors)</p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1904.13262.pdf">similar paper for layer nets</a></p></li>
</ul>
</li>
<li><p>datasets for measuring causality</p>
<ul>
<li><p>Inferring Hidden Statuses and Actions in Video by Causal Reasoning - about finding causality in the video, not interpretation</p></li>
</ul>
</li>
<li><p><strong>PL condition</strong> = Polyak-Lojawsiewicz condition guarantees global convergence of loca methods</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(||\nabla f(x)||^2 \geq \alpha f(x) \geq 0\)</span></p></li>
</ul>
</li>
</ul>
</section>
<section id="semantic-biases-what-correlations-will-a-net-learn">
<h3><span class="section-number">7.11.1.3. </span>semantic biases: what correlations will a net learn?<a class="headerlink" href="#semantic-biases-what-correlations-will-a-net-learn" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/abs/1811.12231">imagenet models are biased towards texture</a> (and removing texture makes them more robust)</p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1904.04621.pdf">analyzing semantic robustness</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1712.06302">eval w/ simulations</a> (reviewer argued against this)</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1903.06256">glcm captures superficial statistics</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1903.12261">deeper, unpruned networks are better against noise</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1809.10374">analytic theory of generalization + transfer (ganguli 19)</a></p></li>
<li><p><a class="reference external" href="https://www.technologyreview.com/s/613502/deep-learning-could-reveal-why-the-world-works-the-way-it-does/">causality in dnns talk by bottou</a></p>
<ul>
<li><p>on mnist, color vs shape will learn color</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1810.10531">A mathematical theory of semantic development in deep neural networks</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1803.03453.pdf">rl agents learn some crazy things</a></p>
<ul>
<li><p><a class="reference external" href="https://docs.google.com/spreadsheets/u/1/d/e/2PACX-1vRPiprOaC3HsCf5Tuum8bRfzYUiKLRqJmbOoC-32JorNdfyTiRRsR7Ea5eWtvsWzuxo8bjOxCG84dAg/pubhtml">itemized list</a></p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1706.01350">Emergence of Invariance and Disentanglement in Deep Representations</a> (achille &amp; soatto 2018)</p>
<ul>
<li><p>information in the weights as a measure of complexity of a learned model (information complexity)</p></li>
<li><p>IB Lagrangian between the <strong>weights of a network and the training data</strong>, as opposed to the traditional one between the <strong>activations and the test datum</strong></p></li>
<li><p>explains tradeoff between over/underfitting</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2007.00823">On Dropout, Overfitting, and Interaction Effects in Deep Neural Networks</a> (lengerich..caruana, 2020)</p>
<ul>
<li><p>use ANOVA to meaure 1st/2nd/3rd order effects and such</p>
<ul>
<li><p>approximate ANOVA decomp. using boosted trees of depth based on a particular order</p></li>
</ul>
</li>
</ul>
</li>
<li><p>they find that increasing dropout rate forces nets to emphasize lower-order effects</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2005.04345">An Investigation of Why Overparameterization Exacerbates Spurious Correlations</a></p>
<ul>
<li><p>overparameterization can hurt test error on minority groups despite improving average test error when there are spurious correlations in the data</p></li>
</ul>
</li>
</ul>
</section>
<section id="expressiveness-what-can-a-dnn-represent">
<h3><span class="section-number">7.11.1.4. </span>expressiveness: what can a dnn represent?<a class="headerlink" href="#expressiveness-what-can-a-dnn-represent" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/pdf/1901.09021.pdf">complexity of linear regions in deep networks</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1711.02114.pdf">Bounding and Counting Linear Regions of Deep Neural Networks</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1606.05336.pdf">On the Expressive Power of Deep Neural Networks</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1906.00904.pdf">Deep ReLU Networks Have Surprisingly Few Activation Patterns</a></p></li>
</ul>
</section>
<section id="complexity-generalization-dnns-are-low-rank-redundant-parameters">
<h3><span class="section-number">7.11.1.5. </span>complexity + generalization: dnns are low-rank / redundant parameters<a class="headerlink" href="#complexity-generalization-dnns-are-low-rank-redundant-parameters" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>measuring complexity</p>
<ul>
<li><p><a class="reference external" href="https://arxiv.org/abs/1904.03867">functional decomposition</a> (molnar 2019)</p>
<ul>
<li><p>decompose function into bias + first-order effects (ALE) + interactions</p></li>
<li><p>3 things: number of features used, interaction strength, main effect complexity</p></li>
</ul>
</li>
</ul>
</li>
<li><p>parameters are redundant</p>
<ul>
<li><p><a class="reference external" href="http://papers.nips.cc/paper/5025-predicting-parameters-in-deep-learning">predicting params</a>: weight matrices are low-rank, decompose into UV by picking a U</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1507.06149">pruning neurons</a></p></li>
<li><p><a class="reference external" href="https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Cheng_An_Exploration_of_ICCV_2015_paper.pdf">circulant projection</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1810.05270.pdf">rethinking the value of pruning</a>: pruning and training from scratch, upto 30% size</p></li>
<li><p><a class="reference external" href="https://openreview.net/pdf?id=rJl-b3RcF7">Lottery ticket</a>: pruning and training from initial random weights, upto 1% size (<a class="reference external" href="https://arxiv.org/abs/1903.01611">followup</a>)</p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1810.03372.pdf">rank of relu activations</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1504.08291.pdf">random weights are good</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1805.10408.pdf">singular values of conv layers</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1904.02698">T-Net: Parametrizing Fully Convolutional Nets with a Single High-Order Tensor</a></p></li>
</ul>
</li>
<li><p>generalization</p>
<ul>
<li><p><a class="reference external" href="http://eprints.qut.edu.au/43927/">size of the weights is more important</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1905.11427v1.pdf">Quantifying the generalization error in deep learning in terms of data distribution and
neural network smoothness</a></p></li>
</ul>
</li>
</ul>
</section>
<section id="nearest-neighbor-comparisons">
<h3><span class="section-number">7.11.1.6. </span>nearest neighbor comparisons<a class="headerlink" href="#nearest-neighbor-comparisons" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="http://papers.nips.cc/paper/7498-overfitting-or-perfect-fitting-risk-bounds-for-classification-and-regression-rules-that-interpolate">weighted interpolating nearest neighbors can generalize well (belkin…mitra 2018)</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1810.02814">Statistical Optimality of Interpolated Nearest Neighbor Algorithms</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1805.06822.pdf">nearest neighbor comparison</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1803.04765.pdf">nearest embedding neighbors</a></p></li>
</ul>
</section>
<section id="kernels">
<h3><span class="section-number">7.11.1.7. </span>kernels<a class="headerlink" href="#kernels" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/abs/1802.01396">To understand deep learning we need to understand kernel learning</a> - overfitted kernel classifiers can still fit the data well</p></li>
<li><p>original kernels (neal 1994) + (lee et al. 2018) + (matthews et al. 2018)</p>
<ul>
<li><p>infinitely wide nets and only top layer is trained</p></li>
<li><p>corresponds to kernel <span class="math notranslate nohighlight">\(\text{ker}(x, x') = \mathbb E_{\theta \sim W}[f(\theta, x) \cdot f(\theta, x')]\)</span>, where <span class="math notranslate nohighlight">\(W\)</span> is an intialization distr. over <span class="math notranslate nohighlight">\(\theta\)</span></p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1806.07572">neural tangent kernel</a> (jacot et al. 2018)</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\text{ker}(x, x') = \mathbb E_{\theta \sim W} \left[\left &lt; \frac{f(\theta, x)}{\partial \theta} \cdot \frac{f(\theta, x')}{\partial \theta} \right&gt; \right]\)</span> - evolution of weights over time follows this kernel</p>
<ul>
<li><p>with very large width, this kernel is the NTK at initialization</p></li>
<li><p>stays stable during training (since weights don’t change much)</p></li>
</ul>
</li>
<li><p>at initialization, artificial neural networks (ANNs) are equivalent to Gaussian processes in the infinite-width limit</p>
<ul>
<li><p>evolution of an ANN during training can also be described by a kernel (kernel gradient descent)</p></li>
</ul>
</li>
<li><p>different types of kernels impose different things on a function (e.g. want more / less low frequencies)</p>
<ul>
<li><p>gradient descent in kernel space can be convex if kernel is PD (even if nonconvex in the parameter space)</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1904.11955.pdf">understanding the neural tangent kernel</a> (arora et al. 2019)</p>
<ul>
<li><p>method to compute the kernel quickly on a gpu</p></li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1901.01608">Scaling description of generalization with number of parameters in deep learning</a> (geiger et al. 2019)</p>
<ul>
<li><p>number of params = N</p></li>
<li><p>above 0 training err, larger number of params reduces variance but doesn’t actually help</p>
<ul>
<li><p>ensembling with smaller N fixes problem</p></li>
</ul>
</li>
<li><p>the improvement of generalization performance with N in this classification task originates from reduced variance of fN when N gets large, as recently observed for mean-square regression</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1905.12173">On the Inductive Bias of Neural Tangent Kernels</a> (bietti &amp; mairal 2019)</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1906.05827">Kernel and Deep Regimes in Overparametrized Models</a> (Woodworth…Srebro 2019)</p>
<ul>
<li><p>transition between <em>kernel</em> and <em>deep regimes</em></p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1908.01580">The HSIC Bottleneck: Deep Learning without Back-Propagation</a> (Ma et al. 2019)</p>
<ul>
<li><p>directly optimize information bottleneck (approximated by HSIC) yields pretty good results</p></li>
</ul>
</li>
</ul>
</section>
<section id="random-projections">
<h3><span class="section-number">7.11.1.8. </span>random projections<a class="headerlink" href="#random-projections" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="http://proceedings.mlr.press/v32/andoni14.pdf">sgd for polynomials</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1811.10495.pdf">deep linear better than just linear</a></p></li>
<li><p>relation to bousquet - fitting random polynomials</p></li>
<li><p><a class="reference external" href="https://pdfs.semanticscholar.org/9636/d8aedd476ef19c762923119750aec95bf8ca.pdf">hierarchical sparse coding for images</a> (can’t just repeat sparse coding, need to include input again)</p></li>
</ul>
</section>
<section id="implicit-dl-optimization">
<h3><span class="section-number">7.11.1.9. </span>implicit dl + optimization<a class="headerlink" href="#implicit-dl-optimization" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/abs/1908.06315">implicit deep learning</a> (el ghaoui et al. 2019)</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\hat y (u) = Cx + D u \)</span>, where <span class="math notranslate nohighlight">\(x = \phi(Ax + Bu)\)</span></p>
<ul>
<li><p>here, <span class="math notranslate nohighlight">\(u\)</span> is a new input</p></li>
<li><p><span class="math notranslate nohighlight">\(x\)</span> is a hidden state which represents some hidden features (which depends on <span class="math notranslate nohighlight">\(u\)</span>)</p>
<ul>
<li><p><strong>well-posedness</strong> - want x to be unique for a given u</p></li>
</ul>
</li>
<li><p><span class="math notranslate nohighlight">\(A, B\)</span> are matrices which let us compute <span class="math notranslate nohighlight">\(x\)</span> given <span class="math notranslate nohighlight">\(u\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(C, D\)</span> help us do the final prediction (like the final linear layer)</p></li>
</ul>
</li>
<li><p>ex. feedforward nets</p>
<ul>
<li><p>consider net with <span class="math notranslate nohighlight">\(L\)</span> layers</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(x_0 = u\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(x_{l + 1} = \phi_l (W_l x_l)\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\hat y (u) = W_L x_L\)</span></p></li>
</ul>
</li>
<li><p>rewriting in implicit form</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(x = (x_L, ..., x_1)\)</span> - concatenate all the activations into one big vector</p></li>
<li><p><img alt="implicit_dl" src="../../_images/implicit_dl.png" /></p></li>
<li><p>ex. <span class="math notranslate nohighlight">\(Ax + Bu= \begin{bmatrix} W_{L-1}x_{L-1} \\ W_{L-2} x_{L-2} \\ \vdots \\ W_1x_1 \\ \mathbf 0\end{bmatrix} + \begin{bmatrix} 0 \\ 0 \\ \vdots \\ 0 \\ W_0 u \end{bmatrix}\)</span></p></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1805.01532">lifted neural networks</a> (askari et al. 2018)</p>
<ul>
<li><p>can solve dnn <span class="math notranslate nohighlight">\(\hat y = \phi(W_2 \phi (W_1X_0))\)</span> by rewriting using constraints:</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(X_1 = \phi(W_1 X_0)\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(X_2 = \phi(W_2 X_1)\)</span></p></li>
</ul>
</li>
<li><p><span class="math notranslate nohighlight">\(\begin{align} &amp;\min (y - \hat y)^2\\s.t. X_1 &amp;= \phi(WX_0)\\X_2 &amp;= \phi(WX_1)\end{align}\)</span></p></li>
<li><p>can be written using Lagrangian multipliers: <span class="math notranslate nohighlight">\(\min (y - \hat y)^2 + \lambda_1( X_1 - \phi(WX_0)) + \lambda_2(X_2 - \phi(WX_1))\)</span></p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1811.08039">Fenchel Lifted Networks: A Lagrange Relaxation of Neural Network Training</a> (gu et al. 2018)</p>
<ul>
<li><p>in the lifted setting above, can replace Lagrangian with simpler expression using Fenchel conjugates</p></li>
</ul>
</li>
<li><p>robust optimization basics</p>
<ul>
<li><p>immunize optimization problems against uncertainty in the data</p></li>
<li><p>do so by having worst-case constraints (e.g. <span class="math notranslate nohighlight">\(a &lt; 5, \forall a\)</span>)</p></li>
<li><p><em>local robustness</em> - maximize radius surrounding parameter subject to all constraints (no objective to maximize)</p></li>
<li><p><em>global robustness</em> - maximize objective subject to robustness constraint  (trades off robustness with objective value)</p></li>
<li><p><em>non-probabilistic robust optimization models</em> (e.g. Wald’s maximin model: <span class="math notranslate nohighlight">\(\underset{x}{\max} \underset{u}{\min} f(x, u)\)</span></p></li>
<li><p>also are <em>probabilistically robust optimization</em></p></li>
</ul>
</li>
<li><p>distributional robustness - using moments in the dl work</p>
<ul>
<li><p>ch 4 and ch10 of <a class="reference external" href="https://people.eecs.berkeley.edu/~elghaoui/robbook.html">robust optimization book</a> (bental, el ghaoui, &amp; nemirovski 2009)</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1710.10571">Certifying Some Distributional Robustness with Principled Adversarial Training</a> (sinha,  namkoong, &amp; duchi 2018)</p>
<ul>
<li><p>want to guarantee performance under adversarial input perturbations</p></li>
<li><p>considering a Lagrangian penalty formulation of perturbing the underlying data distribution in a Wasserstein ball</p>
<ul>
<li><p>during training, augments model parameter updates with worst-case perturbations of training data</p></li>
</ul>
</li>
<li><p>little extra cost and achieves guarantees for smooth losses</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://pdfs.semanticscholar.org/dc8a/e0f1ee878d68208184d123020f1acd2525bb.pdf">On Distributionally Robust Chance-Constrained Linear Programs</a> (calafiore &amp; el ghaoui 2006)</p>
<ul>
<li><p>linear programs where data (in the constraints) is random</p></li>
<li><p>want to enforce the constraints up to a given prob. level</p></li>
<li><p>can convert the prob. constraints into convex 2nd-order cone constraints</p></li>
<li><p>under distrs. for the random data, can guarantee constraints</p></li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference external" href="http://web.stanford.edu/~boyd/papers/pdf/diff_cvxpy.pdf">Differentiable Convex Optimization Layers</a> (agrawal et al. 2019)</p></li>
</ul>
</section>
<section id="statistical-physics">
<h3><span class="section-number">7.11.1.10. </span>statistical physics<a class="headerlink" href="#statistical-physics" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://www.annualreviews.org/doi/abs/10.1146/annurev-conmatphys-031119-050745">Statistical Mechanics of Deep Learning</a> (bahri et al. 2019)</p>
<ul>
<li><p>what is the advantage of depth  - connect to dynamical phase transitions</p>
<ul>
<li><p>there are several function which require only polynomial nodes in each layer for deep nets, but exponential for shallow nets</p></li>
</ul>
</li>
<li><p>what is the shape of the loss landscape - connect to random Gaussian processes, sping glasses, and jamming</p></li>
<li><p>how to pick a good parameter initialization?</p></li>
<li><p>bounding generalization error</p>
<ul>
<li><p>often, generalization bounds take the form <span class="math notranslate nohighlight">\(\epsilon_{test} \leq \epsilon_{train} + \frac {\mathcal C (\mathcal F)} p\)</span>, where <span class="math notranslate nohighlight">\(\mathcal C (\mathcal F)\)</span> is the complexity of a function class and <span class="math notranslate nohighlight">\(p\)</span> is the number of examples</p>
<ul>
<li><p>ex. VC-dimension, Rademacher complexity</p></li>
</ul>
</li>
<li><p>alternative framework: algorithmic stability - will generalize if map is stable wrt perturbations of the data <span class="math notranslate nohighlight">\(\mathcal D\)</span></p></li>
<li><p>altenative: PAC bounds suggest if distr. of weights doesn’t change much during training, generalization will be succesful</p></li>
</ul>
</li>
<li><p>deep linear networks</p>
<ul>
<li><p>student learns biggest singular values of the input-output correlation matrix <span class="math notranslate nohighlight">\(\Sigma = \sum_i y_i x_i^T\)</span>, so it learns the important stuff first and the noise last</p></li>
</ul>
</li>
<li><p>infinite-width limit</p>
<ul>
<li><p>if parameters are random, indcues a prior distribution <span class="math notranslate nohighlight">\(P(\mathcal F)\)</span> over the space of functions</p></li>
<li><p>in th limit of infinite width, this prior is Gaussian, with a specific correlation kernel</p></li>
<li><p>learning is similar to learning the Bayesian posterior <span class="math notranslate nohighlight">\(P(f|data)\)</span>, but connecting this to sgd is still not clear</p></li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2012.04728">Neural Mechanics: Symmetry and Broken Conservation Laws in Deep Learning Dynamics</a> (kunin et al. 2020)</p>
<ul>
<li><p>no assumptions about DNN architecture or gradientflow</p></li>
<li><p>instead, assumptions on symmetries embedded in a network’s architecture constrain training dynamics</p>
<ul>
<li><p>similar to Noether’s thm in physics</p></li>
</ul>
</li>
<li><p>can much better analytically describe learning dynamics</p></li>
<li><p>weights have a <strong>differentiable symmetry</strong> in the loss if the loss doesn’t change under a certain differentiable transformation of the weights</p>
<ul>
<li><p>ex. translation symmetry - for layer before softmax, we get symmetries across weights that shift all outputs</p></li>
<li><p>ex. scale symmetry - inputs to batch normalization are invariant to scaling</p></li>
<li><p>ex. rescale symmetry - scaling up/down 2 things which multiply or add</p></li>
</ul>
</li>
<li><p>modeling discretization</p></li>
</ul>
</li>
</ul>
</section>
</section>
<section id="empirical-studies">
<h2><span class="section-number">7.11.2. </span>empirical studies<a class="headerlink" href="#empirical-studies" title="Link to this heading">#</a></h2>
<section id="interesting-empirical-papers">
<h3><span class="section-number">7.11.2.1. </span>interesting empirical papers<a class="headerlink" href="#interesting-empirical-papers" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/abs/1803.03635">modularity (“lottery ticket hypothesis”)</a></p>
<ul>
<li><p>contemporary experience is that it is difficult to train small architectures from scratch, which would similarly improve training performance - <strong>lottery ticket hypothesis</strong>: large networks that train successfully contain subnetworks that–when trained in isolation–converge in a comparable number of iterations to comparable accuracy</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1812.05687">ablation studies</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1705.10694.pdf">deep learning is robust to massive label noise</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1902.01996.pdf">are all layers created equal?</a></p></li>
<li><p><a class="reference external" href="https://openreview.net/forum?id=HyxyIgHFvr">Truth or backpropaganda? An empirical investigation of deep learning theory</a></p></li>
</ul>
</section>
<section id="adversarial-robustness">
<h3><span class="section-number">7.11.2.2. </span>adversarial + robustness<a class="headerlink" href="#adversarial-robustness" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://openreview.net/pdf?id=SyxAb30cY7">robustness may be at odds with accuracy</a> (madry 2019)</p>
<ul>
<li><p>adversarial training helps w/ little data but hurts with lots of data</p></li>
<li><p>adversarially trained models have more meaningful gradients (and their adversarial examples actually look like other classes)</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1804.00504">Generalizability vs. Robustness: Adversarial Examples for Medical Imaging</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1806.07538.pdf">Towards Robust Interpretability with Self-Explaining Neural Networks</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1909.08072">Adversarial Attacks and Defenses in Images, Graphs and Text: A Review</a> (xu et al. 2019)</p>
<ul>
<li><p><em>Adversarial examples are inputs to machine learning models that an attacker intentionally designed to cause the model to make mistakes</em></p></li>
<li><p>threat models</p>
<ul>
<li><p>poisoning attack (insert fake samples into training data) vs. evasion attack (just evade at test time)</p></li>
<li><p>targeted attack (want specific class) vs. non-targeted attack (just change the prediction)</p></li>
</ul>
</li>
<li><p>adversary’s knowledge</p>
<ul>
<li><p>white-box - adversary knows everything</p></li>
<li><p>black-box - can only feed inputs and get outputs</p></li>
<li><p>gray-box - might have white box for limited amount of time</p></li>
</ul>
</li>
<li><p>security evaluation</p>
<ul>
<li><p>robustness - minimum norm perturbation to change class</p></li>
<li><p>adversarial loss - biggest change in loss within some epsilon ball</p></li>
</ul>
</li>
<li><p><img alt="Screen Shot 2020-02-04 at 1.54.49 PM" src="../../_images/adv_attacks_table.png" /></p></li>
<li><p><img alt="Screen Shot 2020-02-04 at 1.54.28 PM" src="../../_images/adv_attack_hierarchy.png" /></p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1912.02781">AugMix: A Simple Data Processing Method to Improve Robustness and Uncertainty</a> (hendrycks et al. 2020)</p>
<ul>
<li><p>do a bunch of transformations and average images to create each training image</p></li>
</ul>
</li>
<li><p>certifying robustness</p>
<ul>
<li><p>bound gradients of f around x - solve SDP for 2-layer net (<a class="reference external" href="https://arxiv.org/abs/1801.09344">raghunathan, steinhardt, &amp; liang 2018, iclr</a>)</p>
<ul>
<li><p>relax SDP and then applies to multilayer nets (raghunathan et al. 2018)</p></li>
<li><p>improved optimizer for the SDP (dathathri et al. 2020)</p></li>
</ul>
</li>
<li><p>interval bound propagation - instead of passing point, pass an interval where it could be</p>
<ul>
<li><p>works well for word substitions (jia et al. 2019)</p></li>
</ul>
</li>
<li><p>RobEn - cluster words that are confusable + give them the same encoding when you train (jones et al. 2020)</p>
<ul>
<li><p>then you are robust to confusing the words</p></li>
</ul>
</li>
</ul>
</li>
<li><p>unlabeled data + self-training helps</p>
<ul>
<li><p>training robust models has higher sample complexity than training standard models</p></li>
<li><p>tradeoff between robustness and accuracy (raghunathann et al. 2020)</p>
<ul>
<li><p>adding valid data can hurt even in well-specified, convex setting</p></li>
<li><p>robust self-training eliminates this tradeoff in linear regression</p></li>
</ul>
</li>
<li><p>sample complexity can be reduced with unlabeled examples (carmon et al. 2019)</p></li>
</ul>
</li>
<li><p>distributional robust optimization</p>
<ul>
<li><p>instead of minimizing training err, minimize maximum training err over different perturbations</p></li>
<li><p>hard to pick the perturbation set - can easily be too pessimistic</p></li>
<li><p>these things possibly magnify disparities</p>
<ul>
<li><p>larger models</p></li>
<li><p>selective classification</p></li>
<li><p>feature noise</p></li>
<li><p>removing spurious features</p></li>
</ul>
</li>
<li><p>group DRO (sagawa et al. 2020) - maximize error for worst group</p>
<ul>
<li><p>need to add regularization to keep errors from going to 0</p></li>
<li><p>training overparameterized models makes this problem worse</p></li>
</ul>
</li>
<li><p>abstain from classifying based on confidence (jones et al. 2020)</p>
<ul>
<li><p>makes error rates worse for worst group = selective classification can magnify disparities</p></li>
</ul>
</li>
<li><p>adding feature noise to each group can magnify disparities</p></li>
</ul>
</li>
<li><p>domain adaptation</p>
<ul>
<li><p>standard domain adaptation: labeled (x, y) in source and unlabeled x in target</p></li>
<li><p>gradual domain adaptation - things change slowly over time, can use gradual self-training (kumar et al. 2020)</p></li>
<li><p>In-N-Out (xie et al. 2020) - if we have many features, rather than using them all as features, can use some as features and some as targets when we shift, to learn the domain shift</p></li>
</ul>
</li>
</ul>
</section>
<section id="tools-for-analyzing">
<h3><span class="section-number">7.11.2.3. </span>tools for analyzing<a class="headerlink" href="#tools-for-analyzing" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>dim reduction: <a class="reference external" href="http://papers.nips.cc/paper/7188-svcca-singular-vector-canonical-correlation-analysis-for-deep-understanding-and-improvement">svcca</a>, diffusion maps</p></li>
<li><p>viz tools: <a class="reference external" href="http://www.sci.utah.edu/~beiwang/">bei wang</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1712.09913.pdf">visualizing loss landscape</a></p></li>
<li><p>1d: plot loss by extrapolating between 2 points (start/end, 2 ends)</p>
<ul>
<li><p>goodfellow et al. 2015, im et al. 2016</p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1803.00885.pdf">exploring landscape with this technique</a></p></li>
<li><p>2d: plot loss on a grid in 2 directions</p></li>
<li><p>important to think about scale invariance (dinh et al. 2017)</p></li>
<li><p>want to scale direction vector to have same norm in each direction as filter</p></li>
<li><p>use PCA to find important directions (ex. sample w at each step, pca to find most important directions of variance)</p></li>
</ul>
</li>
</ul>
</section>
<section id="misc-theoretical-areas">
<h3><span class="section-number">7.11.2.4. </span>misc theoretical areas<a class="headerlink" href="#misc-theoretical-areas" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>deep vs. shallow <a class="reference external" href="http://cbmm.mit.edu/sites/default/files/publications/CBMM-Memo-058v5.pdf">rvw</a></p></li>
<li><p><a class="reference external" href="https://www.nari.ee.ethz.ch/commth//pubs/files/deep-2016.pdf">probabilistic framework</a></p></li>
<li><p>information bottleneck: tishby paper + david cox follow-up</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1706.01350">Emergence of Invariance and Disentanglement in Deep Representations</a></p></li>
<li><p><a class="reference external" href="https://www.deeplearningbook.org/version-2015-10-03/contents/manifolds.html">manifold learning</a></p>
<ul>
<li><p><a class="reference external" href="https://ieeexplore.ieee.org/document/7348689/">random manifold learning paper</a></p></li>
</ul>
</li>
</ul>
</section>
<section id="comparing-representations">
<h3><span class="section-number">7.11.2.5. </span>comparing representations<a class="headerlink" href="#comparing-representations" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/abs/1811.11684">shared representations across nets</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1810.11750">comparing across random initializations</a></p></li>
</ul>
</section>
<section id="simple-papers">
<h3><span class="section-number">7.11.2.6. </span>simple papers<a class="headerlink" href="#simple-papers" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/pdf/1904.00687.pdf">rvw of random features approach</a></p></li>
<li><p><a class="reference external" href="http://proceedings.mlr.press/v44/li15convergent.pdf">similar nets learn different weights</a></p></li>
</ul>
</section>
<section id="adam-vs-sgd">
<h3><span class="section-number">7.11.2.7. </span>adam vs sgd<a class="headerlink" href="#adam-vs-sgd" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>svd parameterization rnn paper: <a class="reference external" href="https://arxiv.org/pdf/1803.09327.pdf">inderjit paper</a></p>
<ul>
<li><p>original adam paper: <a class="reference external" href="https://arxiv.org/abs/1412.6980">kingma 15</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1806.00900.pdf">regularization via SGD</a> (layers are balanced: du 18)</p></li>
<li><p>marginal value of adaptive methods: <a class="reference external" href="http://papers.nips.cc/paper/7003-the-marginal-value-of-adaptive-gradient-methods-in-machine-learning">recht 17</a></p></li>
<li><p>comparing representations: <a class="reference external" href="https://arxiv.org/abs/1706.05806">svcca</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1804.06561.pdf">montanari 18</a> pde mean field view</p></li>
<li><p><a class="reference external" href="http://papers.nips.cc/paper/7204-spectrally-normalized-margin-bounds-for-neural-networks">normalized margin bounds</a></p></li>
</ul>
</li>
</ul>
</section>
<section id="memorization-background">
<h3><span class="section-number">7.11.2.8. </span>memorization background<a class="headerlink" href="#memorization-background" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/abs/1902.04698v2">memorization on single training example</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1706.05394.pdf">memorization in dnns</a></p></li>
<li><p>“memorization” as the behavior exhibited by DNNs trained on noise, and conduct a series of experiments that contrast the learning dynamics of DNNs on real vs. noise data</p>
<ul>
<li><p>look at critical samples - adversarial exists nearby</p></li>
</ul>
</li>
<li><p>networks that generalize well have deep layers that are approximately linear with respect to batches of similar inputs</p>
<ul>
<li><p>networks that memorize their training data are highly non-linear with respect to similar inputs, even in deep layers</p></li>
<li><p>expect that with respect to a single class, deep layers are approximately linear</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://openreview.net/forum?id=BJlxm30cKm">example forgetting paper</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1802.08232">secret sharing</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1810.10333">memorization in overparameterized autoencoders</a></p>
<ul>
<li><p>autoencoders don’t lean identity, but learn projection onto span of training examples = memorization of training examples</p></li>
<li><p>sometimes output individual training images, not just project onto space of training images</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1810.10333.pdf">https://arxiv.org/pdf/1810.10333.pdf</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1909.12362.pdf">https://arxiv.org/pdf/1909.12362.pdf</a></p></li>
<li><p><a class="reference external" href="https://pdfs.semanticscholar.org/a624/6278cb5e2d0ab79fe20fe20a41c586732a11.pdf">https://pdfs.semanticscholar.org/a624/6278cb5e2d0ab79fe20fe20a41c586732a11.pdf</a></p></li>
<li><p><a class="reference external" href="http://www.yann-ollivier.org/rech/publs/aagen.pdf">Auto-encoders: reconstruction versus compression</a></p></li>
</ul>
</section>
<section id="probabilistic-inference">
<h3><span class="section-number">7.11.2.9. </span>probabilistic inference<a class="headerlink" href="#probabilistic-inference" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>multilayer idea</p></li>
<li><p><a class="reference external" href="https://www.frontiersin.org/articles/10.3389/fncom.2017.00024/full">equilibrium propagation</a></p></li>
</ul>
</section>
<section id="architecture-search-background">
<h3><span class="section-number">7.11.2.10. </span>architecture search background<a class="headerlink" href="#architecture-search-background" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>ideas: nested search (retrain each time), joint search (make arch search differentiable), one-shot search (train big net then search for subnet)</p>
<ul>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1904.04123.pdf">asap: online pruning + training</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1904.00438">rvw</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1611.01578">original (dumb) strategy</a></p></li>
<li><p><a class="reference external" href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Chenxi_Liu_Progressive_Neural_Architecture_ECCV_2018_paper.pdf">progressive nas</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1802.03268">Efficient Neural Architecture Search via Parameter Sharing</a> - sharing params</p></li>
<li><p><a class="reference external" href="https://link.springer.com/chapter/10.1007/978-3-319-46493-0_39">randomly replace layers with the identity when training</a></p></li>
<li><p><a class="reference external" href="https://pdfs.semanticscholar.org/1ff9/a37d766e3a4f39757f5e1b235a42dacf18ff.pdf">learning both weights and connections</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1904.00420">single-path one-shot search</a></p></li>
</ul>
</li>
</ul>
</section>
<section id="bagging-and-boosting">
<h3><span class="section-number">7.11.2.11. </span>bagging and boosting<a class="headerlink" href="#bagging-and-boosting" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://projecteuclid.org/download/pdf_1/euclid.aos/1031689014">analyzing bagging</a> (buhlmann and yu 2002)</p></li>
<li><p><a class="reference external" href="http://zmjones.com/static/statistical-learning/buhlmann-jasa-2003.pdf">boosting with the L2 loss</a> (buhlmann &amp; yu 2003)</p></li>
<li><p><a class="reference external" href="http://papers.nips.cc/paper/1766-boosting-algorithms-as-gradient-descent.pdf">boosting algorithms as gradient descent</a> (mason et al. 2000)</p></li>
</ul>
</section>
</section>
<section id="basics">
<h2><span class="section-number">7.11.3. </span>basics<a class="headerlink" href="#basics" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://people.csail.mit.edu/madry/6.883/">good set of class notes</a></p></li>
<li><p>demos to gain intuition</p>
<ul>
<li><p><a class="reference external" href="http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/">colah</a></p>
<ul>
<li><p><a class="reference external" href="https://playground.tensorflow.org/">tf playground</a></p></li>
<li><p><a class="reference external" href="https://cs.stanford.edu/people/karpathy/convnetjs//demo/classify2d.html">convnetJS</a></p></li>
<li><p><a class="reference external" href="http://ml-playground.com/">ml playground</a></p></li>
</ul>
</li>
<li><p>overview / reviews</p>
<ul>
<li><p><a class="reference external" href="https://arxiv.org/abs/1712.04741">mathematics of dl</a></p></li>
<li><p><a class="reference external" href="https://stats385.github.io/">stanford class</a> (<a class="reference external" href="https://stats385.github.io/readings">good readings</a>)</p></li>
<li><p><a class="reference external" href="http://dalimeeting.org/dali2018/workshopTheoryDL.html">dali 2018 talks</a></p></li>
<li><p><a class="reference external" href="http://www.mit.edu/~rakhlin/papers/myths.pdf">overview (myths)</a></p></li>
</ul>
</li>
</ul>
</li>
<li><p>some people involved: nathan srebro, sanjeev arora, jascha sohl-dickstein, tomaso poggio, stefano soatto, ben recht, <a class="reference external" href="https://arxiv.org/abs/1803.08367">olivier bousquet</a>, jason lee, simon shaolei du</p>
<ul>
<li><p>interpretability: cynthia rudin, rich caruana, been kim, nicholas papernot, finale doshi-velez</p></li>
<li><p>neuro: eero simoncelli, haim sompolinsky</p></li>
</ul>
</li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./notes/research_ovws"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="ovw_complexity.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">7.10. </span>complexity</p>
      </div>
    </a>
    <a class="right-next"
       href="ovw_scat.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">7.12. </span>scattering transform</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#theoretical-studies">7.11.1. theoretical studies</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#functional-approximation">7.11.1.1. functional approximation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#inductive-bias-implicit-regularization-gradient-descent-finds-good-minima">7.11.1.2. inductive bias=implicit regularization: gradient descent finds good minima</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#semantic-biases-what-correlations-will-a-net-learn">7.11.1.3. semantic biases: what correlations will a net learn?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#expressiveness-what-can-a-dnn-represent">7.11.1.4. expressiveness: what can a dnn represent?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#complexity-generalization-dnns-are-low-rank-redundant-parameters">7.11.1.5. complexity + generalization: dnns are low-rank / redundant parameters</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#nearest-neighbor-comparisons">7.11.1.6. nearest neighbor comparisons</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#kernels">7.11.1.7. kernels</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#random-projections">7.11.1.8. random projections</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implicit-dl-optimization">7.11.1.9. implicit dl + optimization</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#statistical-physics">7.11.1.10. statistical physics</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#empirical-studies">7.11.2. empirical studies</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interesting-empirical-papers">7.11.2.1. interesting empirical papers</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#adversarial-robustness">7.11.2.2. adversarial + robustness</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tools-for-analyzing">7.11.2.3. tools for analyzing</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#misc-theoretical-areas">7.11.2.4. misc theoretical areas</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#comparing-representations">7.11.2.5. comparing representations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simple-papers">7.11.2.6. simple papers</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#adam-vs-sgd">7.11.2.7. adam vs sgd</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#memorization-background">7.11.2.8. memorization background</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#probabilistic-inference">7.11.2.9. probabilistic inference</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#architecture-search-background">7.11.2.10. architecture search background</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bagging-and-boosting">7.11.2.11. bagging and boosting</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#basics">7.11.3. basics</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Chandan Singh
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright None.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  <p>
Many of these images are taken from resources on the web.
</p>
</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>