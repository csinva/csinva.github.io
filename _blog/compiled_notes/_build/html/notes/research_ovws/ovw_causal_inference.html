
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>1.10. causal inference</title>
    
  <link rel="stylesheet" href="../../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.3da636dd464baa7582d2.js">

    <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../_static/language_data.js"></script>
    <script type="text/javascript" src="../../_static/togglebutton.js"></script>
    <script type="text/javascript" src="../../_static/clipboard.min.js"></script>
    <script type="text/javascript" src="../../_static/copybutton.js"></script>
    <script type="text/javascript">var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script type="text/javascript" src="../../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" type="text/javascript" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script type="text/javascript">
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" type="text/javascript" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="1.11. dl for neuro" href="ovw_dl_for_neuro.html" />
    <link rel="prev" title="1.9. ml in medicine" href="ovw_ml_medicine.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../index.html">
  
  <img src="../../_static/logo.png" class="logo" alt="logo">
  
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../intro.html">
   overview üëã
  </a>
 </li>
</ul>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 current active collapsible-parent">
  <a class="reference internal" href="research_ovws.html">
   1. research_ovws
  </a>
  <ul class="current collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="ovw_comp_neuro.html">
     1.1. comp neuro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ovw_transfer_learning.html">
     1.2. transfer learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ovw_disentanglement.html">
     1.3. disentanglement
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ovw_omics.html">
     1.4. omics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ovw_complexity.html">
     1.5. complexity
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ovw_interesting_science.html">
     1.6. interesting science
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ovw_dl_theory.html">
     1.7. dl theory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ovw_scat.html">
     1.8. scattering transform
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ovw_ml_medicine.html">
     1.9. ml in medicine
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     1.10. causal inference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ovw_dl_for_neuro.html">
     1.11. dl for neuro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ovw_uncertainty.html">
     1.12. uncertainty
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ovw_interp.html">
     1.13. interpretability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ovw_generalization.html">
     1.14. generalization
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../cs/cs.html">
   2. cs
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../cs/retrieval.html">
     2.1. info retrieval
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cs/data_structures.html">
     2.2. data structures
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cs/languages.html">
     2.3. languages
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cs/software.html">
     2.4. software engineering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cs/quantum.html">
     2.5. quantum
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cs/algo.html">
     2.6. algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cs/graphs.html">
     2.7. graphs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cs/databases.html">
     2.8. overview
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cs/databases.html#sql">
     2.9. sql
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cs/os.html">
     2.10. os
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cs/arch.html">
     2.11. architecture
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cs/reproducibility.html">
     2.12. reproducibility
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cs/comp_theory.html">
     2.13. cs theory
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../math/math.html">
   3. math
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../math/differential_equations.html">
     3.1. differential equations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../math/proofs.html">
     3.2. proofs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../math/analysis.html">
     3.3. real analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../math/linear_algebra.html">
     3.4. linear algebra
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../math/signals.html">
     3.5. signals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../math/optimization.html">
     3.6. optimization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../math/calculus.html">
     3.7. calculus
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../math/chaos.html">
     3.8. chaos
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../math/math_basics.html">
     3.9. math basics
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../stat/stat.html">
   4. stat
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../stat/graphical_models.html">
     4.1. graphical models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stat/data_analysis.html">
     4.2. data analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stat/testing.html">
     4.3. testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stat/causal_inference.html">
     4.4. causal inference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stat/info_theory.html">
     4.5. info theory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stat/linear_models.html">
     4.6. linear models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stat/time_series.html">
     4.7. time series
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stat/game_theory.html">
     4.8. game theory
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../ml/ml.html">
   5. ml
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../ml/kernels.html">
     5.1. kernels
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml/nlp.html">
     5.2. nlp
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml/comp_vision.html">
     5.3. computer vision
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml/structure_ml.html">
     5.4. structure learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml/classification.html">
     5.5. classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml/unsupervised.html">
     5.6. unsupervised
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml/deep_learning.html">
     5.7. deep learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml/feature_selection.html">
     5.8. feature selection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml/learning_theory.html">
     5.9. learning theory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml/evaluation.html">
     5.10. evaluation
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../ai/ai.html">
   6. ai
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../ai/search.html">
     6.1. search
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ai/decisions_rl.html">
     6.2. decisions, rl
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ai/fairness_sts.html">
     6.3. fairness, sts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ai/cogsci.html">
     6.4. cogsci
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ai/ai_futures.html">
     6.5. ai futures
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ai/logic.html">
     6.6. logic
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ai/philosophy.html">
     6.7. philosophy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ai/psychology.html">
     6.8. psychology
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ai/knowledge_rep.html">
     6.9. representations
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../neuro/neuro.html">
   7. neuro
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../neuro/disease.html">
     7.1. disease
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../neuro/brain_basics.html">
     7.2. brain basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../neuro/vissci.html">
     7.3. vision
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../neuro/comp_neuro.html">
     7.4. comp neuro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../neuro/sensory_input.html">
     7.5. sensory input
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../neuro/memory.html">
     7.6. memory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../neuro/motor.html">
     7.7. motor system
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../neuro/development.html">
     7.8. development
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/notes/research_ovws/ovw_causal_inference.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/csinva/csinva.github.io"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        
        
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#classic-studies">
   1.10.1. classic studies
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#natural-experiments">
     1.10.1.1. natural experiments
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#instrumental-variables">
     1.10.1.2. instrumental variables
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#matching">
     1.10.1.3. matching
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#paradoxes">
     1.10.1.4. ‚Äúparadoxes‚Äù
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#problems-beyond-ate">
   1.10.2. problems beyond ATE
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#causal-mechanisms">
     1.10.2.1. causal mechanisms
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#mediation-analysis">
       1.10.2.1.1. mediation analysis
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#heterogenous-treatment-effects">
     1.10.2.2. heterogenous treatment effects
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#reinforcement-policy-learning">
     1.10.2.3. reinforcement (policy) learning
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#causal-discovery">
     1.10.2.4. causal discovery
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#stable-invariant-predictors">
     1.10.2.5. stable/invariant predictors
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#invariance-hierarchies">
       1.10.2.5.1. invariance hierarchies
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#invariance-algorithms">
       1.10.2.5.2. invariance algorithms
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#misc-problems">
     1.10.2.6. misc problems
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#transferring-out-of-sample">
     1.10.2.7. transferring out-of-sample
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#different-assumptions-experimental-designs">
   1.10.3. different assumptions / experimental designs
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#synthetic-control-interventions">
     1.10.3.1. synthetic control/interventions
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#solutions-to-basic-problems">
   1.10.4. solutions to basic problems
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#learning-causal-representations">
     1.10.4.1. learning ‚Äúcausal representations‚Äù
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#limitations">
     1.10.4.2. limitations
    </a>
   </li>
  </ul>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="causal-inference">
<h1>1.10. causal inference<a class="headerlink" href="#causal-inference" title="Permalink to this headline">¬∂</a></h1>
<p>Some good packages: msft <a class="reference external" href="https://github.com/microsoft/EconML">econML</a>, uber <a class="reference external" href="https://github.com/uber/causalml">causalml</a>, msft <a class="reference external" href="https://github.com/microsoft/dowhy">dowhy</a></p>
<div class="section" id="classic-studies">
<h2>1.10.1. classic studies<a class="headerlink" href="#classic-studies" title="Permalink to this headline">¬∂</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://onlinelibrary.wiley.com/doi/full/10.1111/ajps.12187">Descriptive Representation and Judicial Outcomes in Multiethnic Societies</a> (Grossman et al. 2016)</p>
<ul>
<li><p>judicial outcomes of arabs depended on whether there was an Arab judge on the panel</p></li>
</ul>
</li>
<li><p><a class="reference external" href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.554.9675">Using Maimonides‚Äô Rule to Estimate the Effect of Class Size on Scholastic Achievement</a> (angrist &amp; lavy 1999)</p>
<ul>
<li><p>reducing class size induces a signicant and substantial increase in test scores for fourth and 5th graders, although not for third graders.</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://academic.oup.com/jnci/article/22/1/173/912572">Smoking and Lung Cancer: Recent Evidence and a Discussion of Some Questions</a> (cornfield et al. 1959)</p>
<ul>
<li><p>not a traditional statistics paper</p></li>
<li><p>most of it is a review of various scientific evidence about smoking and cancer</p></li>
<li><p>small methodology section that describes an early version of sensitivity analysis</p></li>
<li><p>describes one of the most important contributions causal inference has made to science</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://www.tandfonline.com/doi/abs/10.1198/jasa.2009.ap06589">Attributing Effects to a Cluster-Randomized Get-Out-the-Vote Campaign</a> (hansen &amp; bowers 2009)</p>
<ul>
<li><p>about a randomized experiment</p></li>
<li><p>proved complex to analyze and led to some controversy in political science</p></li>
<li><p>resolves that controversy using well-chosen statistical tools.</p></li>
<li><p>Because randomization is present in the design I think the assumptions are much less of a stretch than in many settings (this is also the case in the Angrist, Imbens, Rubin paper)</p></li>
</ul>
</li>
</ul>
<div class="section" id="natural-experiments">
<h3>1.10.1.1. natural experiments<a class="headerlink" href="#natural-experiments" title="Permalink to this headline">¬∂</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://alondoninheritance.com/london-characters/john-snow-soho-cholera-outbreak-1864/">John Snow on cholera</a> - natural experiment - change of water pollution allowed for computing effect of the water pollution on cholera</p></li>
<li><p><a class="reference external" href="http://www.hangartner.net/files/passportapsr.pdf">Who Gets a Swiss Passport? A Natural Experiment in Immigrant Discrimination</a> (Hainmueller &amp; Hangartner 2013)</p>
<ul>
<li><p>naturalization decisions vary with immigrants‚Äô attributes</p></li>
<li><p>is there immigration against immigrants based on country of origin?</p></li>
<li><p>citizenship requires voting by municipality</p></li>
</ul>
</li>
<li><p><a class="reference external" href="http://sekhon.berkeley.edu/papers/SekhonTitiunik.pdf">When Natural Experiments Are Neither Natural nor Experiments</a> (sekhon &amp; titunik 2012)</p>
<ul>
<li><p>even when natural interventions are randomly assigned, some of the treatment‚Äìcontrol comparisons made available by natural experiments may not be valid</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="instrumental-variables">
<h3>1.10.1.2. instrumental variables<a class="headerlink" href="#instrumental-variables" title="Permalink to this headline">¬∂</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://www.jstor.org/stable/2291629?seq=1#metadata_info_tab_contents">Identification of Causal Effects Using Instrumental Variables</a> (angrist, imbens, &amp; rubin 1996)</p>
<ul>
<li><p>bridges the literature of instrumental variables in econometrics and the literature of causal inference in statistics</p></li>
<li><p>applied paper with delicate statistics</p></li>
<li><p>carefully discuss the assumptions</p></li>
<li><p>instrumental variables - regression w/ constant treatment effects</p></li>
<li><p>effect of veteran status on mortality, using lottery number as instrument</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="matching">
<h3>1.10.1.3. matching<a class="headerlink" href="#matching" title="Permalink to this headline">¬∂</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://www.ncbi.nlm.nih.gov/pubmed/12933551">Matching and thick description in an observational study of mortality after surgery.</a> (rosenbaum &amp; silber 2001)</p>
<ul>
<li><p>spends a lot of time discussing links between quantitative and qualitative analyses</p></li>
<li><p>takes the process of checking assumptions very seriously, and it deals with an important scientific problem</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="paradoxes">
<h3>1.10.1.4. ‚Äúparadoxes‚Äù<a class="headerlink" href="#paradoxes" title="Permalink to this headline">¬∂</a></h3>
<ul class="simple">
<li><p><strong>simpson‚Äôs paradox</strong> = <strong>yule-simpson paradox</strong> - trend appears in several different groups but disappears/reverses when groups are combined</p>
<ul>
<li><p><a class="reference external" href="https://homepage.stat.uiowa.edu/~mbognar/1030/Bickel-Berkeley.pdf">Sex Bias in Graduate Admissions: Data from Berkeley</a> (bickel et al. 1975)</p></li>
<li><p>e.g. overall men seemed to have higher acceptance rates, but in each dept. women seemed to have higher acceptance rates - explanation is that women selectively apply to harder depts.</p></li>
</ul>
</li>
</ul>
<div class="highlight-mermaid notranslate"><div class="highlight"><pre><span></span>graph LR
A(Gender) --&gt;B(Dept Choice)
B --&gt; C(Acceptance rate)
A --&gt; C
</pre></div>
</div>
<ul class="simple">
<li><p>monty hall problem: why you should switch</p></li>
</ul>
<div class="highlight-mermaid notranslate"><div class="highlight"><pre><span></span>graph LR
A(Your Door) --&gt;B(Door Opened)
C(Location of Car) --&gt; B
</pre></div>
</div>
<ul class="simple">
<li><p>berkson‚Äôs paradox - diseases in hospitals are correlated even when they are not in the general population</p>
<ul>
<li><p>possible explanation - only having both diseases together is strong enough to put you in the hospital</p></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="problems-beyond-ate">
<h2>1.10.2. problems beyond ATE<a class="headerlink" href="#problems-beyond-ate" title="Permalink to this headline">¬∂</a></h2>
<div class="section" id="causal-mechanisms">
<h3>1.10.2.1. causal mechanisms<a class="headerlink" href="#causal-mechanisms" title="Permalink to this headline">¬∂</a></h3>
<ul class="simple">
<li><p>treatment effect variation?</p></li>
<li><p>principal stratification</p></li>
<li><p>interference</p></li>
</ul>
<div class="section" id="mediation-analysis">
<h4>1.10.2.1.1. mediation analysis<a class="headerlink" href="#mediation-analysis" title="Permalink to this headline">¬∂</a></h4>
<p><em>Mediation analysis aims to identify a mechanism through which a cause has an effect. Direct effects measure when the treatment varies as mediators are held constant.</em></p>
<ul class="simple">
<li><p>if there are multiple possible paths by which a variable can exert influence, can figure out which path does what, even with just observational data</p></li>
<li><p>cannot just condition on <span class="math notranslate nohighlight">\(M\)</span>! This can lead to spurious associations</p></li>
<li><p>which pathway do causes flow through from X to Y (direct/indirect?)</p></li>
<li><p><img alt="mediation_graph" src="../../_images/mediation_graph-5770090.png" /></p></li>
<li><p>consider potential outcomes with hypothetical intervention on <span class="math notranslate nohighlight">\(T\)</span>:</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\{M(t), Y(t)\}\)</span></p></li>
</ul>
</li>
<li><p>hypothetical intervention on <span class="math notranslate nohighlight">\(T\)</span> and <span class="math notranslate nohighlight">\(M\)</span>:</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\{Y(t, m)\}\)</span></p></li>
</ul>
</li>
<li><p>hypothetical intervention on <span class="math notranslate nohighlight">\(T\)</span> fixing <span class="math notranslate nohighlight">\(M\)</span> to <span class="math notranslate nohighlight">\(M(t') = M_{t'}\)</span> (nested potential outcome, robs &amp; greenland, 1992; pearl, 2001)</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\{Y(t, M_{t'})\}\)</span></p></li>
<li><p>has also been called a priori counterfactual (frangakis &amp; rubin, 2002)</p></li>
<li><p>when <span class="math notranslate nohighlight">\(t \neq t'\)</span>, this can‚Äôt be observed and can‚Äôt be falsified</p></li>
</ul>
</li>
<li><p><strong>total effect</strong> <span class="math notranslate nohighlight">\(\tau=E\{Y(1)-Y(0)\} = \textrm{NDE + NIE}\)</span></p>
<ul>
<li><p>assumes composition assumption <span class="math notranslate nohighlight">\(Y(1, M_1) = Y(1)\)</span>, very reasonable</p></li>
</ul>
</li>
<li><p><strong>natural direct effect</strong> <span class="math notranslate nohighlight">\(\mathrm{NDE}=E\left\{Y\left(1, M_{0}\right)-Y\left(0, M_{0}\right)\right\}\)</span></p>
<ul>
<li><p><strong>controlled direct effect</strong> <span class="math notranslate nohighlight">\(\mathrm{CDE}=E\left\{Y\left(1, m\right)-Y\left(0, m\right)\right\}\)</span> is simpler: sets mediator to some assumed value <span class="math notranslate nohighlight">\(m\)</span> rather than the actual value seen in the data <span class="math notranslate nohighlight">\(M_0\)</span></p></li>
<li><p>w/ composition: <span class="math notranslate nohighlight">\(=E\left\{Y\left(1, M_{0}\right)-Y\left(0\right)\right\}\)</span></p></li>
</ul>
</li>
<li><p><strong>natural indirect effect</strong> <span class="math notranslate nohighlight">\(\mathrm{NIE}=E\left\{Y\left(1, M_1\right)-Y\left(1, M_{0}\right)\right\}\)</span></p></li>
<li><p>w/ composition: <span class="math notranslate nohighlight">\(=E\left\{Y\left( 1 \right)-Y\left(1, M_0\right)\right\}\)</span></p></li>
<li><p><strong>mediation formula</strong></p>
<ul>
<li><p>can condition effects on <span class="math notranslate nohighlight">\(x\)</span></p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\operatorname{NDE}(x)=E\left\{Y\left(1, M_{0}\right)-Y\left(0, M_{0}\right) \mid X=x\right\}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\operatorname{NIE}(x)=E\left\{Y\left(1, M_{1}\right)-Y\left(1, M_{0}\right) \mid X=x\right\}\)</span></p></li>
</ul>
</li>
<li><p>estimators</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\widehat{NDE}(x) = E\left\{Y\left(t, M_{t^{\prime}}\right) \mid X=x\right\}=\sum_{m} E(Y \mid T=t, M=m, X=x) \operatorname{pr}\left(M=m \mid T=t^{\prime}, X=x\right)\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\widehat{NIE}(x) = E\left\{Y\left(t, M_{t^{\prime}}\right)\right\}=\sum_{x} E\left\{Y\left(t, M_{t^{\prime}}\right) \mid X=x\right\} P(X=x)\)</span></p></li>
</ul>
</li>
<li><p>estimators depend on 4 assumptions</p>
<ol class="simple">
<li><p>no treatment-outcome confounding: <span class="math notranslate nohighlight">\(T \perp Y(t, m) \mid X\)</span></p></li>
<li><p>no mediator-outcome confounding: <span class="math notranslate nohighlight">\(M \perp Y(t, m) \mid (X, T)\)</span></p></li>
<li><p>assumption 3: no treatment-mediator confounding: <span class="math notranslate nohighlight">\(T \perp M(t) \mid X\)</span></p></li>
<li><p>no cross-world independence between potential outcomes and potential mdediators: <span class="math notranslate nohighlight">\(Y(t, m) \perp M(z') \; \forall \; t, t', m\)</span></p></li>
</ol>
</li>
<li><p>assumption notes</p>
<ul>
<li><p>1 + 2 are equivalent to <span class="math notranslate nohighlight">\(T, M) \perp Y(t, m) \mid X\)</span></p></li>
<li><p>first three essentially assume that <span class="math notranslate nohighlight">\(T\)</span> and <span class="math notranslate nohighlight">\(M\)</span> are both randomized</p></li>
<li><p>1-3 are very strong but hold with squentially randomized treatment + mediator</p></li>
<li><p>4 cannot be verified</p></li>
</ul>
</li>
<li><p>baron-kenny method (assumes linear models): <img alt="baron_kenny" src="../../_images/baron_kenny.png" /></p></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="heterogenous-treatment-effects">
<h3>1.10.2.2. heterogenous treatment effects<a class="headerlink" href="#heterogenous-treatment-effects" title="Permalink to this headline">¬∂</a></h3>
<p><em>Heterogenous treatment effects refer to effects which differ for different subgroups / individuals in a population and requires more refined modeling.</em></p>
<ul class="simple">
<li><p><strong>conditional average treatment effect (CATE)</strong> - get treatment effect for each individual conditioned on its covariates <span class="math notranslate nohighlight">\(\mathbb E [y|x, t=1] - \mathbb E[y|x, t=0]\)</span> (different from ITE <span class="math notranslate nohighlight">\(Y^{T=1}_i - Y^{T=0}_i\)</span>)</p>
<ul>
<li><p>meta-learners - break down CATE into regression subproblems</p>
<ul>
<li><p>e.g. S-learner (hill 11) - ‚ÄúS‚Äù stands for ‚Äúsingle‚Äù and fits a single statistical model for <span class="math notranslate nohighlight">\(\mu_1 - \mu_0\)</span></p>
<ul>
<li><p>can be biased towards 0</p></li>
</ul>
</li>
<li><p>e.g. T-learner (foster et al. 2011) - ‚ÄúT‚Äù stands for ‚Äútwo‚Äù because we fit 2 models:  one model for conditional expectation of each potential outcome: <span class="math notranslate nohighlight">\(\hat \mu_1(x), \hat \mu_0(x)\)</span></p>
<ul>
<li><p>can have issues, e.g. different effects are regularized differently</p></li>
<li><p>doesn‚Äôt do well with variation in the propensity score. If <span class="math notranslate nohighlight">\(e(x)\)</span> varies considerably, then our estimates of <span class="math notranslate nohighlight">\(\hat \mu(0)\)</span> will be driven by data in areas with many control units (i.e., with <span class="math notranslate nohighlight">\(e(x)\)</span> closer to 0), and those of <span class="math notranslate nohighlight">\(\hat \mu (1)\)</span> by regions with more treated units (i.e., with e(x) closer to 1).</p></li>
</ul>
</li>
<li><p>e.g. X-learner (<a class="reference external" href="https://www.pnas.org/content/116/10/4156.short">kunzel et al. 19</a>) - ‚ÄúX‚Äù stands for crossing between estimates and conditional outcomes for each group</p>
<ul>
<li><p>first, fit <span class="math notranslate nohighlight">\(\hat \mu_1(x), \hat \mu_0(x)\)</span></p></li>
<li><p>second, compute effects using all the data <span class="math notranslate nohighlight">\(\begin{aligned} \hat{\tau}_{1, i} &amp;=Y_{i}(1)-\hat{\mu}_{0}\left(x_{i}\right) \\ \hat{\tau}_{0, i} &amp;=\hat{\mu}_{1}\left(x_{i}\right)-Y_{i}(0) \end{aligned}\)</span></p></li>
<li><p>finally, combine effects <span class="math notranslate nohighlight">\(\hat{\tau}(x)=g(x) \hat{\tau}_{0}(x)+(1-g(x)) \hat{\tau}_{1}(x)\)</span></p>
<ul>
<li><p><span class="math notranslate nohighlight">\(g(x)\)</span> is weighting function, e.g. estimated propensity score</p></li>
</ul>
</li>
</ul>
</li>
<li><p>e.g. R-learner (<a class="reference external" href="https://www.jstor.org/stable/1912705?casa_token=MIFpVeGtg_AAAAAA%3ASw_iZBgtJwx_P6jezFPxHXy8USBdJugzBzt5S9I2sc1j83K_dmYJmskt-l8cTxMBHffbZFTjPCO7KQzrPGkr4SyAAOID7engZqQrMLQy2fv2yQ-C0rs&amp;seq=1#metadata_info_tab_contents">robinson, 1988</a>; nie-wager, 20) - regularized semiparametric learner</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\hat{\tau}_{R}(\cdot)=\operatorname{argmin}_{\hat \tau}\left\{\frac{1}{n} \sum_{i=1}^{n}\left(\underbrace{Y_{i}-\hat \mu\left(X_{i}\right)}_{\text{Y residual}}-\left(T_{i}-\hat e\left(X_{i}\right)\right) \hat \tau\left(X_{i}\right)\right)^{2}\right. \left.+ \underbrace{\Lambda_{n}\left(\hat \tau(\cdot)\right)}_{\text{regularization}}\right\}\)</span></p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\hat \mu(x) = E[Y_i|X=x]\)</span></p></li>
<li><p>use cross-fitting to estimate <span class="math notranslate nohighlight">\(\hat \tau\)</span> and <span class="math notranslate nohighlight">\(\hat \mu\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\tau\)</span> takes a form, e.g. LASSO</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>tree-based methods</p>
<ul>
<li><p>e.g. causal tree (<a class="reference external" href="https://www.pnas.org/content/113/27/7353.short">athey &amp; imbens, 16</a>) - like decision tree, but change splitting criterion for differentiating 2 outcomes + compute effects for each leaf on out-of-sample data</p></li>
<li><p>e.g. causal forest (<a class="reference external" href="https://www.tandfonline.com/doi/full/10.1080/01621459.2017.1319839">wager &amp; athey, 18</a>) - extends causal tree to forest</p></li>
<li><p>e.g. BART (<a class="reference external" href="https://arxiv.org/abs/0806.3286">hill, 12</a>) - takes treatment as an extra input feature</p></li>
</ul>
</li>
<li><p>neural-net based methods</p>
<ul>
<li><p>e.g. TARNet (<a class="reference external" href="https://arxiv.org/abs/1606.03976">shalit et al. 2017</a>) - full notes below, use data from both groups</p></li>
</ul>
</li>
</ul>
</li>
<li><p>validation</p>
<ul>
<li><p>can cross-validate CATE on R-loss (sampling variability is high, but may not always be an issue (<a class="reference external" href="https://www.tandfonline.com/doi/full/10.1080/01621459.2020.1727235?casa_token=vqv0KlGeZcIAAAAA:l-UnVbnUT6r_klyrqTnjPnfrlE_XsywwRC08mOgBWtB_qeuSXsN2wXSKyGJP_pmYW_3Ucp1N4nLM">wager, 2020</a>))</p></li>
<li><p>indirect approach - use CATE to identify subgroups, and then use out-of-sample data to evaluate these subgroups</p></li>
<li><p>fit <span class="math notranslate nohighlight">\(\hat \tau\)</span> then rerun semiparametric model and see if coefficient for <span class="math notranslate nohighlight">\(\hat \tau\)</span> ends up close to 1</p></li>
<li><p>more discussion in (<a class="reference external" href="https://arxiv.org/abs/1902.07409">athey &amp; wager, 2019</a>) and (<a class="reference external" href="https://arxiv.org/abs/1712.04802">chernozhukov et al. 2017</a>)</p></li>
</ul>
</li>
<li><p><strong>subgroup analysis</strong> - identify subgroups with treatment effects far from the average</p>
<ul>
<li><p>generally easier than CATE</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/2008.10109.pdf">staDISC</a> (dwivedi, tan et al. 2020) - learn stable / interpretable subgroups for causal inference</p>
<ul>
<li><p>CATE - estimate with a bunch of different models</p>
<ul>
<li><p>meta-learners: T/X/R/S-learners</p></li>
<li><p>tree-based methods: causal tree/forest, BART</p></li>
<li><p><strong>calibration</strong> to evaluate subgroup CATEs</p>
<ul>
<li><p>main difficulty: hard to do model selection / validation (especially with imbalanced data)</p>
<ul>
<li><p>often use some kind of proxy loss function</p></li>
</ul>
</li>
<li><p>solution: compare average CATE within a bin to CATE on test data in bin</p>
<ul>
<li><p>actual CATE doesn‚Äôt seem to generalize</p></li>
<li><p>but ordering of groups seems pretty preserved</p></li>
</ul>
</li>
<li><p>stability: check stability of this with many CATE estimators</p></li>
</ul>
</li>
</ul>
</li>
<li><p>subgroup analysis</p>
<ul>
<li><p>use CATE as a stepping stone to finding subgroups</p></li>
<li><p>easier, but still linked to real downstream tasks (e.g. identify which subgroup to treat)</p></li>
<li><p>main difficulty: can quickly overfit</p></li>
<li><p><strong>cell-search</strong> - sequential</p>
<ul>
<li><p>first prune features using feature importance</p></li>
<li><p>target: maximize a cell‚Äôs true positive - false positive (subject to using as few features as possible)</p></li>
<li><p>sequentially find cell which maximizes target</p>
<ul>
<li><p>find all cells which perform close to as good as this cell</p></li>
<li><p>remove all cells contained in another cell</p></li>
<li><p>pick one randomly, remove all points in this cell, then continue</p></li>
</ul>
</li>
</ul>
</li>
<li><p>stability: rerun search multiple times and look for stable cells / stable cell coverage</p></li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1606.03976">Estimating individual treatment effect: generalization bounds and algorithms</a> (shalit, johansson, &amp; sontag, 2017)</p>
<ul>
<li><p>bound the ITE estimation error using (1) generalization err of the repr. and (2) the distance between the treated and control distrs., e.g. MMD</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="reinforcement-policy-learning">
<h3>1.10.2.3. reinforcement (policy) learning<a class="headerlink" href="#reinforcement-policy-learning" title="Permalink to this headline">¬∂</a></h3>
<ul class="simple">
<li><p>rather than estimating a treatment effect, find a policy that maximizes some expected utility (e.g. can define utility as the potential outcome <span class="math notranslate nohighlight">\(\mathbb E[Y_i(\pi(X_i))]\)</span>)</p></li>
<li><p>in this case, policy is like an intervention</p></li>
</ul>
</div>
<div class="section" id="causal-discovery">
<h3>1.10.2.4. causal discovery<a class="headerlink" href="#causal-discovery" title="Permalink to this headline">¬∂</a></h3>
<p><em>Causal discovery aims to identify causal relationships (sometimes under some smoothness / independence assumptions. This is often impossible in general. Also called causal relation learning, causal search.</em></p>
<ul class="simple">
<li><p>a lot of our science does not actually rest on experiments (e.g. physics, geology)</p>
<ul>
<li><p>hume (1739) - all we can observe is association, never actual counterfactuals or causes (‚Äúnecesary connexion‚Äù)</p></li>
<li><p>requires careful model selection</p></li>
<li><p>rvw: <a class="reference external" href="https://www.frontiersin.org/articles/10.3389/fgene.2019.00524/full">Review of Causal Discovery Methods Based on Graphical Models</a></p></li>
</ul>
</li>
<li><p><strong>constraint-based algorithms</strong> - use conditional indep. checks to determine graphs up to markov equivalence</p>
<ul>
<li><p><em>faithfulness</em> means the statistical dependence between variables estimated from the data does not violate the independence defined by any causal graph which generates the data</p></li>
<li><p>extensions to more general distrs., unobserved confounders</p></li>
<li><p><strong>peter-clark (PC) algorithm</strong> - first learns undirected graph, then detects edge directions and returns equivalence class</p>
<ul>
<li><p>assumes that there is no confounder (unobserved direct common cause of two measured variables)</p></li>
</ul>
</li>
<li><p>fast causal inference (FCI) (spirtes et al. 200)</p>
<ul>
<li><p>can deal with confounders - instead of edge/no edge have 3 possibilities: edge, no edge, confounding by unobserved missing common cause (+possibly another possibility for ‚Äúunknown‚Äù)</p></li>
</ul>
</li>
</ul>
</li>
<li><p><strong>score-based algorithms</strong> - replace conditional indep. tests with godness of fit tests (e.g. BIC)</p>
<ul>
<li><p>assume there are no confounders</p></li>
<li><p>still can only determine graphs up to markov equivalence</p></li>
<li><p>optimizing goodness of fit is NP-hard, so often use heuristics such as greedy equivalence search (GES) (<a class="reference external" href="https://www.jmlr.org/papers/v3/chickering02b.html">chickering, 2002</a>)</p></li>
</ul>
</li>
<li><p><strong>functional causal models</strong> - assume a variable can be written as a function of its direct causes and some noise term</p>
<ul>
<li><p>can distinguish between different DAGs in same equivalence class</p></li>
<li><p>e.g. (hyavarinen &amp; zhang, 2016) assume additive noise and that <span class="math notranslate nohighlight">\(p(E|C)\)</span> can be modeled while <span class="math notranslate nohighlight">\(P(C|E)\)</span> cannot</p></li>
<li><p>e.g. LiNGAM (Shimizu et al., 2006), ICA-LINGAM - linear relations between different variables and noise</p></li>
<li><p>additive noise models ANM (Hoyer et al., 2009) relax the linear restriction</p>
<ul>
<li><p>ANM-MM (Hu et al., 2018)</p></li>
</ul>
</li>
<li><p>post-nonlinear models PNL (Zhang and Hyvarinen, 2009) expand the functional space with non-linear relations between the variables and the noise</p></li>
</ul>
</li>
<li><p>many models assume the generating cause distribution <span class="math notranslate nohighlight">\(p(C)\)</span> is in some sense ‚Äúindependent‚Äù to the mechanism <span class="math notranslate nohighlight">\(P(E|C)\)</span></p>
<ul>
<li><p>e.g. IGCI (Janzing et al., 2012) uses orthogonality in information space to express the independence between the two distributions</p></li>
<li><p>e.g. KCDC (Mitrovic et al., 2018) uses  invariance of Kolmogorov complexity of conditional distribution</p></li>
<li><p>e.g. RECI (Blobaum et al., 2018) extends IGCI to the setting with small noise, and proceeds by comparing the regression errors in both possible directions</p></li>
</ul>
</li>
<li><p>check variables which reduce entropy the most</p>
<ul>
<li><p><a class="reference external" href="https://link.springer.com/article/10.1007/s10115-017-1130-5">Origo : causal inference by compression</a> (budhathoki &amp; vreekan, 2017) - similar intuition as ICM: causal directions are more easily compressible</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://proceedings.neurips.cc/paper/2018/hash/78631a4bb5303be54fa1cfdcb958c00a-Abstract.html">Learning and Testing Causal Models with Interventions</a> (acharya et al. 2018)</p>
<ul>
<li><p>given DAG, want to learn distribution on interventions with minimum number of interventions, variables intevened on, numper of samples draw per intervention</p></li>
</ul>
</li>
<li><p><a class="reference external" href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Lopez-Paz_Discovering_Causal_Signals_CVPR_2017_paper.pdf">Discovering Causal Signals in Images</a> (lopez-paz et al. 2017)</p>
<ul>
<li><p>C(A, B) - count number of images in which B would disappear if A was removed</p></li>
<li><p>we say A <em>causes</em> B when C(A, B) is (sufficiently) greater than the converse C(B, A)</p></li>
<li><p>basics</p>
<ul>
<li><p>given joint distr. of (A, B), we want to know if A -&gt; B, B-&gt; A</p>
<ul>
<li><p>with no assumptions, this is nonidentifiable</p></li>
</ul>
</li>
<li><p>requires 2 assumptions</p>
<ul>
<li><p>ICM: independence between cause and mechanism (i.e. the function doesn‚Äôt change based on distr. of X) - this usually gets violated in anticausal direction</p></li>
<li><p>causal sufficiency - we aren‚Äôt missing any vars</p></li>
</ul>
</li>
<li><p>ex. <img alt="Screen Shot 2019-05-20 at 10.04.03 PM" src="../../_images/learning_causal_pattern.png" /></p>
<ul>
<li><p>here noise is indep. from x (causal direction), but can‚Äôt be independent from y (non-causal direction)</p></li>
<li><p>in (c), function changes based on input</p></li>
</ul>
</li>
<li><p>can turn this into binary classification and learn w/ network: given X, Y, does X-&gt;Y or Y-X?</p></li>
</ul>
</li>
<li><p>on images, they get scores for different objects (w/ bounding boxes)</p>
<ul>
<li><p>eval - when one thing is erased, does the other also get erased?</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://www.technologyreview.com/s/613502/deep-learning-could-reveal-why-the-world-works-the-way-it-does/?fbclid=IwAR3LF2dc_3EvWXzEHhtrsqtH9Vs-4pjPALfuqKCOma9_gqLXMKDeCWrcdrQ">link to iclr talk</a> (bottou 2019)</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1412.2309">Visual Causal Feature Learning</a> (chalupka, perona, &amp; eberhardt, 2015)</p>
<ul>
<li><p>assume the behavior <span class="math notranslate nohighlight">\(T\)</span> is a function of some hidden causes <span class="math notranslate nohighlight">\(H_i\)</span> and the image</p>
<ul>
<li><p><img alt="Screen Shot 2020-02-03 at 2.27.27 PM" src="../../_images/hidden_graphical_node.png" /></p></li>
</ul>
</li>
<li><p><strong>Causal Coarsening Theorem</strong> - causal partition is coarser version of the observational partition</p>
<ul>
<li><p>observational partition - divide images into partition where each partition has constant prediction <span class="math notranslate nohighlight">\(P(T|I)\)</span></p></li>
<li><p>causal partition - divide images into partition where each partition has constant <span class="math notranslate nohighlight">\(P(T|man(I))\)</span></p>
<ul>
<li><p><span class="math notranslate nohighlight">\(man(I)\)</span> does visual manipulation which changes <span class="math notranslate nohighlight">\(I\)</span>, while keeping all <span class="math notranslate nohighlight">\(H_i\)</span> fixed and <span class="math notranslate nohighlight">\(T\)</span> fixed</p>
<ul>
<li><p>ex. turn a digit into a 7 (or turn a 7 into not a 7)</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>can further simplify the problem into <span class="math notranslate nohighlight">\(P(T|I) = P(T|C, S)\)</span></p>
<ul>
<li><p><span class="math notranslate nohighlight">\(C\)</span> are the causes and <span class="math notranslate nohighlight">\(S\)</span> are the spurious correlates</p></li>
<li><p>any other variable <span class="math notranslate nohighlight">\(X\)</span> such that <span class="math notranslate nohighlight">\(P(T|I) = P(T|X)\)</span> has Shannon entropy <span class="math notranslate nohighlight">\(H(X) \geq H(C, S)\)</span> - these are the simplest descriptions of <span class="math notranslate nohighlight">\(P(T|I\)</span>)</p></li>
</ul>
</li>
<li><p>causal effect prediction</p>
<ul>
<li><p>first, create causal dataset of <span class="math notranslate nohighlight">\(P(T|man(I))\)</span> and train, so the model can‚Äôt learn spurious correlations</p></li>
<li><p>then train on this - very similar to adversarial training</p></li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1911.11893">Visual Physics: Discovering Physical Laws from Videos</a></p>
<ul>
<li><p>3 steps</p>
<ul>
<li><p>Mask R-CNN finds bounding box of object and center of bounding box is taken to be location</p></li>
<li><p><span class="math notranslate nohighlight">\(\beta-VAE\)</span> compresses the trajectory to some latent repr. (while also being able to predict held-out points of the trajectory)</p></li>
<li><p><strong>Eureqa</strong> package does eq. discovery on latent repr + trajectory</p>
<ul>
<li><p>includes all basic operations, such as addition, mult., sine function</p></li>
<li><p>R-squared value measures goodness of fit</p></li>
</ul>
</li>
</ul>
</li>
<li><p>see also SciNet -  <a class="reference external" href="https://arxiv.org/abs/1807.10300">Discovering physical concepts with neural networks</a> (iten et al. 2020)</p></li>
<li><p>see also the field of symbolic regression</p>
<ul>
<li><p>genetic programming is the most pervalent method here</p></li>
<li><p>alternatives: sparse regression, dimensional function synthesis</p></li>
</ul>
</li>
</ul>
</li>
<li><p>Causal Mosaic: Cause-Effect Inference via Nonlinear ICA and Ensemble Method (<a class="reference external" href="https://arxiv.org/abs/2001.01894">wu &amp; fukumizu, 2020</a>)</p>
<ul>
<li><p>focus on bivariate case</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="stable-invariant-predictors">
<h3>1.10.2.5. stable/invariant predictors<a class="headerlink" href="#stable-invariant-predictors" title="Permalink to this headline">¬∂</a></h3>
<p><em>Under certain assumptions, invariance to data perturbations (i.e. interventions) can help us identify causal effects.</em></p>
<div class="section" id="invariance-hierarchies">
<h4>1.10.2.5.1. invariance hierarchies<a class="headerlink" href="#invariance-hierarchies" title="Permalink to this headline">¬∂</a></h4>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/abs/1905.11374">The Hierarchy of Stable Distributions and Operators to Trade Off Stability and Performance</a> (subbaswamy, chen, &amp; saria 2019)</p>
<ul>
<li><p>different predictors learn different things</p></li>
<li><p>only pick the stable parts of what they learn (in a graph representation)</p></li>
<li><p>there is a tradeoff between stability to all shifts and average performance on the shifts we expect to see</p></li>
<li><p>different types of methods</p>
<ul>
<li><p><em>transfer learning</em> - given unlabelled test data, match training/testing representations</p></li>
<li><p><em>proactive methods</em> - make assumptions about possible set of target distrs.</p></li>
<li><p><em>data-driven methods</em> - assume independence of cause and mechanism, like ICP, and use data from different shifts to find invariant subsets</p></li>
<li><p><em>explicit graph methods</em> - assume explicit knowledge of graph representing the data-generating process</p></li>
</ul>
</li>
<li><p>hierarchy</p>
<ul>
<li><p>level 1 - invariant conditional distrs. of the form <span class="math notranslate nohighlight">\(P(Y|\mathbf Z)\)</span></p></li>
<li><p>level 2 - conditional interventional distrs. of the form <span class="math notranslate nohighlight">\(P(Y|do(\mathbf W), \mathbf Z)\)</span></p></li>
<li><p>level 3 - distributions corresponding to counterfactuals</p></li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1911.10500">Causality for Machine Learning</a> (scholkopf 19)</p>
<ul>
<li><p>most of ml is built on the iid assumption and fails when it is violated (e.g. cow on a beach)</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="invariance-algorithms">
<h4>1.10.2.5.2. invariance algorithms<a class="headerlink" href="#invariance-algorithms" title="Permalink to this headline">¬∂</a></h4>
<ul class="simple">
<li><p>algorithms overview (see papers for more details) + <a class="reference external" href="https://github.com/facebookresearch/InvarianceUnitTests">implementations</a></p>
<ul>
<li><p><em>ICP</em> - invariant causal prediction - find feature set where, after conditioning, loss is the same for all environments</p>
<ul>
<li><p>fails when distr. of residuals varies across environments</p></li>
</ul>
</li>
<li><p><em>IRM</em> - invariant risk minimization (v1) - find a feature repr. such that the optimal classifier, on top of that repr., is the identity function for all environments</p></li>
<li><p><em>GroupDRO</em> - distributionally robust optimization (e.g. encourage strict equality between err of each group)</p></li>
<li><p><em>ERM</em> - empirical risk minimization - minimize total training err</p></li>
<li><p><em>domain-adversarial techniques</em>: find a repr. which does not differ across environments, then predict</p>
<ul>
<li><p>fails when distr. of causes changes across environments</p></li>
</ul>
</li>
<li><p><em>AND-mask</em> - minimize the err only in directions where the sign of the gradient of the loss is the same for most environments</p></li>
<li><p><span class="xref myst">IGA</span> - inter-environmental gradient alignment - ERM + reduce variance of the gradient of the loss per environment: <span class="math notranslate nohighlight">\(\lambda \operatorname{trace}\left(\operatorname{Var}\left(\nabla_{\theta} L_{\mathcal{E}}(\theta)\right)\right)\)</span></p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1812.08233">Invariance, Causality and Robustness</a> - ICP (buhlmann 18)</p>
<ul>
<li><p>predict <span class="math notranslate nohighlight">\(Y^e\)</span> given <span class="math notranslate nohighlight">\(X^e\)</span> such that the prediction ‚Äúworks well‚Äù or is ‚Äúrobust‚Äù for all <span class="math notranslate nohighlight">\(e ‚àà \mathcal F\)</span> based on data from much fewer environments <span class="math notranslate nohighlight">\(e \in \mathcal E\)</span></p>
<ul>
<li><p><strong>key assumption (<em>invariance</em>)</strong>: there exists a subset of ‚Äúcausal‚Äù covariates - when conditioning on these covariates, the loss is the same across all environments <span class="math notranslate nohighlight">\(e\)</span></p></li>
<li><p>assumption: ideally <span class="math notranslate nohighlight">\(e\)</span> changes only the distr. of <span class="math notranslate nohighlight">\(X^e\)</span> (so doesn‚Äôt act directly on <span class="math notranslate nohighlight">\(Y^e\)</span> or change the mechanism between <span class="math notranslate nohighlight">\(X^e\)</span> and <span class="math notranslate nohighlight">\(Y^e\)</span>)</p></li>
<li><p>when these assumptions are satisfied, then minimizing a worst-case risk over environments <span class="math notranslate nohighlight">\(e\)</span> yields a causal parameter</p></li>
</ul>
</li>
<li><p>identifiability issue: we typically can‚Äôt identify the causal variables without very many perturbations <span class="math notranslate nohighlight">\(e\)</span></p>
<ul>
<li><p><strong>Invariant Causal Prediction (ICP)</strong> only identifies variables as causal if they appear in all invariant sets (see also <a class="reference external" href="https://arxiv.org/abs/1501.01332">Peters, Buhlmann, &amp; Meinshausen, 2015</a>)</p></li>
<li><p>brute-force feature selection</p></li>
</ul>
</li>
<li><p>anchor regression model helps to relax assumptions</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1907.02893">Invariant Risk Minimization</a> - IRM (arjovsky, bottou, gulrajani, &amp; lopez-paz 2019)</p>
<ul>
<li><p>idealized formulation: <span class="math notranslate nohighlight">\(\begin{array}{ll}\min _{\Phi: \mathcal{X} \rightarrow \mathcal{H}} &amp; \sum_{e \in \mathcal{E}_{\mathrm{tr}}} R^{e}(w \circ \Phi) \\ \text { subject to } &amp; w \in \underset{\bar{w}: \mathcal{H} \rightarrow \mathcal{Y}}{\arg \min  } \: R^{e}(\bar{w} \circ \Phi), \text { for all } e \in \mathcal{E}_{\mathrm{tr}}\end{array}\)</span></p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\Phi\)</span> is repr., <span class="math notranslate nohighlight">\(w \circ \Phi\)</span> is predictor</p></li>
</ul>
</li>
<li><p>practical formulation: <span class="math notranslate nohighlight">\(\min _{\Phi: \mathcal{X} \rightarrow \mathcal{Y}} \sum_{e \in \mathcal{E}_{\mathrm{tr}}} R^{e}(\Phi)+\lambda \cdot\left\|\nabla_{w \mid w=1.0} R^{e}(w \cdot \Phi)\right\|^{2}\)</span></p></li>
<li><p>random splitting causes problems with our data</p></li>
<li><p>what to perform well under different distributions of X, Y</p></li>
<li><p>can‚Äôt be solved via robust optimization</p></li>
<li><p>a correlation is spurious when we do not expect it to hold in the future in the same manner as it held in the past</p>
<ul>
<li><p>i.e. spurious correlations are unstable</p></li>
</ul>
</li>
<li><p>assume we have infinite data, and know what kinds of changes our distribution for the problem might have (e.g. variance of features might change)</p>
<ul>
<li><p>make a model which has the minimum test error regardless of the distribution of the problem</p></li>
</ul>
</li>
<li><p>adds a penalty inspired by invariance (which can be viewed as a stability criterion)</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2009.00329">Learning explanations that are hard to vary</a> - AND-mask (parascandolo‚Ä¶sholkopf, 2020)</p>
<ul>
<li><p>basically, gradients should be consistent during learning</p>
<ul>
<li><p>after learning, they should be consistent within some epsilon ball</p></li>
</ul>
</li>
<li><p>practical algorithm: AND-mask</p>
<ul>
<li><p>like zeroing out those gradient components with respect to weights that have <em>inconsistent signs</em> across environments</p>
<ul>
<li><p>basically same complexity as normal GD</p></li>
</ul>
</li>
<li><p>previous works used cosine similarity between weights in different settings</p></li>
<li><p>experiments</p>
<ul>
<li><p>real data is spiral but each env is linearly separable - still able to learn spiral</p></li>
<li><p>cifar - with real labels, performance unaffected; with random labels, training acc drops significantly</p>
<ul>
<li><p>each example is its own environment</p></li>
<li><p>with noisy labels, imposes good regularization</p></li>
</ul>
</li>
<li><p>rl - works well on coinrun</p></li>
</ul>
</li>
</ul>
</li>
<li><p>propose <strong>invariant learning consistency</strong> (ILC)- measures expected consistency of the soln found by an algorithm given a hypothesis class</p>
<ul>
<li><p>consistency - what extent a minimum of the loss surface appears <strong>only when data from different envs</strong> are pooled</p></li>
</ul>
</li>
<li><p>given algorithm <span class="math notranslate nohighlight">\(\mathcal A\)</span>, maximize this: <span class="math notranslate nohighlight">\(\mathrm{ILC}\left(\mathcal{A}, p_{\theta^{0}}\right):= \underbrace{-\mathbb{E}_{\theta^{0} \sim p\left(\theta^{0}\right)}}_{\text{expectation over reinits}}\left[\mathcal{I}^{\epsilon} (\underbrace{\mathcal{A}_{\infty}(\theta^{0}, \mathcal{E}}_{\hat \theta}) \right]\)</span></p>
<ul>
<li><p><strong>inconsistency score</strong> for a solution <span class="math notranslate nohighlight">\(\hat \theta\)</span> given environments <span class="math notranslate nohighlight">\(e\)</span>: <span class="math notranslate nohighlight">\(\mathcal{I}^{\epsilon}(\hat \theta):=\overbrace{\max _{\left(e, e^{\prime}\right) \in \mathcal{E}^{2}} }^{\text{env. pairs}} \underbrace{\max _{\theta \in N_{e, \hat \theta}^{\epsilon}}}_{\text{low-loss region around \)</span>\hat \theta<span class="math notranslate nohighlight">\(}} \overbrace{\mid \mathcal{L}_{e^{\prime}}(\theta)-\mathcal{L}_{e}(\theta)|}^{\text{loss between envs.}}\)</span></p>
<ul>
<li><p><span class="math notranslate nohighlight">\(N_{e, \hat \theta}^{\epsilon}\)</span> is path-connected region around <span class="math notranslate nohighlight">\(\hat \theta\)</span> where <span class="math notranslate nohighlight">\(\left\{\theta \in \Theta\right.\)</span> s.t. <span class="math notranslate nohighlight">\(\left|\mathcal{L}_{e}(\theta)-\mathcal{L}_{e}\left(\hat \theta\right)\right| \leqslant \epsilon\)</span></p></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2002.04692">Invariant Risk Minimization Games</a> (ahuja et al. 2020) - pose IRM as finding the Nash equilibrium of an ensemble game among several environments</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2003.09772">Invariant Rationalization</a> (chang et al. 2020) - identify a small subset of input features ‚Äì the rationale ‚Äì that best explains or supports the prediction</p>
<ul>
<li><p>key assumption: <span class="math notranslate nohighlight">\(Y \perp E | Z\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\max _{\boldsymbol{m} \in \mathcal{S}} I(Y ; \boldsymbol{Z}) \quad\)</span> s.t. <span class="math notranslate nohighlight">\(\boldsymbol{Z}= \overbrace{\boldsymbol{m}}^{\text{binary mask}} \odot \boldsymbol{X}, \quad \underbrace{Y \perp E \mid \boldsymbol{Z}}_{\text{this part is invariance}}\)</span></p>
<ul>
<li><p>solve this via 3 nets with adv. penalty to approximate invariance</p></li>
<li><p>standard maximum mutual info objective is just <span class="math notranslate nohighlight">\(\max _{\boldsymbol{m} \in \mathcal{S}} I(Y ; \boldsymbol{Z}) \quad\)</span> s.t. <span class="math notranslate nohighlight">\(\boldsymbol{Z}= \overbrace{\boldsymbol{m}}^{\text{binary mask}} \odot \boldsymbol{X}\)</span> (see <a class="reference external" href="https://arxiv.org/abs/1606.04155">lei et al. 2016</a>)</p></li>
<li><p>ex. <span class="math notranslate nohighlight">\(X\)</span> is text reviews for beer, <span class="math notranslate nohighlight">\(Y\)</span> is aroma, <span class="math notranslate nohighlight">\(E\)</span> could be beer brand</p></li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference external" href="https://www.cmu.edu/dietrich/causality/CameraReadys-accepted%20papers/32%5CCameraReady%5Cdatasets.pdf">Linear unit-tests for invariance discovery</a>  (aubin et al. 2020) - a set of 6 simple settings where current IRM procedures fail</p>
<ul>
<li><p>test 1 (colormnist-style linear regr): <span class="math notranslate nohighlight">\(x_{inv}  \to \tilde y \to x_{spu}\)</span></p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\tilde y \to y\)</span></p></li>
</ul>
</li>
<li><p>test 2 (cows vs camels binary classification): <span class="math notranslate nohighlight">\(y=mean(x_{inv})&gt;0\)</span>, but <span class="math notranslate nohighlight">\(x_{inv} \propto x_{spu}\)</span></p></li>
<li><p>test 3 (small invariant margin): <span class="math notranslate nohighlight">\(y_i\sim Bern(1/2)\)</span>, <span class="math notranslate nohighlight">\(x_{inv} = \pm 0.1+\)</span>noise, <span class="math notranslate nohighlight">\(x_{spu} = \pm \mu^e\)</span> + noise, where <span class="math notranslate nohighlight">\(\mu^e ~ N(0, 1)\)</span></p></li>
<li><p>scrambling: apply random rotation matrix to inputs</p></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="misc-problems">
<h3>1.10.2.6. misc problems<a class="headerlink" href="#misc-problems" title="Permalink to this headline">¬∂</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/abs/1907.13258">Incremental causal effects</a> (rothenhausler &amp; yu, 2019)</p>
<ul>
<li><p>instead of considering a treatment, consider an infinitesimal change in a continuous treatment</p></li>
<li><p>use assumption of local independence and can prove some nice things</p>
<ul>
<li><p>local ignorability assumption states that potential outcomes are independent of the current treatment assignment in a neighborhood of observations</p></li>
</ul>
</li>
</ul>
</li>
<li><p><strong>probability of necessity</strong> <span class="math notranslate nohighlight">\(PN(t, y) = P(Y^{T=t'}=y'|T=t, Y=y)\)</span> = ‚Äúprobability of causation‚Äù (Robins &amp; Greenland, 1989)</p>
<ul>
<li><p>find the probability that <span class="math notranslate nohighlight">\(Y\)</span> would be <span class="math notranslate nohighlight">\(y‚Ä≤\)</span> had <span class="math notranslate nohighlight">\(T\)</span> been <span class="math notranslate nohighlight">\(t'\)</span>, given that, in reality, <span class="math notranslate nohighlight">\(Y\)</span> is actually <span class="math notranslate nohighlight">\(y\)</span> and <span class="math notranslate nohighlight">\(T\)</span> is <span class="math notranslate nohighlight">\(t\)</span></p></li>
<li><p>If <span class="math notranslate nohighlight">\(Y\)</span> is monotonic relative to <span class="math notranslate nohighlight">\(T\)</span> <span class="math notranslate nohighlight">\(i.e ., Y^{T=1}(x) \geq Y^{T=0}(x),\)</span> then <span class="math notranslate nohighlight">\(\mathrm{PN}\)</span> is identifiable whenever the causal effect <span class="math notranslate nohighlight">\(P(y \mid d o(t))\)</span> is identifiable and, moreover,
$<span class="math notranslate nohighlight">\(
\mathrm{PN}=\underbrace{\frac{P(y \mid t)-P\left(y \mid t^{\prime}\right)}{P(y \mid t)}}_{\text{excess risk ratio}}+\underbrace{\frac{P\left(y \mid t^{\prime}\right)-P\left(y \mid d o\left(t^{\prime}\right)\right)}{P(t, y)}}_{\text{confounding adjustment}}
\)</span>$</p></li>
</ul>
</li>
<li><p><strong>causal transportability</strong> - seeks to identify conditions under which causal knowledge learned from experiments can be reused in different domains with observational data only</p></li>
<li><p><a class="reference external" href="https://ftp.cs.ucla.edu/pub/stat_ser/r502.pdf">Radical Empiricism and Machine Learning Research</a> (pearl 2021)</p>
<ul>
<li><p>contrast the ‚Äúdata fitting‚Äù vs. ‚Äúdata interpreting‚Äù approaches to data-science</p></li>
<li><p>current research is too empiricist (data-fitting based) - should include man-made models of how data are generated</p></li>
<li><p>3 reasons: expediency, transparency, explainability</p>
<ul>
<li><p>expediency: we often have to ask fast (e.g. covid) and use our knowledge to guide future experiments</p></li>
<li><p>transparency: need repr.d with right level off abstraction</p></li>
<li><p>explainability: humans must understand inferences</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="transferring-out-of-sample">
<h3>1.10.2.7. transferring out-of-sample<a class="headerlink" href="#transferring-out-of-sample" title="Permalink to this headline">¬∂</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://naokiegami.com/paper/external_full.pdf">Elements of External Validity: Framework, Design, and Analysis</a></p>
<ul>
<li><p>external validity - when do results from an RCT generalize to new settings?</p></li>
<li><p>X-, T-, Y -, and C-validity (units, treatments, outcomes, and contexts)</p></li>
<li><p>two goals: effect-generalization + sign-generalization</p></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="different-assumptions-experimental-designs">
<h2>1.10.3. different assumptions / experimental designs<a class="headerlink" href="#different-assumptions-experimental-designs" title="Permalink to this headline">¬∂</a></h2>
<ul class="simple">
<li><p>unconfoundedness <span class="math notranslate nohighlight">\(T_i \perp (Y_i(0), Y_i(1)) | X_i\)</span> is strong</p>
<ul>
<li><p>sometimes we may perfer <span class="math notranslate nohighlight">\(T_i \perp (Y_i(0), Y_i(1)) | X_i, Z_i\)</span> for some unobserved <span class="math notranslate nohighlight">\(Z_i\)</span> that we need to figure out</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1805.06826">The Blessings of Multiple Causes</a> (wang &amp; blei, 2019) - having multiple causes can help construct / find all the confounders</p>
<ul>
<li><p><strong>deconfounder algorithm</strong></p>
<ul>
<li><p>fit a factor model of causes</p></li>
<li><p>estimate a repr <span class="math notranslate nohighlight">\(Z_i\)</span> of data point <span class="math notranslate nohighlight">\(A_i\)</span> - <span class="math notranslate nohighlight">\(Z_i\)</span> renders the causes conditionally independent</p></li>
<li><p>now, <span class="math notranslate nohighlight">\(Z_i\)</span> is a substitute for unobserved confounders</p></li>
</ul>
</li>
<li><p>assumptions</p>
<ul>
<li><p>no causal arrows among causes <span class="math notranslate nohighlight">\(A_i\)</span></p></li>
<li><p>no unobserved single-cause confounders: any missing confounder affects multiple observed variables</p>
<ul>
<li><p>‚Äì&gt; can check the fit of the factor model, but won‚Äôt check perfectly</p></li>
</ul>
</li>
<li><p>the substitute confounder: there is enough information in the data to learn the variable <span class="math notranslate nohighlight">\(Z\)</span> which renders causes conditionally independent</p>
<ul>
<li><p>strong assumption!</p></li>
</ul>
</li>
</ul>
</li>
<li><p>thm</p>
<ul>
<li><p>with observed covariates X, weak unconfoundedness: <span class="math notranslate nohighlight">\(A_1, ...A_m \perp Y(a) | Z, X\)</span> (i.e. <span class="math notranslate nohighlight">\(Z\)</span> contains all multi-cause confounders, <span class="math notranslate nohighlight">\(X\)</span> contains all single-cause confounders)</p></li>
</ul>
</li>
<li><p>replaces an uncheckable search for possible confounders with the checkable goal of building a good factor model of observed casts.</p></li>
<li><p>controversial whether this works in general</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2003.04948">Towards Clarifying the Theory of the Deconfounder</a> (wang &amp; blei, 2020)</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1902.10286">On Multi-Cause Causal Inference with Unobserved Confounding: Counterexamples, Impossibility, and Alternatives</a> (d‚Äôamour 2019)</p></li>
</ul>
</li>
</ul>
<div class="section" id="synthetic-control-interventions">
<h3>1.10.3.1. synthetic control/interventions<a class="headerlink" href="#synthetic-control-interventions" title="Permalink to this headline">¬∂</a></h3>
<ul class="simple">
<li><p>synthetic control</p>
<ul>
<li><p>Using Synthetic Controls rvw paper (<a class="reference external" href="https://economics.mit.edu/files/17847">abadie 2020</a>)</p>
<ul>
<li><p>setting: treatment occurs at time t0 on multiple units (e.g. policy in california)</p></li>
<li><p>goal: estimate effect of treatment (e.g. effect of policy in california)</p></li>
<li><p>approach: impute counterfactual (california time-series without policy) by weighted combination on observed outcomes for other observations (e.g. average other ‚Äúsimilar‚Äù states)</p>
<ul>
<li><p>per-observation weights are learned during pre-intervention period with cross-validation procedure</p>
<ul>
<li><p>per-feature weights are also learned (bc matching on some features is more important than others)</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>The Economic Costs of Conflict: A Case Study of the Basque Country (<a class="reference external" href="https://economics.mit.edu/files/11870">Abadie &amp; G, 2003</a>)</p></li>
<li><p>Synthetic Control Methods for Comparative Case Studies: Estimating the Effect of California‚Äôs Tobacco Control Program (<a class="reference external" href="https://economics.mit.edu/files/11859">abadie et al. 2010</a>)</p></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="solutions-to-basic-problems">
<h2>1.10.4. solutions to basic problems<a class="headerlink" href="#solutions-to-basic-problems" title="Permalink to this headline">¬∂</a></h2>
<div class="section" id="learning-causal-representations">
<h3>1.10.4.1. learning ‚Äúcausal representations‚Äù<a class="headerlink" href="#learning-causal-representations" title="Permalink to this headline">¬∂</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/abs/1605.03661">Learning Representations for Counterfactual Inference</a> (johansson et al. 2016)</p>
<ul>
<li><p><img alt="learning_causal_repr" src="../../_images/learning_causal_repr.png" /></p></li>
<li><p>assumption similar to ignorability: the treatment assignment information (and any info which predicts it) should not influence the ITE: <span class="math notranslate nohighlight">\(T \perp \!\!\! \perp \{ Y^{T=1}, Y^{T=0}\} | X\)</span></p>
<ul>
<li><p>often not the case, e.g. medical symptoms lead doctors to give a treatment more</p></li>
<li><p>in this case, we will lose info that can help us predict the CATE</p></li>
</ul>
</li>
<li><p>also an extra loss: penalty that encourages counterfactual preds to be close to nearest observed outcome from the same set</p></li>
<li><p>fit linear ridge regression on top of representation <span class="math notranslate nohighlight">\(\phi\)</span></p></li>
<li><p>not exactly the same as the setting in <a class="reference external" href="http://www.cs.toronto.edu/~zemel/documents/fair-icml-final.pdf">fair repr. learning</a> or <a class="reference external" href="https://www.jmlr.org/papers/volume17/15-239/15-239.pdf">domain adversarial training</a> - MMD or Wasserstein distance instead of classification</p></li>
<li><p>same idea present in <a class="reference external" href="https://www.nature.com/articles/s41467-020-19784-9">Training confounder-free deep learning models for medical applications</a> (zhou et al. 2020)</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1606.03976">Estimating individual treatment effect: generalization bounds and algorithms</a> (shalit et al. 2017)</p>
<ul>
<li><p><img alt="ite_dnn" src="../../_images/ite_dnn.png" /></p></li>
<li><p>bound for estimating ITE <span class="math notranslate nohighlight">\(\tau(x)\)</span> is uper bounded by error for learning <span class="math notranslate nohighlight">\(Y_1\)</span> and <span class="math notranslate nohighlight">\(Y_0\)</span> plus a term for the  Integral Probability Metric (IPM)</p></li>
<li><p>IPM measures distance between <span class="math notranslate nohighlight">\(p(x|T = 0)\)</span> and <span class="math notranslate nohighlight">\(P(x|T = 1)\)</span>, and requires that they overlap at <span class="math notranslate nohighlight">\(x\)</span></p></li>
<li><p>In his foundational text about causality, Pearl (2009) writes: ‚ÄúWhereas in traditional learning tasks we attempt to generalize from one set of insteances to another, the causal modeling task is to generalize from behavior under one set of conditions to behavior under another set. <em>Causal models should therefore be chosen by a criterion that challenges their stability against changing conditions..</em>.‚Äù</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1802.08598">Learning Weighted Representations for Generalization Across Designs</a> (johansson et al. 2018)</p>
<ul>
<li><p><img alt="weighted_causal_repr" src="../../_images/weighted_causal_repr.png" /></p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2010.12618">Counterfactual Representation Learning with Balancing Weights</a> (assaad et al. 2020)</p>
<ul>
<li><p>combine balancing weights with representation learning: Balancing Weights Counterfactual Regression (BWCFR)</p>
<ul>
<li><p>representation learning has trade-off between balance and predictive power (<a class="reference external" href="https://arxiv.org/abs/2001.04754">zhang, bellot, &amp; van der Schaar, 2020</a>)</p></li>
<li><p>weights are from propensity scores, unlike johansson et al. 2018</p></li>
<li><p>intuition: upweight regions with good overlap</p></li>
</ul>
</li>
<li><p>bounds on degree of imbalance as a function of propensity model</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1705.08821">Causal Effect Inference with Deep Latent-Variable Models</a> (louizos et al. 2017) - like vae but learn latent distr. that also changes based on treatment</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2011.12379">Invariant Representation Learning for Treatment Effect Estimation</a> (shi, veitch, &amp; blei, 2020)</p>
<ul>
<li><p>Nearly Invariant Causal Estimation - uses IRM to learn repr. that strips out bad controls but preserves sufficient information to adjust for confounding</p>
<ul>
<li><p>observe data from multiple environments</p></li>
<li><p>covariates contain some causal variables</p></li>
<li><p>covariates also contain some false confounders</p></li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1802.05664">DeepMatch: Balancing Deep Covariate Representations for Causal Inference Using Adversarial Training</a> (kallus, 2018)</p>
<ul>
<li><p>weighting and a discriminator network compete adversarially to minimize ‚Äúdiscriminative discrepancy metric‚Äù for measuring covariate balance</p></li>
<li><p>this metric goes beyond just the original feature space</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="limitations">
<h3>1.10.4.2. limitations<a class="headerlink" href="#limitations" title="Permalink to this headline">¬∂</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="http://proceedings.mlr.press/v80/alaa18a.html">Limits of Estimating Heterogeneous Treatment Effects: Guidelines for Practical Algorithm Design</a> (alaa &amp; van der schaar, 2018)</p>
<ul>
<li><p>over enforcing balance can be harmful, as it may inadvertently remove information that is predictive of outcomes</p></li>
<li><p>analyze optimal minimax rate for ITE using Bayesian nonparametric methods</p>
<ul>
<li><p>with small sample size: selection bias matters</p></li>
<li><p>with large sample size: smoothness and sparsity of <span class="math notranslate nohighlight">\(\mathbb{E}\left[Y_{i}^{(0)} \mid X_{i}=x\right]\)</span> and <span class="math notranslate nohighlight">\(\mathbb{E}\left[Y_{i}^{(1)} \mid X_{i}=x\right]\)</span></p>
<ul>
<li><p>suggests smoothness of mean function for each group should be different, so better to approximate each individually rather than their difference directly</p></li>
</ul>
</li>
</ul>
</li>
<li><p>algorithm: non-stationary Gaussian process w/ doubly-robust huperparameters</p></li>
</ul>
</li>
</ul>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./notes/research_ovws"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="ovw_ml_medicine.html" title="previous page">1.9. ml in medicine</a>
    <a class='right-next' id="next-link" href="ovw_dl_for_neuro.html" title="next page">1.11. dl for neuro</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Chandan Singh<br/>
        
            &copy; Copyright None.<br/>
          <div class="extra_footer">
            <p>
Many of these images are taken from resources on the web.
</p>
          </div>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../../_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>